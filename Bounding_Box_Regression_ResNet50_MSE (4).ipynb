{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **BOUNDING BOX REGRESSION WITH RESNET 50**\n",
        "**WE ARE GOING TO USE CALTECH-101 DATASET, I HAVE UPDATED THE DATASET FOR OUR PURPOSE, ZUERST IMPLEMENTIEREN DIE DATASET**"
      ],
      "metadata": {
        "id": "XKOn5h2TnlUT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BP4fCzQRmu8i"
      },
      "outputs": [],
      "source": [
        "#### ZUERST IMPLEMENTIREN WIR DIE BIBLIOTHEKEN, DI WIR BRAUCHEN KÖNNEN:\n",
        "import os\n",
        "import cv2\n",
        "import imutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import pickle\n",
        "import zipfile # importing the 'zipfile' module\n",
        "\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "!pip install send2trash\n",
        "\n",
        "from send2trash import send2trash\n",
        "import pandas as pd\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "import cv2\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "from keras.models import Sequential\n",
        "## Import from keras_preprocessing not from keras.preprocessing\n",
        "## from keras_preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import regularizers, optimizers\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf1\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "######################################################\n",
        "############## RESNET50 ##############################\n",
        "######################################################\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import MeanIoU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://vijayabhaskar96.medium.com/tutorial-on-keras-flow-from-dataframe-1fd4493d237c\n",
        "# https://studymachinelearning.com/keras-imagedatagenerator-with-flow_from_dataframe/\n",
        "# https://stackoverflow.com/questions/66424141/imagedatagenerator-flow-from-dataframe-multi-output-regression-and-classificatio\n",
        "# https://stackoverflow.com/questions/50781562/stratified-splitting-of-pandas-dataframe-into-training-validation-and-test-set\n",
        "\n",
        "##################################################\n",
        "########### DATA LOADER LINKS ####################\n",
        "##################################################\n"
      ],
      "metadata": {
        "id": "6Nc6hVp7p0df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## WE ARE GOING TO IMPORT THE ZIP FILE, WHICH CONSIST THE IMAGES:\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "XiD5QAYYtmnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_file_name = \"/content/drive/MyDrive/caltech-101_m2.zip\"  # Zip dosyasının adını güncelleyin\n",
        "\n",
        "with zipfile.ZipFile(zip_file_name, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"caltech_files/\")"
      ],
      "metadata": {
        "id": "VwkJK_a6t13l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install send2trash\n",
        "\n",
        "from send2trash import send2trash\n",
        "\n",
        "file_path = 'caltech-101_new/101_ObjectCategories/BACKGROUND_Google'\n",
        "\n",
        "try:\n",
        "    send2trash(file_path)\n",
        "    print(f\"File '{file_path}' has been moved to the trash.\")\n",
        "except OSError:\n",
        "    print(f\"Failed to delete file '{file_path}'.\")"
      ],
      "metadata": {
        "id": "TQINMAVyt2Yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## LET'S IMPORT THE DATAFRAMES FOR VALIDATION, TEST AND TRAIN\n",
        "\n",
        "train_path = '/content/drive/My Drive/train_df.csv'\n",
        "train_df = pd.read_csv(train_path)\n",
        "\n",
        "val_path = '/content/drive/My Drive/val_df.csv'\n",
        "val_df = pd.read_csv(val_path)\n",
        "\n",
        "test_path = '/content/drive/My Drive/test_df.csv'\n",
        "test_df = pd.read_csv(test_path)"
      ],
      "metadata": {
        "id": "Ve6e4rmEt5jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(train_df))\n",
        "print(type(test_df))\n",
        "print(type(val_df))\n",
        "\n",
        "\n",
        "print(len(train_df))\n",
        "print(len(test_df))\n",
        "print(len(val_df))\n"
      ],
      "metadata": {
        "id": "Tt9AICizun1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_csv('/content/train_df.csv', index=False)\n",
        "val_df.to_csv('/content/val_df.csv', index=False)\n",
        "test_df.to_csv('/content/test_df.csv', index=False)\n"
      ],
      "metadata": {
        "id": "BVo4qBdSut4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "id": "K8oPQAbLw_X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "metadata": {
        "id": "laoRMC64xFcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_df.head()"
      ],
      "metadata": {
        "id": "fZSw2q8nxHh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_eda(dataframe):\n",
        "    # Count the number of unique classes\n",
        "    num_classes = len(dataframe['Class Name'].unique())\n",
        "\n",
        "    # Count the number of images\n",
        "    num_images = dataframe.shape[0]\n",
        "\n",
        "    # Count the number of images per class\n",
        "    images_per_class = dataframe['Class Name'].value_counts()\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    plt.barh(range(num_classes), images_per_class.values)\n",
        "    plt.yticks(range(num_classes), images_per_class.index)\n",
        "    plt.xlabel('Number of Images')\n",
        "    plt.ylabel('Class')\n",
        "    plt.title('Number of Images per Class')\n",
        "\n",
        "    # Display the number of images\n",
        "    for i, v in enumerate(images_per_class.values):\n",
        "        plt.text(v, i, str(v), color='black', va='center')\n",
        "\n",
        "    # Adjust the layout and display the plot\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "-cJISgo30TTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the function for each dataframe\n",
        "plot_eda(train_df)\n",
        "plot_eda(val_df)\n",
        "plot_eda(test_df)"
      ],
      "metadata": {
        "id": "MElEvyzR08uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the dataframes\n",
        "combined_df = pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
        "\n",
        "def plot_combined_eda(dataframe):\n",
        "    # Count the number of unique classes\n",
        "    num_classes = len(dataframe['Class Name'].unique())\n",
        "\n",
        "    # Count the number of images\n",
        "    num_images = dataframe.shape[0]\n",
        "\n",
        "    # Count the number of images per class\n",
        "    images_per_class = dataframe['Class Name'].value_counts()\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    plt.barh(range(num_classes), images_per_class.values, height=0.5)\n",
        "\n",
        "    # Adjust the spacing between the y-tick labels\n",
        "    plt.gca().set_yticks(range(num_classes))\n",
        "    plt.gca().set_yticklabels(images_per_class.index, ha='right')\n",
        "\n",
        "    plt.xlabel('Number of Images')\n",
        "    plt.ylabel('Class')\n",
        "    plt.title('Number of Images per Class (Combined)')\n",
        "\n",
        "    # Display the number of images\n",
        "    for i, v in enumerate(images_per_class.values):\n",
        "        plt.text(v + 5, i, str(v), color='black', va='center')\n",
        "\n",
        "    # Display the total number of images\n",
        "    plt.text(0, num_classes+1, f'Total Images: {num_images}', fontsize=12, fontweight='bold')\n",
        "\n",
        "    # Adjust the layout and display the plot\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Call the function for the combined dataframe\n",
        "plot_combined_eda(combined_df)"
      ],
      "metadata": {
        "id": "0Y6jMa4UNwA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **WE HAVE THE DATAFRAMES FOR TRAINING, VALIDATION AND TEST LET'S CONTINUE WITH TRAINING THE MODEL**"
      ],
      "metadata": {
        "id": "g_Cfyveu0U2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/content/drive/My Drive/train_df.csv')\n",
        "val_df = pd.read_csv('/content/drive/My Drive/val_df.csv')\n",
        "test_df = pd.read_csv('/content/drive/My Drive/test_df.csv')"
      ],
      "metadata": {
        "id": "wsC9oPBQxvAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = ['Image Path', 'Class Name', 'Image Name', 'Bounding Box', 'Height', 'Width', 'label',\n",
        "                'normalized', 'Xmin', 'Ymin', 'Xmax', 'Ymax']\n",
        "\n",
        "\n",
        "train_df.columns = column_names\n",
        "val_df.columns = column_names\n",
        "test_df.columns = column_names"
      ],
      "metadata": {
        "id": "F11rRRO9Qiq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "    image = image.astype(np.float32) / 255.0\n",
        "    return image"
      ],
      "metadata": {
        "id": "AMBWKrx9Qn-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_images_with_bboxes(df):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
        "    for i, row in df.head(5).iterrows():\n",
        "        image_path = row['Image Path']\n",
        "        class_name = row['Class Name']\n",
        "        image_name = row['Image Name']\n",
        "        xmin, ymin, xmax, ymax = row['Xmin']*224, row['Ymin']*224, row['Xmax']*224, row['Ymax']*224\n",
        "\n",
        "        image = load_image(image_path)\n",
        "\n",
        "        ax = axes[i]\n",
        "        ax.imshow(image)\n",
        "        ax.axis('off')\n",
        "\n",
        "        # Add bounding box\n",
        "        bbox = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, linewidth=2, edgecolor='r', facecolor='none')\n",
        "        ax.add_patch(bbox)\n",
        "\n",
        "        ax.set_title(f'Class: {class_name}\\nImage: {image_name}')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Plot images with bounding boxes for val_df, test_df, train_df\n",
        "plot_images_with_bboxes(val_df)\n",
        "plot_images_with_bboxes(test_df)\n",
        "plot_images_with_bboxes(train_df)"
      ],
      "metadata": {
        "id": "DL7hTnj1Qvd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####################################################\n",
        "############## MOST IMPORTANT PART #################\n",
        "####################################################\n",
        "def resize_image(image, target_size):\n",
        "    return cv2.resize(image, target_size)\n",
        "\n",
        "def plot_images(images, boxes, labels, dataset_name):\n",
        "    fig, axes = plt.subplots(1, len(images), figsize=(12, 4))\n",
        "    for i, ax in enumerate(axes):\n",
        "        ax.imshow(images[i])\n",
        "        xmin, ymin, xmax, ymax = boxes[i]\n",
        "        ax.add_patch(plt.Rectangle((xmin*224, ymin*224), xmax*224 - xmin*224, ymax*224 - ymin*224, fill=False, color='red', linewidth=2))\n",
        "        ax.set_title(labels[i])\n",
        "        ax.axis('off')\n",
        "    plt.suptitle(f'{dataset_name} Images with Bounding Boxes')\n",
        "    plt.show()\n",
        "\n",
        "# Append data from val_df into arrays\n",
        "val_images = []\n",
        "val_boxes = []\n",
        "val_labels = []\n",
        "\n",
        "for index, row in val_df.iterrows():\n",
        "    image_path = row['Image Path']\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = resize_image(image, (224, 224))\n",
        "    val_images.append(image)\n",
        "\n",
        "    xmin, ymin, xmax, ymax = map(float, [row['Xmin'], row['Ymin'], row['Xmax'], row['Ymax']])\n",
        "    val_boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "    label = row['Class Name']\n",
        "    val_labels.append(label)\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "val_images = np.array(val_images, dtype='float32')\n",
        "val_boxes = np.array(val_boxes, dtype='float32')\n",
        "val_labels = np.array(val_labels)\n",
        "\n",
        "# Normalize the images\n",
        "val_images = val_images / 255.0\n",
        "\n",
        "# Plot the images, bounding boxes, and class names for the first 4 images from the val_df dataset\n",
        "plot_images(val_images[:5], val_boxes[:5], val_labels[:5], 'Validation')\n",
        "\n",
        "# Append data from train_df into arrays\n",
        "train_images = []\n",
        "train_boxes = []\n",
        "train_labels = []\n",
        "\n",
        "for index, row in train_df.iterrows():\n",
        "    image_path = row['Image Path']\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = resize_image(image, (224, 224))\n",
        "    train_images.append(image)\n",
        "\n",
        "    xmin, ymin, xmax, ymax = map(float, [row['Xmin'], row['Ymin'], row['Xmax'], row['Ymax']])\n",
        "    train_boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "    label = row['Class Name']\n",
        "    train_labels.append(label)\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "train_images = np.array(train_images, dtype='float32')\n",
        "train_boxes = np.array(train_boxes, dtype='float32')\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "# Normalize the images\n",
        "train_images = train_images / 255.0\n",
        "\n",
        "# Plot the images, bounding boxes, and class names for the first 4 images from the train_df dataset\n",
        "plot_images(train_images[:5], train_boxes[:5], train_labels[:5], 'Train')\n",
        "\n",
        "# Append data from test_df into arrays\n",
        "test_images = []\n",
        "test_boxes = []\n",
        "test_labels = []\n",
        "\n",
        "for index, row in test_df.iterrows():\n",
        "    image_path = row['Image Path']\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = resize_image(image, (224, 224))\n",
        "    test_images.append(image)\n",
        "\n",
        "    xmin, ymin, xmax, ymax = map(float, [row['Xmin'], row['Ymin'], row['Xmax'], row['Ymax']])\n",
        "    test_boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "    label = row['Class Name']\n",
        "    test_labels.append(label)\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "test_images = np.array(test_images, dtype='float32')\n",
        "test_boxes = np.array(test_boxes, dtype='float32')\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "# Normalize the images\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Plot the images, bounding boxes, and class names for the first 4 images from the test_df dataset\n",
        "plot_images(test_images[:5], test_boxes[:5], test_labels[:5], 'Test')\n"
      ],
      "metadata": {
        "id": "WA-6WBR1ZIpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Perform label encoding on the target labels\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
        "val_labels_encoded = label_encoder.transform(val_labels)\n",
        "\n",
        "# Convert the encoded labels to one-hot encoding\n",
        "train_labels_onehot = to_categorical(train_labels_encoded, num_classes=101)\n",
        "val_labels_onehot = to_categorical(val_labels_encoded, num_classes=101)\n",
        "\n",
        "\n",
        "# Model architecture\n",
        "input_layer = Input(shape=(224, 224, 3))\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=input_layer)\n",
        "\n",
        "flatten = Flatten()(base_model.output)\n",
        "\n",
        "bboxHead = Dense(1024, activation=\"relu\")(flatten)\n",
        "bboxHead = Dense(1024, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(1024, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(1024, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(1024, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(1024, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(1024, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(1024, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(1024, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(1024, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(1024, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(1024, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(1024, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(1024, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(1024, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(1024, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(1024, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(1024, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(1024, activation=\"relu\")(bboxHead)\n",
        "\n",
        "\n",
        "bboxHead = Dense(512, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(512, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(512, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(512, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(512, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(512, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(512, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(512, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(512, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(512, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(512, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(512, activation=\"relu\")(bboxHead)\n",
        "\n",
        "bboxHead = Dense(256, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(256, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(256, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(256, activation=\"relu\")(bboxHead)\n",
        "\n",
        "\n",
        "bboxHead = Dense(128, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(128, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(128, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(128, activation=\"relu\")(bboxHead)\n",
        "\n",
        "\n",
        "bboxHead = Dense(64, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(64, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(64, activation=\"relu\")(bboxHead)\n",
        "\n",
        "bboxHead = Dense(32, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(32, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(32, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(32, activation=\"relu\")(bboxHead)\n",
        "bbox_output = Dense(4, activation='linear', name='bounding_box')(bboxHead)\n",
        "\n",
        "\n",
        "\n",
        "softmaxHead = Dense(1024, activation=\"relu\")(flatten)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "softmaxHead = Dense(1024, activation=\"relu\")(softmaxHead)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "softmaxHead = Dense(1024, activation=\"relu\")(softmaxHead)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "softmaxHead = Dense(512, activation=\"relu\")(softmaxHead)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "softmaxHead = Dense(512, activation=\"relu\")(softmaxHead)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "softmaxHead = Dense(256, activation=\"relu\")(softmaxHead)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "softmaxHead = Dense(256, activation=\"relu\")(softmaxHead)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "softmaxHead = Dense(128, activation=\"relu\")(softmaxHead)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "softmaxHead = Dense(128, activation=\"relu\")(softmaxHead)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "class_output = Dense(101, activation='softmax', name='class_output')(softmaxHead)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=[class_output, bbox_output], random_state=42)\n",
        "\n",
        "# Loss function\n",
        "losses = {\n",
        "    'class_output': 'categorical_crossentropy',\n",
        "    'bounding_box': 'mean_squared_error'\n",
        "}\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss=losses)\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "0if34ot5ym-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(train_images, {'class_output': train_labels_onehot, 'bounding_box': train_boxes},\n",
        "                    validation_data=(val_images, {'class_output': val_labels_onehot, 'bounding_box': val_boxes}),\n",
        "                    epochs=50, batch_size=32)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('/content/drive/MyDrive/trained_model.h5')"
      ],
      "metadata": {
        "id": "_XoO_eHHzM0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the label encoder\n",
        "with open('/content/label_encoder.pkl', 'wb') as file:\n",
        "    pickle.dump(label_encoder, file)"
      ],
      "metadata": {
        "id": "bRRiBnP34MOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the losses\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.style.use('seaborn')\n",
        "\n",
        "# Classification Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['class_output_loss'], label='Train Classification Loss', color='blue')\n",
        "plt.plot(history.history['val_class_output_loss'], label='Validation Classification Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Classification Loss', fontsize=14)\n",
        "plt.legend()\n",
        "\n",
        "# Bounding Box Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['bounding_box_loss'], label='Train Bounding Box Loss', color='blue')\n",
        "plt.plot(history.history['val_bounding_box_loss'], label='Validation Bounding Box Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Bounding Box Loss', fontsize=14)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "e8KpUEkHzNXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Perform label encoding on the target labels\n",
        "test_labels_encoded = label_encoder.transform(test_labels)\n",
        "\n",
        "# Convert the encoded labels to one-hot encoding\n",
        "test_labels_onehot = to_categorical(test_labels_encoded, num_classes=101)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_class_output_loss, test_bbox_output_loss = model.evaluate(test_images, {'class_output': test_labels_onehot, 'bounding_box': test_boxes})\n",
        "\n",
        "print('Test Loss:', test_loss)\n",
        "print('Test Classification Loss:', test_class_output_loss)\n",
        "print('Test Bounding Box Loss:', test_bbox_output_loss)"
      ],
      "metadata": {
        "id": "-47I88Er8Y7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.patches as patches\n",
        "from sklearn.metrics import jaccard_score\n",
        "\n",
        "# Define a function to calculate the IoU score\n",
        "def calculate_iou(box1, box2):\n",
        "    # Extract coordinates from the bounding boxes\n",
        "    xmin1, ymin1, xmax1, ymax1 = box1\n",
        "    xmin2, ymin2, xmax2, ymax2 = box2\n",
        "\n",
        "    # Calculate the coordinates of the intersection rectangle\n",
        "    xmin_inter = max(xmin1, xmin2)\n",
        "    ymin_inter = max(ymin1, ymin2)\n",
        "    xmax_inter = min(xmax1, xmax2)\n",
        "    ymax_inter = min(ymax1, ymax2)\n",
        "\n",
        "    # Calculate the area of intersection rectangle\n",
        "    inter_area = max(0, xmax_inter - xmin_inter + 1) * max(0, ymax_inter - ymin_inter + 1)\n",
        "\n",
        "    # Calculate the areas of the bounding boxes\n",
        "    box1_area = (xmax1 - xmin1 + 1) * (ymax1 - ymin1 + 1)\n",
        "    box2_area = (xmax2 - xmin2 + 1) * (ymax2 - ymin2 + 1)\n",
        "\n",
        "    # Calculate the IoU score\n",
        "    iou = inter_area / float(box1_area + box2_area - inter_area)\n",
        "    return iou\n",
        "\n",
        "# Define a function to plot test images with predicted bounding box, original bounding box, predicted class, and original class\n",
        "def plot_test_images(test_images, test_boxes, test_labels, pred_boxes, pred_labels, step=10):\n",
        "    num_plots = min(len(test_images), 10)\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    for i in range(0, len(test_images), step):\n",
        "        if i // step >= num_plots:\n",
        "            break\n",
        "        plt.subplot(5, 2, (i // step) + 1)\n",
        "\n",
        "        # Denormalize the bounding box coordinates\n",
        "        x1, y1, x2, y2 = test_boxes[i] * 224\n",
        "        xmin = int(x1)\n",
        "        ymin = int(y1)\n",
        "        xmax = int(x2)\n",
        "        ymax = int(y2)\n",
        "\n",
        "        # Denormalize the image array\n",
        "        image = test_images[i] * 255\n",
        "        image = image.astype(np.uint8)\n",
        "\n",
        "        plt.imshow(image)\n",
        "        plt.axis('off')\n",
        "        plt.title(f\"Original Class: {test_labels[i]}\\nPredicted Class: {pred_labels[i]}\")\n",
        "\n",
        "        # Plot original bounding box\n",
        "        rect = patches.Rectangle((xmin, ymin), (xmax - xmin), (ymax - ymin), linewidth=2, edgecolor='r', facecolor='none')\n",
        "        plt.gca().add_patch(rect)\n",
        "\n",
        "        # Denormalize the predicted bounding box coordinates\n",
        "        x1, y1, x2, y2 = pred_boxes[i] * 224\n",
        "        xmin = int(x1)\n",
        "        ymin = int(y1)\n",
        "        xmax = int(x2)\n",
        "        ymax = int(y2)\n",
        "\n",
        "        # Plot predicted bounding box\n",
        "        rect = patches.Rectangle((xmin, ymin), (xmax - xmin), (ymax - ymin), linewidth=2, edgecolor='g', facecolor='none')\n",
        "        plt.gca().add_patch(rect)\n",
        "\n",
        "        # Calculate IoU score\n",
        "        iou_score = calculate_iou(test_boxes[i] * 224, pred_boxes[i] * 224)\n",
        "        plt.text(xmin, ymin, f\"IoU: {iou_score:.2f}\", color='b', fontsize=8, backgroundcolor='w')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Perform predictions on the test data\n",
        "preds = model.predict(test_images)\n",
        "pred_labels = label_encoder.inverse_transform(np.argmax(preds[0], axis=1))\n",
        "pred_boxes = preds[1]\n",
        "\n",
        "# Plot every 10th test image with predicted bounding box, original bounding box, predicted class, original class, and IoU score\n",
        "plot_test_images(test_images, test_boxes, test_labels, pred_boxes, pred_labels, step=1)\n"
      ],
      "metadata": {
        "id": "EWXGJZ8W-HLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Calculate precision, recall, and F1 scores for each class\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_labels, pred_labels, average=None)\n",
        "\n",
        "# Get the unique class labels\n",
        "classes = np.unique(test_labels)\n",
        "\n",
        "# Set the width of the bars\n",
        "bar_width = 0.35\n",
        "\n",
        "# Set the x locations of the bars\n",
        "index = np.arange(len(classes))\n",
        "\n",
        "# Set the figure size\n",
        "plt.figure(figsize=(12, 12))\n",
        "\n",
        "# Plot the recall scores\n",
        "plt.bar(index, recall, bar_width, label='Recall', color='skyblue')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Recall Scores by Class')\n",
        "plt.xticks(index, classes, rotation='vertical')\n",
        "\n",
        "# Add scores as text inside each bar\n",
        "for i, v in enumerate(recall):\n",
        "    plt.text(i, v, f\"{v:.2f}\", color='black', ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Set the figure size\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot the F1 scores\n",
        "plt.bar(index, f1, bar_width, label='F1 Score', color='lightgreen')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Score')\n",
        "plt.title('F1 Scores by Class')\n",
        "plt.xticks(index, classes, rotation='vertical')\n",
        "\n",
        "# Add scores as text inside each bar\n",
        "for i, v in enumerate(f1):\n",
        "    plt.text(i, v, f\"{v:.2f}\", color='black', ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6jev0sbVAbpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_iou_scores = []\n",
        "\n",
        "# Calculate the mean IoU score for each class\n",
        "for class_label in classes:\n",
        "    # Get the indices of samples belonging to the current class\n",
        "    class_indices = np.where(test_labels == class_label)[0]\n",
        "\n",
        "    # Extract the predicted and ground truth bounding boxes for the current class\n",
        "    class_pred_boxes = pred_boxes[class_indices]\n",
        "    class_test_boxes = test_boxes[class_indices]\n",
        "\n",
        "    # Calculate the IoU score for each sample\n",
        "    iou_scores = []\n",
        "\n",
        "    for i in range(len(class_indices)):\n",
        "        iou_score = calculate_iou(class_test_boxes[i], class_pred_boxes[i])\n",
        "        iou_scores.append(iou_score)\n",
        "\n",
        "    # Calculate the mean IoU score for the current class\n",
        "    mean_iou_score = np.mean(iou_scores)\n",
        "\n",
        "    # Append the class label and mean IoU score to the list of class IoU scores\n",
        "    class_iou_scores.append((class_label, mean_iou_score))\n",
        "\n",
        "# Sort the mean IoU scores from best to worst\n",
        "class_iou_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Extract the class labels and mean IoU scores into separate lists\n",
        "sorted_classes = [x[0] for x in class_iou_scores]\n",
        "sorted_scores = [x[1] for x in class_iou_scores]\n",
        "\n",
        "# Calculate the total mean IoU score\n",
        "total_mean_iou = np.mean(sorted_scores)\n",
        "\n",
        "# Plot the mean IoU scores for each class\n",
        "fig, ax = plt.subplots(figsize=(12, 12))\n",
        "bars = ax.barh(range(len(sorted_classes)), sorted_scores, color='purple')\n",
        "ax.set_xlabel('Mean IoU Score')\n",
        "ax.set_ylabel('Class')\n",
        "ax.set_title('Mean IoU Scores by Class')\n",
        "ax.set_yticks(range(len(sorted_classes)))\n",
        "ax.set_yticklabels(sorted_classes)\n",
        "ax.invert_yaxis()\n",
        "\n",
        "# Add scores as text inside each bar\n",
        "for bar, score in zip(bars, sorted_scores):\n",
        "    ax.text(bar.get_width() + 0.005, bar.get_y() + bar.get_height() / 2, f\"{score:.2f}\",\n",
        "            va='center', fontsize=7)\n",
        "\n",
        "# Add total mean IoU score as text at the top\n",
        "ax.text(0, -1, f\"Total Mean IoU: {total_mean_iou:.2f}\", ha='left', va='center', fontsize=12)\n",
        "\n",
        "# Add a vertical line at x=0.5 for reference\n",
        "ax.axvline(x=0.5, color='red', linestyle='--', linewidth=1)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u3ysj2hgFvcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Get the number of images for each class from test_df\n",
        "class_counts = test_df[\"Class Name\"].value_counts()\n",
        "\n",
        "# Set the figure size\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot the number of images per class\n",
        "class_counts.plot(kind='bar')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of Images')\n",
        "plt.title('Number of Images per Class')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rbXziPejLf63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Calculate precision, recall, and F1 scores for each class\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_df[\"Class Name\"], pred_labels, average=None)\n",
        "\n",
        "# Get the unique class labels\n",
        "classes = np.unique(test_df[\"Class Name\"])\n",
        "\n",
        "# Sort precision, recall, and F1 scores in descending order\n",
        "sorted_indices = np.argsort(f1)[::-1]\n",
        "precision_sorted = precision[sorted_indices]\n",
        "recall_sorted = recall[sorted_indices]\n",
        "f1_sorted = f1[sorted_indices]\n",
        "classes_sorted = classes[sorted_indices]\n",
        "class_counts_sorted = class_counts[classes_sorted]\n",
        "\n",
        "# Set the figure size\n",
        "plt.figure(figsize=(12, 12))\n",
        "\n",
        "# Plot the precision scores\n",
        "plt.bar(range(len(classes)), precision_sorted, width=0.3, label='Precision', color='lightblue')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Precision Scores by Class')\n",
        "plt.xticks(range(len(classes)), classes_sorted, rotation='vertical')\n",
        "\n",
        "# Add scores and class counts as text above each bar\n",
        "for i, v in enumerate(precision_sorted):\n",
        "    plt.text(i, v, f\"{v:.2f}\\n({class_counts_sorted[i]})\", color='black', ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Set the figure size\n",
        "plt.figure(figsize=(12, 12))\n",
        "\n",
        "# Plot the recall scores\n",
        "plt.bar(range(len(classes)), recall_sorted, width=0.3, label='Recall', color='lightgreen')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Recall Scores by Class')\n",
        "plt.xticks(range(len(classes)), classes_sorted, rotation='vertical')\n",
        "\n",
        "# Add scores and class counts as text above each bar\n",
        "for i, v in enumerate(recall_sorted):\n",
        "    plt.text(i, v, f\"{v:.2f}\\n({class_counts_sorted[i]})\", color='black', ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Set the figure size\n",
        "plt.figure(figsize=(12, 12))\n",
        "\n",
        "# Plot the F1 scores\n",
        "plt.bar(range(len(classes)), f1_sorted, width=0.3, label='F1 Score', color='orange')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Score')\n",
        "plt.title('F1 Scores by Class')\n",
        "plt.xticks(range(len(classes)), classes_sorted, rotation='vertical')\n",
        "\n",
        "# Add scores and class counts as text above each bar\n",
        "for i, v in enumerate(f1_sorted):\n",
        "    plt.text(i, v, f\"{v:.2f}\\n({class_counts_sorted[i]})\", color='black', ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JUB_NvZWJ9RI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()\n",
        "\n"
      ],
      "metadata": {
        "id": "ZOgNw1B0K_wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Calculate precision, recall, and F1 scores for each class\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_df[\"Class Name\"], pred_labels, average=None)\n",
        "\n",
        "# Calculate the mean F1 score\n",
        "mean_f1 = np.mean(f1)\n",
        "\n",
        "# Get the unique class labels and their counts\n",
        "classes, class_counts = np.unique(test_df[\"Class Name\"], return_counts=True)\n",
        "\n",
        "# Sort precision, recall, F1 scores, and class counts in descending order\n",
        "sorted_indices = np.argsort(f1)[::-1]\n",
        "precision_sorted = precision[sorted_indices]\n",
        "recall_sorted = recall[sorted_indices]\n",
        "f1_sorted = f1[sorted_indices]\n",
        "classes_sorted = classes[sorted_indices]\n",
        "class_counts_sorted = class_counts[sorted_indices]\n",
        "\n",
        "# Set the figure size and create subplots\n",
        "fig, ax = plt.subplots(figsize=(12, 12))\n",
        "\n",
        "# Set the width of the bars\n",
        "bar_width = 0.8\n",
        "\n",
        "# Plot the F1 scores\n",
        "bars = ax.barh(np.arange(len(classes_sorted)), f1_sorted, height=bar_width, color='purple')\n",
        "\n",
        "# Add F1 scores as text inside each bar\n",
        "for i, (bar, score) in enumerate(zip(bars, f1_sorted)):\n",
        "    ax.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height() / 2, f\"{score:.2f}\",\n",
        "            va='center', ha='left', fontsize=7)\n",
        "\n",
        "# Set y-axis ticks and labels\n",
        "ax.set_yticks(np.arange(len(classes_sorted)))\n",
        "ax.set_yticklabels(classes_sorted, fontsize=7)\n",
        "\n",
        "# Set x-axis label and limits\n",
        "ax.set_xlabel('F1 Score', fontsize=10)\n",
        "ax.set_xlim(0, 1)\n",
        "\n",
        "# Add class counts as text near the class names\n",
        "for i, count in enumerate(class_counts_sorted):\n",
        "    ax.text(-0.07, i, f\"  ({count})\", va='center', ha='right', fontsize=8)\n",
        "\n",
        "# Set plot title\n",
        "ax.set_title('F1 Scores by Class', fontsize=12)\n",
        "\n",
        "# Remove spines and ticks\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['left'].set_visible(False)\n",
        "ax.spines['bottom'].set_visible(False)\n",
        "ax.tick_params(left=False, bottom=False)\n",
        "\n",
        "# Add a grid to the plot\n",
        "ax.grid(axis='x', color='lightgray', linestyle='--')\n",
        "\n",
        "# Adjust layout\n",
        "fig.tight_layout()\n",
        "\n",
        "# Invert the y-axis\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Fr4yxMbQM2EF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_iou_scores = []\n",
        "\n",
        "# Calculate the mean IoU score for each class\n",
        "for class_label in classes:\n",
        "    # Get the indices of samples belonging to the current class\n",
        "    class_indices = np.where(test_labels == class_label)[0]\n",
        "\n",
        "    # Extract the predicted and ground truth bounding boxes for the current class\n",
        "    class_pred_boxes = pred_boxes[class_indices]\n",
        "    class_test_boxes = test_boxes[class_indices]\n",
        "\n",
        "    # Calculate the IoU score for each sample\n",
        "    iou_scores = []\n",
        "\n",
        "    for i in range(len(class_indices)):\n",
        "        iou_score = calculate_iou(class_test_boxes[i], class_pred_boxes[i])\n",
        "        iou_scores.append(iou_score)\n",
        "\n",
        "    # Calculate the mean IoU score for the current class\n",
        "    mean_iou_score = np.mean(iou_scores)\n",
        "\n",
        "    # Append the class label, mean IoU score, and number of images to the list of class IoU scores\n",
        "    class_iou_scores.append((class_label, mean_iou_score, len(class_indices)))\n",
        "\n",
        "# Sort the mean IoU scores from best to worst\n",
        "class_iou_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Extract the class labels, mean IoU scores, and number of images into separate lists\n",
        "sorted_classes = [x[0] for x in class_iou_scores]\n",
        "sorted_scores = [x[1] for x in class_iou_scores]\n",
        "num_images = [x[2] for x in class_iou_scores]\n",
        "\n",
        "# Calculate the total mean IoU score\n",
        "total_mean_iou = np.mean(sorted_scores)\n",
        "\n",
        "# Plot the mean IoU scores for each class\n",
        "fig, ax = plt.subplots(figsize=(12, 12))\n",
        "bars = ax.barh(range(len(sorted_classes)), sorted_scores, color='purple')\n",
        "ax.set_xlabel('Mean IoU Score')\n",
        "ax.set_ylabel('Class')\n",
        "ax.set_title('Mean IoU Scores by Class')\n",
        "ax.set_yticks(range(len(sorted_classes)))\n",
        "ax.set_yticklabels(sorted_classes)\n",
        "\n",
        "for i, count in enumerate(class_counts_sorted):\n",
        "    ax.text(-0.1, i, f\"  ({count})\", va='center', ha='right', fontsize=8)\n",
        "\n",
        "# Add scores as text inside each bar\n",
        "for bar, score in zip(bars, sorted_scores):\n",
        "    ax.text(bar.get_width() + 0.005, bar.get_y() + bar.get_height() / 2, f\"{score:.2f}\",\n",
        "            va='center', fontsize=7)\n",
        "\n",
        "# Add total mean IoU score as text at the top\n",
        "ax.text(0, len(sorted_classes), f\"Total Mean IoU: {total_mean_iou:.2f}\", ha='left', va='center', fontsize=12)\n",
        "\n",
        "# Add a vertical line at x=0.5 for reference\n",
        "ax.axvline(x=0.5, color='red', linestyle='--', linewidth=1)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_Znfr_uBQ5TC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate precision, recall, and F1 scores for each class\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_df[\"Class Name\"], pred_labels, average=None)\n",
        "\n",
        "# Calculate the mean F1 score\n",
        "mean_f1 = np.mean(f1)\n",
        "\n",
        "# Get the unique class labels and their counts\n",
        "classes, class_counts = np.unique(test_df[\"Class Name\"], return_counts=True)\n",
        "\n",
        "# Sort precision, recall, F1 scores, and class counts in descending order based on F1 scores\n",
        "sorted_indices = np.argsort(f1)[::-1]\n",
        "precision_sorted = precision[sorted_indices]\n",
        "recall_sorted = recall[sorted_indices]\n",
        "f1_sorted = f1[sorted_indices]\n",
        "classes_sorted = classes[sorted_indices]\n",
        "class_counts_sorted = class_counts[sorted_indices]\n",
        "\n",
        "# Calculate mean IoU score for each class\n",
        "class_iou_scores = []\n",
        "\n",
        "for class_label in classes_sorted:\n",
        "    class_indices = np.where(test_labels == class_label)[0]\n",
        "    class_pred_boxes = pred_boxes[class_indices]\n",
        "    class_test_boxes = test_boxes[class_indices]\n",
        "\n",
        "    iou_scores = []\n",
        "\n",
        "    for i in range(len(class_indices)):\n",
        "        iou_score = calculate_iou(class_test_boxes[i], class_pred_boxes[i])\n",
        "        iou_scores.append(iou_score)\n",
        "\n",
        "    mean_iou_score = np.mean(iou_scores)\n",
        "\n",
        "    class_iou_scores.append(mean_iou_score)\n",
        "\n",
        "# Sort the mean IoU scores from best to worst\n",
        "class_iou_scores_sorted = np.array(class_iou_scores)[sorted_indices]\n",
        "\n",
        "# Set the figure size and create subplots\n",
        "fig, ax = plt.subplots(figsize=(12, 12))\n",
        "\n",
        "# Set the width of the bars\n",
        "bar_width = 0.4\n",
        "\n",
        "# Plot the F1 scores\n",
        "f1_bars = ax.barh(np.arange(len(classes_sorted)), f1_sorted, height=bar_width, color='purple', label='F1 Score')\n",
        "\n",
        "# Plot the mean IoU scores\n",
        "iou_bars = ax.barh(np.arange(len(classes_sorted)) + bar_width, class_iou_scores_sorted, height=bar_width, color='blue', label='Mean IoU')\n",
        "\n",
        "# Add F1 scores as text inside each bar\n",
        "for i, (bar, score) in enumerate(zip(f1_bars, f1_sorted)):\n",
        "    ax.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height() / 2, f\"{score:.2f}\",\n",
        "            va='center', ha='left', fontsize=7)\n",
        "\n",
        "# Add mean IoU scores as text inside each bar\n",
        "for i, (bar, score) in enumerate(zip(iou_bars, class_iou_scores_sorted)):\n",
        "    ax.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height() / 2, f\"{score:.2f}\",\n",
        "            va='center', ha='left', fontsize=7, color='white')\n",
        "\n",
        "# Set y-axis ticks and labels\n",
        "ax.set_yticks(np.arange(len(classes_sorted)) + bar_width / 2)\n",
        "ax.set_yticklabels(classes_sorted, fontsize=7)\n",
        "\n",
        "# Set x-axis label and limits\n",
        "ax.set_xlabel('Scores', fontsize=10)\n",
        "ax.set_xlim(0, 1)\n",
        "\n",
        "# Add class counts as text near the class names\n",
        "for i, count in enumerate(class_counts_sorted):\n",
        "    ax.text(-0.07, i + bar_width / 2, f\"  ({count})\", va='center', ha='right', fontsize=8)\n",
        "\n",
        "# Set plot title\n",
        "ax.set_title('F1 Scores and Mean IoU Scores by Class', fontsize=12)\n",
        "\n",
        "# Remove spines and ticks\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['left'].set_visible(False)\n",
        "ax.spines['bottom'].set_visible(False)\n",
        "ax.tick_params(left=False, bottom=False)\n",
        "\n",
        "# Add a grid to the plot\n",
        "ax.grid(axis='x', color='lightgray', linestyle='--')\n",
        "\n",
        "# Adjust layout\n",
        "fig.tight_layout()\n",
        "\n",
        "# Invert the y-axis\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "# Show the legend\n",
        "ax.legend(loc='lower right')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "i3Eyf7Y9RUs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate precision, recall, and F1 scores for each class\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_df[\"Class Name\"], pred_labels, average=None)\n",
        "\n",
        "# Calculate the mean F1 score\n",
        "mean_f1 = np.mean(f1)\n",
        "\n",
        "# Get the unique class labels and their counts\n",
        "classes, class_counts = np.unique(test_df[\"Class Name\"], return_counts=True)\n",
        "\n",
        "# Sort precision, recall, F1 scores, and class counts in descending order based on F1 scores\n",
        "sorted_indices = np.argsort(f1)[::-1]\n",
        "precision_sorted = precision[sorted_indices]\n",
        "recall_sorted = recall[sorted_indices]\n",
        "f1_sorted = f1[sorted_indices]\n",
        "classes_sorted = classes[sorted_indices]\n",
        "class_counts_sorted = class_counts[sorted_indices]\n",
        "\n",
        "# Calculate mean IoU score for each class\n",
        "class_iou_scores = []\n",
        "\n",
        "for class_label in classes_sorted:\n",
        "    class_indices = np.where(test_labels == class_label)[0]\n",
        "    class_pred_boxes = pred_boxes[class_indices]\n",
        "    class_test_boxes = test_boxes[class_indices]\n",
        "\n",
        "    iou_scores = []\n",
        "\n",
        "    for i in range(len(class_indices)):\n",
        "        iou_score = calculate_iou(class_test_boxes[i], class_pred_boxes[i])\n",
        "        iou_scores.append(iou_score)\n",
        "\n",
        "    mean_iou_score = np.mean(iou_scores)\n",
        "\n",
        "    class_iou_scores.append(mean_iou_score)\n",
        "\n",
        "# Sort the mean IoU scores from best to worst\n",
        "class_iou_scores_sorted = np.array(class_iou_scores)[sorted_indices]\n",
        "\n",
        "# Set the figure size and create subplots\n",
        "fig, ax = plt.subplots(figsize=(12, 12))\n",
        "\n",
        "# Set the width of the bars\n",
        "bar_width = 0.4\n",
        "\n",
        "# Plot the F1 scores\n",
        "f1_bars = ax.barh(np.arange(len(classes_sorted)), f1_sorted, height=bar_width, color='green', label='F1 Score')\n",
        "\n",
        "# Plot the mean IoU scores\n",
        "iou_bars = ax.barh(np.arange(len(classes_sorted)) + bar_width, class_iou_scores_sorted, height=bar_width, color='blue', label='Mean IoU')\n",
        "\n",
        "# Add F1 scores as text inside each bar\n",
        "for i, (bar, score) in enumerate(zip(f1_bars, f1_sorted)):\n",
        "    ax.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height() / 2, f\"{score:.2f}\",\n",
        "            va='center', ha='left', fontsize=7, fontweight='bold', color='red')\n",
        "\n",
        "# Add mean IoU scores as text inside each bar\n",
        "for i, (bar, score) in enumerate(zip(iou_bars, class_iou_scores_sorted)):\n",
        "    ax.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height() / 2, f\"{score:.2f}\",\n",
        "            va='center', ha='left', fontsize=7, fontweight='bold', color='red')\n",
        "\n",
        "# Set y-axis ticks and labels\n",
        "ax.set_yticks(np.arange(len(classes_sorted)) + bar_width / 2)\n",
        "ax.set_yticklabels(classes_sorted, fontsize=7, fontweight='bold', color='black')\n",
        "\n",
        "# Set x-axis label and limits\n",
        "ax.set_xlabel('Scores', fontsize=7, color='red')\n",
        "ax.set_xlim(0, 1)\n",
        "\n",
        "# Add class counts as text near the class names\n",
        "for i, count in enumerate(class_counts_sorted):\n",
        "    ax.text(-0.1, i + bar_width / 2, f\"  ({count})\", va='center', ha='right', fontsize=7, fontweight='bold', color='red')\n",
        "\n",
        "# Set plot title\n",
        "ax.set_title('F1 Scores and Mean IoU Scores by Class', fontsize=14, fontweight='bold', color='red')\n",
        "\n",
        "# Remove spines and ticks\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['left'].set_visible(False)\n",
        "ax.spines['bottom'].set_visible(False)\n",
        "ax.tick_params(left=False, bottom=False)\n",
        "\n",
        "# Add a grid to the plot\n",
        "ax.grid(axis='x', color='lightgray', linestyle='--')\n",
        "\n",
        "# Show the legend\n",
        "ax.legend(loc='upper right', fontsize=7)\n",
        "\n",
        "# Invert the y-axis\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mTeBXeVfTS-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## WE ARE GOING TO SEPERATE CARSIDE DATASET FROM TRAINING ARRAYS:\n",
        "## (WE ARE GOING TO ACCOMPLISH OUR EXPERIMENTS WITH 100 DATASET CLASSES)\n",
        "\n",
        "\n",
        "## * RESNET50 --> MSE --> TRAINABLE = FALSE (TOP ONLY)\n",
        "## * RESNET50 --> MSE --> TRAINABLE = TRUE (ONLY FULL)\n",
        "## * RESNET50 --> MSE --> TRAINABLE = FALSE --> THEN --> TRAINABLE = TRUE (TRAIN SAME MODEL WITH SMALLER LEARNING RATE)\n",
        "\n",
        "\n",
        "## SAME FOR IOU\n",
        "\n",
        "## THEN SHOE THE RESULTS OF CARSIDE\n",
        "\n",
        "\n",
        "## CREATE TABLE TO SHOW OUTPUTS IN BETTER WAY"
      ],
      "metadata": {
        "id": "XYn7goIeTeAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## LET'S IMPORT THE DATAFRAMES FOR VALIDATION, TEST AND TRAIN\n",
        "\n",
        "train_path = '/content/drive/My Drive/train_df.csv'\n",
        "train_df = pd.read_csv(train_path)\n",
        "\n",
        "val_path = '/content/drive/My Drive/val_df.csv'\n",
        "val_df = pd.read_csv(val_path)\n",
        "\n",
        "test_path = '/content/drive/My Drive/test_df.csv'\n",
        "test_df = pd.read_csv(test_path)"
      ],
      "metadata": {
        "id": "fThg0N2P1D_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_df))\n",
        "print(len(test_df))\n",
        "print(len(val_df))\n"
      ],
      "metadata": {
        "id": "e6zChmml1SjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Filter rows with 'carside' class and create a new DataFrame\n",
        "carside_df = train_df[train_df['Class Name'] == 'carside'].copy()\n",
        "\n",
        "# Remove rows with 'carside' class from the original DataFrame\n",
        "train_df = train_df[train_df['Class Name'] != 'carside']\n",
        "\n",
        "# Reset the index of the new DataFrame\n",
        "carside_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Reset the index of the original DataFrame\n",
        "train_df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "8V5jvjAr1aTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(carside_df))\n",
        "print(len(train_df))"
      ],
      "metadata": {
        "id": "HeLB5_za1m67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Filter rows with 'carside' class and create a new DataFrame\n",
        "val_carside_df = val_df[val_df['Class Name'] == 'carside'].copy()\n",
        "\n",
        "# Remove rows with 'carside' class from the original DataFrame\n",
        "val_df = val_df[val_df['Class Name'] != 'carside']\n",
        "\n",
        "# Reset the index of the new DataFrame\n",
        "val_carside_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Reset the index of the original DataFrame\n",
        "val_df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "BPDEpySH1uHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(val_carside_df))\n",
        "print(len(val_df))"
      ],
      "metadata": {
        "id": "iWN9k5i_1_c2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Filter rows with 'carside' class and create a new DataFrame\n",
        "test_carside_df = test_df[test_df['Class Name'] == 'carside'].copy()\n",
        "\n",
        "# Remove rows with 'carside' class from the original DataFrame\n",
        "test_df = test_df[test_df['Class Name'] != 'carside']\n",
        "\n",
        "# Reset the index of the new DataFrame\n",
        "test_carside_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Reset the index of the original DataFrame\n",
        "test_df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "dvp_bJ-g2Dnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(test_carside_df))\n",
        "print(len(test_df))"
      ],
      "metadata": {
        "id": "fN8P5LG-2N_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Set the parent directory path\n",
        "parent_dir = \"/content/drive/MyDrive/\"\n",
        "\n",
        "# Set the directory name\n",
        "directory_name = \"project_mark2\"\n",
        "\n",
        "# Combine the parent directory path and directory name\n",
        "directory_path = os.path.join(parent_dir, directory_name)\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(directory_path, exist_ok=True)\n",
        "\n",
        "# Print the path of the created directory\n",
        "print(\"Directory created:\", directory_path)"
      ],
      "metadata": {
        "id": "BRQ3TV_a2Rkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Set the parent directory path\n",
        "parent_dir = \"/content/drive/MyDrive/project_mark2\"\n",
        "\n",
        "# Save train_df to CSV\n",
        "train_df.to_csv(os.path.join(parent_dir, \"train_df.csv\"), index=False)\n",
        "\n",
        "# Save val_df to CSV\n",
        "val_df.to_csv(os.path.join(parent_dir, \"val_df.csv\"), index=False)\n",
        "\n",
        "# Save test_df to CSV\n",
        "test_df.to_csv(os.path.join(parent_dir, \"test_df.csv\"), index=False)\n",
        "\n",
        "# Save test_carside_df to CSV\n",
        "test_carside_df.to_csv(os.path.join(parent_dir, \"test_carside_df.csv\"), index=False)\n",
        "\n",
        "# Save val_carside_df to CSV\n",
        "val_carside_df.to_csv(os.path.join(parent_dir, \"val_carside_df.csv\"), index=False)\n",
        "\n",
        "# Save carside_df to CSV\n",
        "carside_df.to_csv(os.path.join(parent_dir, \"carside_df.csv\"), index=False)\n",
        "\n",
        "print(\"Files saved in directory:\", parent_dir)"
      ],
      "metadata": {
        "id": "pGCZDy5t3Bw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#########################################\n",
        "####### controls for 'carside' ##########\n",
        "\n",
        "test_carside_df.head()"
      ],
      "metadata": {
        "id": "JAUgZO4C3WT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_carside_df.head()"
      ],
      "metadata": {
        "id": "_7pAn52R3dHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "carside_df.head()"
      ],
      "metadata": {
        "id": "oGeBtETw3xVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the occurrences of each class name in the train_df DataFrame\n",
        "class_counts = train_df['Class Name'].value_counts()\n",
        "\n",
        "# Check if the class name 'carside' exists in the DataFrame\n",
        "if 'carside' in class_counts:\n",
        "    # Get the number of classes with the class name 'carside'\n",
        "    num_classes_carside = class_counts['carside']\n",
        "    print(f\"The number of classes with the class name 'carside': {num_classes_carside}\")\n",
        "else:\n",
        "    print(\"No classes with the class name 'carside' found.\")"
      ],
      "metadata": {
        "id": "bKYgOH4q3zAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the occurrences of each class name in the train_df DataFrame\n",
        "class_counts = val_df['Class Name'].value_counts()\n",
        "\n",
        "# Check if the class name 'carside' exists in the DataFrame\n",
        "if 'carside' in class_counts:\n",
        "    # Get the number of classes with the class name 'carside'\n",
        "    num_classes_carside = class_counts['carside']\n",
        "    print(f\"The number of classes with the class name 'carside': {num_classes_carside}\")\n",
        "else:\n",
        "    print(\"No classes with the class name 'carside' found.\")"
      ],
      "metadata": {
        "id": "eI_Q5WAL34cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the occurrences of each class name in the train_df DataFrame\n",
        "class_counts = test_df['Class Name'].value_counts()\n",
        "\n",
        "# Check if the class name 'carside' exists in the DataFrame\n",
        "if 'carside' in class_counts:\n",
        "    # Get the number of classes with the class name 'carside'\n",
        "    num_classes_carside = class_counts['carside']\n",
        "    print(f\"The number of classes with the class name 'carside': {num_classes_carside}\")\n",
        "else:\n",
        "    print(\"No classes with the class name 'carside' found.\")"
      ],
      "metadata": {
        "id": "mvopCTpK36Qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the occurrences of each class name in the train_df DataFrame\n",
        "class_counts = carside_df['Class Name'].value_counts()\n",
        "\n",
        "# Check if the class name 'carside' exists in the DataFrame\n",
        "if 'carside' in class_counts:\n",
        "    # Get the number of classes with the class name 'carside'\n",
        "    num_classes_carside = class_counts['carside']\n",
        "    print(f\"The number of classes with the class name 'carside': {num_classes_carside}\")\n",
        "else:\n",
        "    print(\"No classes with the class name 'carside' found.\")"
      ],
      "metadata": {
        "id": "wH27oWc938Wf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the occurrences of each class name in the train_df DataFrame\n",
        "class_counts = val_carside_df['Class Name'].value_counts()\n",
        "\n",
        "# Check if the class name 'carside' exists in the DataFrame\n",
        "if 'carside' in class_counts:\n",
        "    # Get the number of classes with the class name 'carside'\n",
        "    num_classes_carside = class_counts['carside']\n",
        "    print(f\"The number of classes with the class name 'carside': {num_classes_carside}\")\n",
        "else:\n",
        "    print(\"No classes with the class name 'carside' found.\")"
      ],
      "metadata": {
        "id": "B7oKGMl73-ZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the occurrences of each class name in the train_df DataFrame\n",
        "class_counts = test_carside_df['Class Name'].value_counts()\n",
        "\n",
        "# Check if the class name 'carside' exists in the DataFrame\n",
        "if 'carside' in class_counts:\n",
        "    # Get the number of classes with the class name 'carside'\n",
        "    num_classes_carside = class_counts['carside']\n",
        "    print(f\"The number of classes with the class name 'carside': {num_classes_carside}\")\n",
        "else:\n",
        "    print(\"No classes with the class name 'carside' found.\")"
      ],
      "metadata": {
        "id": "c4XRtJtL4B_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################################################\n",
        "######## okey we have now train - test - val df's ##########\n",
        "############################################################\n",
        "################# we also have carside dataset ###########\n",
        "###########################################################\n",
        "\n",
        "############################################################################\n",
        "########## UPDATE FILE NAMES AND LEARNING RATE FOR FIRST TWO ###############\n",
        "############################################################################\n"
      ],
      "metadata": {
        "id": "f-4fYSTZ4Kd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **100 classes resnet50 - mse - trainable = Ture**"
      ],
      "metadata": {
        "id": "ChbuPwvi4i3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "\n",
        "# def iou_loss(y_true, y_pred):\n",
        "#     # Extract the normalized coordinates of the predicted and ground truth boxes\n",
        "#     pred_x1, pred_y1, pred_x2, pred_y2 = tf.unstack(y_pred, axis=1)\n",
        "#     true_x1, true_y1, true_x2, true_y2 = tf.unstack(y_true, axis=1)\n",
        "\n",
        "#     # Convert normalized coordinates to absolute coordinates\n",
        "#     pred_x1 = pred_x1 * 512\n",
        "#     pred_y1 = pred_y1 * 512\n",
        "#     pred_x2 = pred_x2 * 512\n",
        "#     pred_y2 = pred_y2 * 512\n",
        "#     true_x1 = true_x1 * 512\n",
        "#     true_y1 = true_y1 * 512\n",
        "#     true_x2 = true_x2 * 512\n",
        "#     true_y2 = true_y2 * 512\n",
        "\n",
        "#     # Calculate the coordinates of the intersection rectangle\n",
        "#     x1 = tf.maximum(pred_x1, true_x1)\n",
        "#     y1 = tf.maximum(pred_y1, true_y1)\n",
        "#     x2 = tf.minimum(pred_x2, true_x2)\n",
        "#     y2 = tf.minimum(pred_y2, true_y2)\n",
        "\n",
        "#     # Calculate the area of intersection\n",
        "#     intersection = tf.maximum(0.0, x2 - x1) * tf.maximum(0.0, y2 - y1)\n",
        "\n",
        "#     # Calculate the area of predicted and ground truth boxes\n",
        "#     pred_area = (pred_x2 - pred_x1) * (pred_y2 - pred_y1)\n",
        "#     true_area = (true_x2 - true_x1) * (true_y2 - true_y1)\n",
        "\n",
        "#     # Calculate the union area\n",
        "#     union = pred_area + true_area - intersection\n",
        "\n",
        "#     # Calculate the IoU\n",
        "#     iou = intersection / (union + tf.keras.backend.epsilon())\n",
        "\n",
        "#     # Calculate the IoU loss\n",
        "#     iou_loss = 1.0 - iou\n",
        "\n",
        "#     return iou_loss"
      ],
      "metadata": {
        "id": "sgu2XP1JpOWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras.utils import get_custom_objects\n",
        "# get_custom_objects().update({'iou_loss': iou_loss})\n",
        "\n",
        "\n",
        "losses = {\n",
        "    'class_output': 'categorical_crossentropy',\n",
        "    'bounding_box': 'mean_squared_error'\n",
        "}"
      ],
      "metadata": {
        "id": "VsWvyAuspiyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####################################################\n",
        "############## MOST IMPORTANT PART #################\n",
        "####################################################\n",
        "def resize_image(image, target_size):\n",
        "    return cv2.resize(image, target_size)\n",
        "\n",
        "def plot_images(images, boxes, labels, dataset_name):\n",
        "    fig, axes = plt.subplots(1, len(images), figsize=(12, 4))\n",
        "    for i, ax in enumerate(axes):\n",
        "        ax.imshow(images[i])\n",
        "        xmin, ymin, xmax, ymax = boxes[i]\n",
        "        ax.add_patch(plt.Rectangle((xmin*224, ymin*224), xmax*224 - xmin*224, ymax*224 - ymin*224, fill=False, color='red', linewidth=2))\n",
        "        ax.set_title(labels[i])\n",
        "        ax.axis('off')\n",
        "    plt.suptitle(f'{dataset_name} Images with Bounding Boxes')\n",
        "    plt.show()\n",
        "\n",
        "# Append data from val_df into arrays\n",
        "val_images = []\n",
        "val_boxes = []\n",
        "val_labels = []\n",
        "\n",
        "for index, row in val_df.iterrows():\n",
        "    image_path = row['Image Path']\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = resize_image(image, (224, 224))\n",
        "    val_images.append(image)\n",
        "\n",
        "    xmin, ymin, xmax, ymax = map(float, [row['Xmin'], row['Ymin'], row['Xmax'], row['Ymax']])\n",
        "    val_boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "    label = row['Class Name']\n",
        "    val_labels.append(label)\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "val_images = np.array(val_images, dtype='float32')\n",
        "val_boxes = np.array(val_boxes, dtype='float32')\n",
        "val_labels = np.array(val_labels)\n",
        "\n",
        "# Normalize the images\n",
        "val_images = val_images / 255.0\n",
        "\n",
        "\n",
        "\n",
        "# Append data from train_df into arrays\n",
        "train_images = []\n",
        "train_boxes = []\n",
        "train_labels = []\n",
        "\n",
        "for index, row in train_df.iterrows():\n",
        "    image_path = row['Image Path']\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = resize_image(image, (224, 224))\n",
        "    train_images.append(image)\n",
        "\n",
        "    xmin, ymin, xmax, ymax = map(float, [row['Xmin'], row['Ymin'], row['Xmax'], row['Ymax']])\n",
        "    train_boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "    label = row['Class Name']\n",
        "    train_labels.append(label)\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "train_images = np.array(train_images, dtype='float32')\n",
        "train_boxes = np.array(train_boxes, dtype='float32')\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "# Normalize the images\n",
        "train_images = train_images / 255.0\n",
        "\n",
        "\n",
        "\n",
        "# Append data from test_df into arrays\n",
        "test_images = []\n",
        "test_boxes = []\n",
        "test_labels = []\n",
        "\n",
        "for index, row in test_df.iterrows():\n",
        "    image_path = row['Image Path']\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = resize_image(image, (224, 224))\n",
        "    test_images.append(image)\n",
        "\n",
        "    xmin, ymin, xmax, ymax = map(float, [row['Xmin'], row['Ymin'], row['Xmax'], row['Ymax']])\n",
        "    test_boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "    label = row['Class Name']\n",
        "    test_labels.append(label)\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "test_images = np.array(test_images, dtype='float32')\n",
        "test_boxes = np.array(test_boxes, dtype='float32')\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "# Normalize the images\n",
        "test_images = test_images / 255.0\n"
      ],
      "metadata": {
        "id": "DTCVCXx-4rpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Perform label encoding on the target labels\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
        "val_labels_encoded = label_encoder.transform(val_labels)\n",
        "\n",
        "# Convert the encoded labels to one-hot encoding\n",
        "train_labels_onehot = to_categorical(train_labels_encoded, num_classes=100) ## ==> update number of classes\n",
        "val_labels_onehot = to_categorical(val_labels_encoded, num_classes=100) ## ==> update number of classes\n",
        "\n",
        "# Model architecture\n",
        "input_layer = Input(shape=(224, 224, 3))\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=input_layer)\n",
        "\n",
        "\n",
        "flatten = Flatten()(base_model.output)\n",
        "\n",
        "\n",
        "bboxHead = Dense(1024, activation=\"relu\")(flatten)\n",
        "\n",
        "bboxHead = Dense(512, activation=\"relu\")(bboxHead)\n",
        "\n",
        "bboxHead = Dense(256, activation=\"relu\")(bboxHead)\n",
        "\n",
        "bboxHead = Dense(128, activation=\"relu\")(bboxHead)\n",
        "\n",
        "bboxHead = Dense(64, activation=\"relu\")(bboxHead)\n",
        "\n",
        "bboxHead = Dense(32, activation=\"relu\")(bboxHead)\n",
        "\n",
        "bbox_output = Dense(4, activation='linear', name='bounding_box')(bboxHead)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "softmaxHead = Dense(1024, activation=\"relu\")(flatten)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "\n",
        "softmaxHead = Dense(512, activation=\"relu\")(softmaxHead)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "\n",
        "softmaxHead = Dense(256, activation=\"relu\")(softmaxHead)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "\n",
        "softmaxHead = Dense(128, activation=\"relu\")(softmaxHead)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "\n",
        "class_output = Dense(100, activation='softmax', name='class_output')(softmaxHead) ## ==> update number of classes\n",
        "\n",
        "\n",
        "\n",
        "model_resnet_mse_1 = Model(inputs=input_layer, outputs=[class_output, bbox_output])\n",
        "\n",
        "learning_rate = 1e-4\n",
        "\n",
        "# # Compile the model for training only the top layers\n",
        "# model_top_layers.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss=losses)\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model_resnet_mse_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss=losses)\n",
        "model_resnet_mse_1.summary()"
      ],
      "metadata": {
        "id": "ZPYiBABI7Khh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=7)\n",
        "\n",
        "\n",
        "# Train the model with early stopping\n",
        "model_resnet_mse_1_history = model_resnet_mse_1.fit(train_images, {'class_output': train_labels_onehot, 'bounding_box': train_boxes},\n",
        "                    validation_data=(val_images, {'class_output': val_labels_onehot, 'bounding_box': val_boxes}),\n",
        "                    epochs=300, batch_size=32, callbacks=[callback])\n",
        "\n",
        "## --> \"/content/drive/MyDrive/project_mark2\"\n",
        "\n",
        "# Save the trained model\n",
        "model_resnet_mse_1.save('/content/drive/MyDrive/project_mark2/model_resnet_mse_1_trained_model.h5')"
      ],
      "metadata": {
        "id": "vnJY4Skr9-ZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the label encoder\n",
        "with open('/content/drive/MyDrive/project_mark2/model_resnet_mse_1_label_encoder.pkl', 'wb') as file:\n",
        "    pickle.dump(label_encoder, file)"
      ],
      "metadata": {
        "id": "cwAvCpoW7-ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the losses\n",
        "plt.figure(figsize=(24, 12))\n",
        "plt.style.use('seaborn')\n",
        "\n",
        "# Classification Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(model_resnet_mse_1_history.history['class_output_loss'], label='Train Classification Loss', color='blue')\n",
        "plt.plot(model_resnet_mse_1_history.history['val_class_output_loss'], label='Validation Classification Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Classification Loss', fontsize=12)\n",
        "plt.legend()\n",
        "\n",
        "# Bounding Box Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(model_resnet_mse_1_history.history['bounding_box_loss'], label='Train Bounding Box Loss', color='blue')\n",
        "plt.plot(model_resnet_mse_1_history.history['val_bounding_box_loss'], label='Validation Bounding Box Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Bounding Box Loss', fontsize=12)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1houJfbe9xEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the history object to a file using pickle\n",
        "with open('model_resnet_mse_1_history.pkl', 'wb') as file:\n",
        "    pickle.dump(model_resnet_mse_1_history.history, file)"
      ],
      "metadata": {
        "id": "bNoiHSnYEnjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the entire model to a HDF5 file\n",
        "model_resnet_mse_1.save('/content/drive/MyDrive/project_mark2/model_resnet_mse_1.h5')"
      ],
      "metadata": {
        "id": "O0UP2bi2Eu1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the history object to a file using pickle\n",
        "with open('/content/drive/MyDrive/project_mark2/model_resnet_mse_1_history.pkl', 'wb') as file:\n",
        "    pickle.dump(model_resnet_mse_1_history.history, file)\n"
      ],
      "metadata": {
        "id": "7NjnGfY2FMhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x9xNSfnhF73n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **100 classes resnet50 - mse - trainable = false**"
      ],
      "metadata": {
        "id": "Ho5QxGu4GtBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Perform label encoding on the target labels\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
        "val_labels_encoded = label_encoder.transform(val_labels)\n",
        "\n",
        "# Convert the encoded labels to one-hot encoding\n",
        "train_labels_onehot = to_categorical(train_labels_encoded, num_classes=100) ## ==> update number of classes\n",
        "val_labels_onehot = to_categorical(val_labels_encoded, num_classes=100) ## ==> update number of classes\n",
        "\n",
        "# Model architecture\n",
        "input_layer = Input(shape=(224, 224, 3))\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=input_layer)\n",
        "\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "\n",
        "flatten = Flatten()(base_model.output)\n",
        "\n",
        "\n",
        "bboxHead = Dense(1024, activation=\"relu\")(flatten)\n",
        "\n",
        "bboxHead = Dense(512, activation=\"relu\")(bboxHead)\n",
        "\n",
        "bboxHead = Dense(256, activation=\"relu\")(bboxHead)\n",
        "\n",
        "bboxHead = Dense(128, activation=\"relu\")(bboxHead)\n",
        "\n",
        "bboxHead = Dense(64, activation=\"relu\")(bboxHead)\n",
        "\n",
        "bboxHead = Dense(32, activation=\"relu\")(bboxHead)\n",
        "\n",
        "bbox_output = Dense(4, activation='linear', name='bounding_box')(bboxHead)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "softmaxHead = Dense(1024, activation=\"relu\")(flatten)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "\n",
        "softmaxHead = Dense(512, activation=\"relu\")(softmaxHead)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "\n",
        "softmaxHead = Dense(256, activation=\"relu\")(softmaxHead)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "\n",
        "softmaxHead = Dense(128, activation=\"relu\")(softmaxHead)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "\n",
        "class_output = Dense(100, activation='softmax', name='class_output')(softmaxHead) ## ==> update number of classes\n",
        "\n",
        "\n",
        "\n",
        "model_resnet_mse_2 = Model(inputs=input_layer, outputs=[class_output, bbox_output])\n",
        "\n",
        "# Loss function --> defined in first experiment\n",
        "\n",
        "learning_rate = 1e-4\n",
        "\n",
        "# Compile the model\n",
        "model_resnet_mse_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss=losses)\n",
        "\n",
        "model_resnet_mse_2.summary()"
      ],
      "metadata": {
        "id": "SkBHsw_qG123"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## at least we understand how we are going to train them:"
      ],
      "metadata": {
        "id": "yutrZo6dI8v4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=7)\n",
        "\n",
        "\n",
        "# Train the model with early stopping\n",
        "model_resnet_mse_2_history = model_resnet_mse_2.fit(train_images, {'class_output': train_labels_onehot, 'bounding_box': train_boxes},\n",
        "                    validation_data=(val_images, {'class_output': val_labels_onehot, 'bounding_box': val_boxes}),\n",
        "                    epochs=300, batch_size=32, callbacks=[callback])\n",
        "\n",
        "# Save the trained model\n",
        "\n",
        "## --> \"/content/drive/MyDrive/project_mark2\"\n",
        "\n",
        "model_resnet_mse_2.save('/content/drive/MyDrive/project_mark2/model_resnet_mse_2_trained_model.h5')"
      ],
      "metadata": {
        "id": "RpYnwHjRHEgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the label encoder\n",
        "with open('/content/drive/MyDrive/project_mark2/model_resnet_mse_2_label_encoder.pkl', 'wb') as file:\n",
        "    pickle.dump(label_encoder, file)"
      ],
      "metadata": {
        "id": "hk5Gu_JZI1ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the losses\n",
        "plt.figure(figsize=(24, 12))\n",
        "plt.style.use('seaborn')\n",
        "\n",
        "# Classification Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(model_resnet_mse_2_history.history['class_output_loss'], label='Train Classification Loss', color='blue')\n",
        "plt.plot(model_resnet_mse_2_history.history['val_class_output_loss'], label='Validation Classification Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Classification Loss', fontsize=12)\n",
        "plt.legend()\n",
        "\n",
        "# Bounding Box Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(model_resnet_mse_2_history.history['bounding_box_loss'], label='Train Bounding Box Loss', color='blue')\n",
        "plt.plot(model_resnet_mse_2_history.history['val_bounding_box_loss'], label='Validation Bounding Box Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Bounding Box Loss', fontsize=12)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "l1t23Ed9I1po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the history object to a file using pickle\n",
        "with open('model_resnet_mse_2_history.pkl', 'wb') as file:\n",
        "    pickle.dump(model_resnet_mse_2_history.history, file)"
      ],
      "metadata": {
        "id": "XZOXo0s5J4z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the entire model to a HDF5 file\n",
        "model_resnet_mse_2.save('/content/drive/MyDrive/project_mark2/model_resnet_mse_2.h5')"
      ],
      "metadata": {
        "id": "8LjGZHKaKgT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the history object to a file using pickle\n",
        "with open('/content/drive/MyDrive/project_mark2/model_resnet_mse_2_history.pkl', 'wb') as file:\n",
        "    pickle.dump(model_resnet_mse_2_history.history, file)"
      ],
      "metadata": {
        "id": "0jAk3OkZKgRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h3PUA8XtLiZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **100 classes resnet50 - mse - trainable = false - then - trainable = true with lower learning rate**"
      ],
      "metadata": {
        "id": "eNoNnQJLLjNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Flatten, Dense, Dropout\n",
        "from keras.applications import ResNet50\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)            ### --> Canan Hocaya sor ???\n",
        "\n",
        "# Perform label encoding on the target labels\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
        "val_labels_encoded = label_encoder.transform(val_labels)\n",
        "\n",
        "# Convert the encoded labels to one-hot encoding\n",
        "num_classes = 100  # Update with the actual number of classes\n",
        "train_labels_onehot = to_categorical(train_labels_encoded, num_classes=num_classes)\n",
        "val_labels_onehot = to_categorical(val_labels_encoded, num_classes=num_classes)\n",
        "\n",
        "# Model architecture\n",
        "input_layer = Input(shape=(224, 224, 3))\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=input_layer)\n",
        "\n",
        "flatten = Flatten()(base_model.output)\n",
        "\n",
        "# Top layers for bounding box regression\n",
        "bboxHead = Dense(1024, activation=\"relu\")(flatten)\n",
        "bboxHead = Dense(512, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(256, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(128, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(64, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(32, activation=\"relu\")(bboxHead)\n",
        "bbox_output = Dense(4, activation='linear', name='bounding_box')(bboxHead)\n",
        "\n",
        "# Top layers for classification\n",
        "softmaxHead = Dense(1024, activation=\"relu\")(flatten)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "softmaxHead = Dense(512, activation=\"relu\")(softmaxHead)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "softmaxHead = Dense(256, activation=\"relu\")(softmaxHead)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "softmaxHead = Dense(128, activation=\"relu\")(softmaxHead)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "class_output = Dense(num_classes, activation='softmax', name='class_output')(softmaxHead)\n",
        "\n",
        "# Create the first model (train only the top layers)\n",
        "model_top_layers = Model(inputs=input_layer, outputs=[class_output, bbox_output])\n",
        "\n",
        "# Freeze the base model's layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "learning_rate = 1e-4\n",
        "\n",
        "# Compile the model for training only the top layers\n",
        "model_top_layers.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss=losses)\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=7)\n",
        "\n",
        "\n",
        "# Train only the top layers\n",
        "model_top_layers_history = model_top_layers.fit(train_images, {'class_output': train_labels_onehot, 'bounding_box': train_boxes},\n",
        "                                                validation_data=(val_images, {'class_output': val_labels_onehot, 'bounding_box': val_boxes}),\n",
        "                                                epochs=300, batch_size=32, callbacks=[callback])\n",
        "\n",
        "\n",
        "\n",
        "# Unfreeze the base model's layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "\n",
        "\n",
        "# Recompile the model with a smaller learning rate for fine-tuning\n",
        "learning_rate = 1e-5  # Update with the desired learning rate\n",
        "model_top_layers.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss=losses)              #### --> Canan Hocaya sor ???\n",
        "\n",
        "# Train the model with fine-tuning\n",
        "model_fine_tuned_history = model_top_layers.fit(train_images, {'class_output': train_labels_onehot, 'bounding_box': train_boxes},\n",
        "                                                validation_data=(val_images, {'class_output': val_labels_onehot, 'bounding_box': val_boxes}),\n",
        "                                                epochs=300, batch_size=32, callbacks=[callback])\n"
      ],
      "metadata": {
        "id": "oAd0GWg_Ls7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recompile the model with a smaller learning rate for fine-tuning\n",
        "learning_rate = 1e-5  # Update with the desired learning rate\n",
        "model_top_layers.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss=losses)              #### --> Canan Hocaya sor ???\n",
        "\n",
        "# Train the model with fine-tuning\n",
        "model_fine_tuned_history_2 = model_top_layers.fit(train_images, {'class_output': train_labels_onehot, 'bounding_box': train_boxes},\n",
        "                                                validation_data=(val_images, {'class_output': val_labels_onehot, 'bounding_box': val_boxes}),\n",
        "                                                epochs=500, batch_size=128, callbacks=[callback])\n"
      ],
      "metadata": {
        "id": "r7BvkUxyYsP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the label encoder\n",
        "with open('/content/drive/MyDrive/project_mark2/model_top_layers_label_encoder.pkl', 'wb') as file:\n",
        "    pickle.dump(label_encoder, file)\n",
        "\n",
        "# Save the entire model to a HDF5 file\n",
        "model_top_layers.save('/content/drive/MyDrive/project_mark2/model_top_layers.h5')\n",
        "\n",
        "# Save the history object to a file using pickle\n",
        "with open('/content/drive/MyDrive/project_mark2/model_fine_tuned_history_2.pkl', 'wb') as file:\n",
        "    pickle.dump(model_fine_tuned_history_2.history, file)"
      ],
      "metadata": {
        "id": "PBQ6Su3FMKtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the label encoder\n",
        "with open('/content/drive/MyDrive/project_mark2/model_top_layers_label_encoder.pkl', 'wb') as file:\n",
        "    pickle.dump(label_encoder, file)\n",
        "\n",
        "# Save the entire model to a HDF5 file\n",
        "model_top_layers.save('/content/drive/MyDrive/project_mark2/model_top_layers.h5')\n",
        "\n",
        "# Save the history object to a file using pickle\n",
        "with open('/content/drive/MyDrive/project_mark2/model_fine_tuned_history.pkl', 'wb') as file:\n",
        "    pickle.dump(model_fine_tuned_history_2.history, file)"
      ],
      "metadata": {
        "id": "xrn279wAcnVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the losses\n",
        "plt.figure(figsize=(24, 12))\n",
        "plt.style.use('seaborn')\n",
        "\n",
        "# Classification Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(model_fine_tuned_history_2.history['class_output_loss'], label='Train Classification Loss', color='blue')\n",
        "plt.plot(model_fine_tuned_history_2.history['val_class_output_loss'], label='Validation Classification Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Classification Loss', fontsize=12)\n",
        "plt.legend()\n",
        "\n",
        "# Bounding Box Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(model_fine_tuned_history_2.history['bounding_box_loss'], label='Train Bounding Box Loss', color='blue')\n",
        "plt.plot(model_fine_tuned_history_2.history['val_bounding_box_loss'], label='Validation Bounding Box Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Bounding Box Loss', fontsize=12)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "grr96XsPO1E3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the losses\n",
        "plt.figure(figsize=(24, 12))\n",
        "plt.style.use('seaborn')\n",
        "\n",
        "# Classification Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(model_fine_tuned_history.history['class_output_loss'], label='Train Classification Loss', color='blue')\n",
        "plt.plot(model_fine_tuned_history.history['val_class_output_loss'], label='Validation Classification Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Classification Loss', fontsize=12)\n",
        "plt.legend()\n",
        "\n",
        "# Bounding Box Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(model_fine_tuned_history.history['bounding_box_loss'], label='Train Bounding Box Loss', color='blue')\n",
        "plt.plot(model_fine_tuned_history.history['val_bounding_box_loss'], label='Validation Bounding Box Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Bounding Box Loss', fontsize=12)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n8AM87J_cr6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################\n",
        "################ MSE - 1 ######################\n",
        "###############################################"
      ],
      "metadata": {
        "id": "Vd50hiObV0yE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform predictions on the test data\n",
        "preds = model_resnet_mse_1.predict(test_images)\n",
        "pred_labels = label_encoder.inverse_transform(np.argmax(preds[0], axis=1))\n",
        "pred_boxes = preds[1]"
      ],
      "metadata": {
        "id": "24w2en6IQfU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# Calculate precision, recall, and F1 scores for each class\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_df[\"Class Name\"], pred_labels, average=None)\n"
      ],
      "metadata": {
        "id": "NZuf2AHbQ7EY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.patches as patches\n",
        "from sklearn.metrics import jaccard_score\n",
        "\n",
        "# Define a function to calculate the IoU score\n",
        "def calculate_iou(box1, box2):\n",
        "    # Extract coordinates from the bounding boxes\n",
        "    xmin1, ymin1, xmax1, ymax1 = box1\n",
        "    xmin2, ymin2, xmax2, ymax2 = box2\n",
        "\n",
        "    # Calculate the coordinates of the intersection rectangle\n",
        "    xmin_inter = max(xmin1, xmin2)\n",
        "    ymin_inter = max(ymin1, ymin2)\n",
        "    xmax_inter = min(xmax1, xmax2)\n",
        "    ymax_inter = min(ymax1, ymax2)\n",
        "\n",
        "    # Calculate the area of intersection rectangle\n",
        "    inter_area = max(0, xmax_inter - xmin_inter + 1) * max(0, ymax_inter - ymin_inter + 1)\n",
        "\n",
        "    # Calculate the areas of the bounding boxes\n",
        "    box1_area = (xmax1 - xmin1 + 1) * (ymax1 - ymin1 + 1)\n",
        "    box2_area = (xmax2 - xmin2 + 1) * (ymax2 - ymin2 + 1)\n",
        "\n",
        "    # Calculate the IoU score\n",
        "    iou = inter_area / float(box1_area + box2_area - inter_area)\n",
        "    return iou\n"
      ],
      "metadata": {
        "id": "dpIe_J63Rifs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate precision, recall, and F1 scores for each class\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_df[\"Class Name\"], pred_labels, average=None)\n",
        "\n",
        "# Calculate the mean F1 score\n",
        "mean_f1 = np.mean(f1)\n",
        "\n",
        "# Get the unique class labels and their counts\n",
        "classes, class_counts = np.unique(test_df[\"Class Name\"], return_counts=True)\n",
        "\n",
        "# Sort precision, recall, F1 scores, and class counts in descending order based on F1 scores\n",
        "sorted_indices = np.argsort(f1)[::-1]\n",
        "precision_sorted = precision[sorted_indices]\n",
        "recall_sorted = recall[sorted_indices]\n",
        "f1_sorted = f1[sorted_indices]\n",
        "classes_sorted = classes[sorted_indices]\n",
        "class_counts_sorted = class_counts[sorted_indices]\n",
        "\n",
        "# Calculate mean IoU score for each class\n",
        "class_iou_scores = []\n",
        "\n",
        "for class_label in classes_sorted:\n",
        "    class_indices = np.where(test_labels == class_label)[0]\n",
        "    class_pred_boxes = pred_boxes[class_indices]\n",
        "    class_test_boxes = test_boxes[class_indices]\n",
        "\n",
        "    iou_scores = []\n",
        "\n",
        "    for i in range(len(class_indices)):\n",
        "        iou_score = calculate_iou(class_test_boxes[i], class_pred_boxes[i])\n",
        "        iou_scores.append(iou_score)\n",
        "\n",
        "    mean_iou_score = np.mean(iou_scores)\n",
        "\n",
        "    class_iou_scores.append(mean_iou_score)\n",
        "\n",
        "# Sort the mean IoU scores from best to worst\n",
        "class_iou_scores_sorted = np.array(class_iou_scores)[sorted_indices]\n",
        "\n",
        "# Set the figure size and create subplots\n",
        "fig, ax = plt.subplots(figsize=(12, 12))\n",
        "\n",
        "# Set the width of the bars\n",
        "bar_width = 0.4\n",
        "\n",
        "# Plot the F1 scores\n",
        "f1_bars = ax.barh(np.arange(len(classes_sorted)), f1_sorted, height=bar_width, color='purple', label='F1 Score')\n",
        "\n",
        "# Plot the mean IoU scores\n",
        "iou_bars = ax.barh(np.arange(len(classes_sorted)) + bar_width, class_iou_scores_sorted, height=bar_width, color='blue', label='Mean IoU')\n",
        "\n",
        "# Add F1 scores as text inside each bar\n",
        "for i, (bar, score) in enumerate(zip(f1_bars, f1_sorted)):\n",
        "    ax.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height() / 2, f\"{score:.2f}\",\n",
        "            va='center', ha='left', fontsize=7, fontweight='bold', color='red')\n",
        "\n",
        "# Add mean IoU scores as text inside each bar\n",
        "for i, (bar, score) in enumerate(zip(iou_bars, class_iou_scores_sorted)):\n",
        "    ax.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height() / 2, f\"{score:.2f}\",\n",
        "            va='center', ha='left', fontsize=7, fontweight='bold', color='red')\n",
        "\n",
        "# Set y-axis ticks and labels\n",
        "ax.set_yticks(np.arange(len(classes_sorted)) + bar_width / 2)\n",
        "ax.set_yticklabels(classes_sorted, fontsize=7, fontweight='bold', color='black')\n",
        "\n",
        "# Set x-axis label and limits\n",
        "ax.set_xlabel('Scores', fontsize=7, color='red')\n",
        "ax.set_xlim(0, 1)\n",
        "\n",
        "# Add class counts as text near the class names\n",
        "for i, count in enumerate(class_counts_sorted):\n",
        "    ax.text(-0.1, i + bar_width / 2, f\"  ({count})\", va='center', ha='right', fontsize=7, fontweight='bold', color='red')\n",
        "\n",
        "# Set plot title\n",
        "ax.set_title('F1 Scores and Mean IoU Scores by Class', fontsize=14, fontweight='bold', color='red')\n",
        "\n",
        "# Remove spines and ticks\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['left'].set_visible(False)\n",
        "ax.spines['bottom'].set_visible(False)\n",
        "ax.tick_params(left=False, bottom=False)\n",
        "\n",
        "# Add a grid to the plot\n",
        "ax.grid(axis='x', color='lightgray', linestyle='--')\n",
        "\n",
        "# Show the legend\n",
        "ax.legend(loc='upper right', fontsize=7)\n",
        "\n",
        "# Invert the y-axis\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rS6C6cORQs7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# Calculate precision, recall, and F1 scores for each class\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_df[\"Class Name\"], pred_labels, average=None)\n",
        "\n",
        "# Calculate mean F1 score\n",
        "mean_f1 = np.mean(f1)\n",
        "\n",
        "# Get the unique class labels and their counts\n",
        "classes, class_counts = np.unique(test_df[\"Class Name\"], return_counts=True)\n",
        "\n",
        "# Sort precision, recall, F1 scores, and class counts in descending order based on F1 scores\n",
        "sorted_indices = np.argsort(f1)[::-1]\n",
        "precision_sorted = precision[sorted_indices]\n",
        "recall_sorted = recall[sorted_indices]\n",
        "f1_sorted = f1[sorted_indices]\n",
        "classes_sorted = classes[sorted_indices]\n",
        "class_counts_sorted = class_counts[sorted_indices]\n",
        "\n",
        "# Calculate mean IoU score for each class\n",
        "class_iou_scores = []\n",
        "\n",
        "for class_label in classes_sorted:\n",
        "    class_indices = np.where(test_labels == class_label)[0]\n",
        "    class_pred_boxes = pred_boxes[class_indices]\n",
        "    class_test_boxes = test_boxes[class_indices]\n",
        "\n",
        "    iou_scores = []\n",
        "\n",
        "    for i in range(len(class_indices)):\n",
        "        iou_score = calculate_iou(class_test_boxes[i], class_pred_boxes[i])\n",
        "        iou_scores.append(iou_score)\n",
        "\n",
        "    mean_iou_score = np.mean(iou_scores)\n",
        "\n",
        "    class_iou_scores.append(mean_iou_score)\n",
        "\n",
        "# Sort the mean IoU scores from best to worst\n",
        "class_iou_scores_sorted = np.array(class_iou_scores)[sorted_indices]\n",
        "\n",
        "# Create a DataFrame to store the results\n",
        "results_df_1 = pd.DataFrame({\n",
        "    'Class': classes_sorted,\n",
        "    'F1 Score': f1_sorted,\n",
        "    'Mean IoU': class_iou_scores_sorted,\n",
        "    'Class Count': class_counts_sorted\n",
        "})\n",
        "\n",
        "# Save the results to a CSV file\n",
        "results_df_1.to_csv('results_1.csv', index=False)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(results_df_1)"
      ],
      "metadata": {
        "id": "9WEfCLSlVkbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################################\n",
        "################## MSE -2 ################################"
      ],
      "metadata": {
        "id": "aXRw4Qy7Q499"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform predictions on the test data\n",
        "preds = model_resnet_mse_2.predict(test_images)\n",
        "pred_labels = label_encoder.inverse_transform(np.argmax(preds[0], axis=1))\n",
        "pred_boxes = preds[1]"
      ],
      "metadata": {
        "id": "asWuA9ezSGLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# Calculate precision, recall, and F1 scores for each class\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_df[\"Class Name\"], pred_labels, average=None)"
      ],
      "metadata": {
        "id": "FJSBl3XSSKCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate precision, recall, and F1 scores for each class\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_df[\"Class Name\"], pred_labels, average=None)\n",
        "\n",
        "# Calculate the mean F1 score\n",
        "mean_f1 = np.mean(f1)\n",
        "\n",
        "# Get the unique class labels and their counts\n",
        "classes, class_counts = np.unique(test_df[\"Class Name\"], return_counts=True)\n",
        "\n",
        "# Sort precision, recall, F1 scores, and class counts in descending order based on F1 scores\n",
        "sorted_indices = np.argsort(f1)[::-1]\n",
        "precision_sorted = precision[sorted_indices]\n",
        "recall_sorted = recall[sorted_indices]\n",
        "f1_sorted = f1[sorted_indices]\n",
        "classes_sorted = classes[sorted_indices]\n",
        "class_counts_sorted = class_counts[sorted_indices]\n",
        "\n",
        "# Calculate mean IoU score for each class\n",
        "class_iou_scores = []\n",
        "\n",
        "for class_label in classes_sorted:\n",
        "    class_indices = np.where(test_labels == class_label)[0]\n",
        "    class_pred_boxes = pred_boxes[class_indices]\n",
        "    class_test_boxes = test_boxes[class_indices]\n",
        "\n",
        "    iou_scores = []\n",
        "\n",
        "    for i in range(len(class_indices)):\n",
        "        iou_score = calculate_iou(class_test_boxes[i], class_pred_boxes[i])\n",
        "        iou_scores.append(iou_score)\n",
        "\n",
        "    mean_iou_score = np.mean(iou_scores)\n",
        "\n",
        "    class_iou_scores.append(mean_iou_score)\n",
        "\n",
        "# Sort the mean IoU scores from best to worst\n",
        "class_iou_scores_sorted = np.array(class_iou_scores)[sorted_indices]\n",
        "\n",
        "# Set the figure size and create subplots\n",
        "fig, ax = plt.subplots(figsize=(12, 12))\n",
        "\n",
        "# Set the width of the bars\n",
        "bar_width = 0.4\n",
        "\n",
        "# Plot the F1 scores\n",
        "f1_bars = ax.barh(np.arange(len(classes_sorted)), f1_sorted, height=bar_width, color='purple', label='F1 Score')\n",
        "\n",
        "# Plot the mean IoU scores\n",
        "iou_bars = ax.barh(np.arange(len(classes_sorted)) + bar_width, class_iou_scores_sorted, height=bar_width, color='blue', label='Mean IoU')\n",
        "\n",
        "# Add F1 scores as text inside each bar\n",
        "for i, (bar, score) in enumerate(zip(f1_bars, f1_sorted)):\n",
        "    ax.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height() / 2, f\"{score:.2f}\",\n",
        "            va='center', ha='left', fontsize=7, fontweight='bold', color='red')\n",
        "\n",
        "# Add mean IoU scores as text inside each bar\n",
        "for i, (bar, score) in enumerate(zip(iou_bars, class_iou_scores_sorted)):\n",
        "    ax.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height() / 2, f\"{score:.2f}\",\n",
        "            va='center', ha='left', fontsize=7, fontweight='bold', color='red')\n",
        "\n",
        "# Set y-axis ticks and labels\n",
        "ax.set_yticks(np.arange(len(classes_sorted)) + bar_width / 2)\n",
        "ax.set_yticklabels(classes_sorted, fontsize=7, fontweight='bold', color='black')\n",
        "\n",
        "# Set x-axis label and limits\n",
        "ax.set_xlabel('Scores', fontsize=7, color='red')\n",
        "ax.set_xlim(0, 1)\n",
        "\n",
        "# Add class counts as text near the class names\n",
        "for i, count in enumerate(class_counts_sorted):\n",
        "    ax.text(-0.1, i + bar_width / 2, f\"  ({count})\", va='center', ha='right', fontsize=7, fontweight='bold', color='red')\n",
        "\n",
        "# Set plot title\n",
        "ax.set_title('F1 Scores and Mean IoU Scores by Class', fontsize=14, fontweight='bold', color='red')\n",
        "\n",
        "# Remove spines and ticks\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['left'].set_visible(False)\n",
        "ax.spines['bottom'].set_visible(False)\n",
        "ax.tick_params(left=False, bottom=False)\n",
        "\n",
        "# Add a grid to the plot\n",
        "ax.grid(axis='x', color='lightgray', linestyle='--')\n",
        "\n",
        "# Show the legend\n",
        "ax.legend(loc='upper right', fontsize=7)\n",
        "\n",
        "# Invert the y-axis\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m2RkjseFSdrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# Calculate precision, recall, and F1 scores for each class\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_df[\"Class Name\"], pred_labels, average=None)\n",
        "\n",
        "# Calculate mean F1 score\n",
        "mean_f1 = np.mean(f1)\n",
        "\n",
        "# Get the unique class labels and their counts\n",
        "classes, class_counts = np.unique(test_df[\"Class Name\"], return_counts=True)\n",
        "\n",
        "# Sort precision, recall, F1 scores, and class counts in descending order based on F1 scores\n",
        "sorted_indices = np.argsort(f1)[::-1]\n",
        "precision_sorted = precision[sorted_indices]\n",
        "recall_sorted = recall[sorted_indices]\n",
        "f1_sorted = f1[sorted_indices]\n",
        "classes_sorted = classes[sorted_indices]\n",
        "class_counts_sorted = class_counts[sorted_indices]\n",
        "\n",
        "# Calculate mean IoU score for each class\n",
        "class_iou_scores = []\n",
        "\n",
        "for class_label in classes_sorted:\n",
        "    class_indices = np.where(test_labels == class_label)[0]\n",
        "    class_pred_boxes = pred_boxes[class_indices]\n",
        "    class_test_boxes = test_boxes[class_indices]\n",
        "\n",
        "    iou_scores = []\n",
        "\n",
        "    for i in range(len(class_indices)):\n",
        "        iou_score = calculate_iou(class_test_boxes[i], class_pred_boxes[i])\n",
        "        iou_scores.append(iou_score)\n",
        "\n",
        "    mean_iou_score = np.mean(iou_scores)\n",
        "\n",
        "    class_iou_scores.append(mean_iou_score)\n",
        "\n",
        "# Sort the mean IoU scores from best to worst\n",
        "class_iou_scores_sorted = np.array(class_iou_scores)[sorted_indices]\n",
        "\n",
        "# Create a DataFrame to store the results\n",
        "results_df_2 = pd.DataFrame({\n",
        "    'Class': classes_sorted,\n",
        "    'F1 Score': f1_sorted,\n",
        "    'Mean IoU': class_iou_scores_sorted,\n",
        "    'Class Count': class_counts_sorted\n",
        "})\n",
        "\n",
        "# Save the results to a CSV file\n",
        "results_df_2.to_csv('results_2.csv', index=False)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(results_df_2)"
      ],
      "metadata": {
        "id": "xU9XeyIZVq4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################\n",
        "###################### MSE -3 ##################################"
      ],
      "metadata": {
        "id": "pdjiMrFTVtWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform predictions on the test data\n",
        "preds = model_top_layers.predict(test_images)\n",
        "pred_labels = label_encoder.inverse_transform(np.argmax(preds[0], axis=1))\n",
        "pred_boxes = preds[1]"
      ],
      "metadata": {
        "id": "pLaH8NhDSlC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# Calculate precision, recall, and F1 scores for each class\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_df[\"Class Name\"], pred_labels, average=None)"
      ],
      "metadata": {
        "id": "s0vpPnZLSsc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate precision, recall, and F1 scores for each class\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_df[\"Class Name\"], pred_labels, average=None)\n",
        "\n",
        "# Calculate the mean F1 score\n",
        "mean_f1 = np.mean(f1)\n",
        "\n",
        "# Get the unique class labels and their counts\n",
        "classes, class_counts = np.unique(test_df[\"Class Name\"], return_counts=True)\n",
        "\n",
        "# Sort precision, recall, F1 scores, and class counts in descending order based on F1 scores\n",
        "sorted_indices = np.argsort(f1)[::-1]\n",
        "precision_sorted = precision[sorted_indices]\n",
        "recall_sorted = recall[sorted_indices]\n",
        "f1_sorted = f1[sorted_indices]\n",
        "classes_sorted = classes[sorted_indices]\n",
        "class_counts_sorted = class_counts[sorted_indices]\n",
        "\n",
        "# Calculate mean IoU score for each class\n",
        "class_iou_scores = []\n",
        "\n",
        "for class_label in classes_sorted:\n",
        "    class_indices = np.where(test_labels == class_label)[0]\n",
        "    class_pred_boxes = pred_boxes[class_indices]\n",
        "    class_test_boxes = test_boxes[class_indices]\n",
        "\n",
        "    iou_scores = []\n",
        "\n",
        "    for i in range(len(class_indices)):\n",
        "        iou_score = calculate_iou(class_test_boxes[i], class_pred_boxes[i])\n",
        "        iou_scores.append(iou_score)\n",
        "\n",
        "    mean_iou_score = np.mean(iou_scores)\n",
        "\n",
        "    class_iou_scores.append(mean_iou_score)\n",
        "\n",
        "# Sort the mean IoU scores from best to worst\n",
        "class_iou_scores_sorted = np.array(class_iou_scores)[sorted_indices]\n",
        "\n",
        "# Set the figure size and create subplots\n",
        "fig, ax = plt.subplots(figsize=(12, 12))\n",
        "\n",
        "# Set the width of the bars\n",
        "bar_width = 0.4\n",
        "\n",
        "# Plot the F1 scores\n",
        "f1_bars = ax.barh(np.arange(len(classes_sorted)), f1_sorted, height=bar_width, color='purple', label='F1 Score')\n",
        "\n",
        "# Plot the mean IoU scores\n",
        "iou_bars = ax.barh(np.arange(len(classes_sorted)) + bar_width, class_iou_scores_sorted, height=bar_width, color='blue', label='Mean IoU')\n",
        "\n",
        "# Add F1 scores as text inside each bar\n",
        "for i, (bar, score) in enumerate(zip(f1_bars, f1_sorted)):\n",
        "    ax.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height() / 2, f\"{score:.2f}\",\n",
        "            va='center', ha='left', fontsize=7, fontweight='bold', color='red')\n",
        "\n",
        "# Add mean IoU scores as text inside each bar\n",
        "for i, (bar, score) in enumerate(zip(iou_bars, class_iou_scores_sorted)):\n",
        "    ax.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height() / 2, f\"{score:.2f}\",\n",
        "            va='center', ha='left', fontsize=7, fontweight='bold', color='red')\n",
        "\n",
        "# Set y-axis ticks and labels\n",
        "ax.set_yticks(np.arange(len(classes_sorted)) + bar_width / 2)\n",
        "ax.set_yticklabels(classes_sorted, fontsize=7, fontweight='bold', color='black')\n",
        "\n",
        "# Set x-axis label and limits\n",
        "ax.set_xlabel('Scores', fontsize=7, color='red')\n",
        "ax.set_xlim(0, 1)\n",
        "\n",
        "# Add class counts as text near the class names\n",
        "for i, count in enumerate(class_counts_sorted):\n",
        "    ax.text(-0.1, i + bar_width / 2, f\"  ({count})\", va='center', ha='right', fontsize=7, fontweight='bold', color='red')\n",
        "\n",
        "# Set plot title\n",
        "ax.set_title('F1 Scores and Mean IoU Scores by Class', fontsize=14, fontweight='bold', color='red')\n",
        "\n",
        "# Remove spines and ticks\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['left'].set_visible(False)\n",
        "ax.spines['bottom'].set_visible(False)\n",
        "ax.tick_params(left=False, bottom=False)\n",
        "\n",
        "# Add a grid to the plot\n",
        "ax.grid(axis='x', color='lightgray', linestyle='--')\n",
        "\n",
        "# Show the legend\n",
        "ax.legend(loc='upper right', fontsize=7)\n",
        "\n",
        "# Invert the y-axis\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QLRpY2htSw0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# Calculate precision, recall, and F1 scores for each class\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_df[\"Class Name\"], pred_labels, average=None)\n",
        "\n",
        "# Calculate mean F1 score\n",
        "mean_f1 = np.mean(f1)\n",
        "\n",
        "# Get the unique class labels and their counts\n",
        "classes, class_counts = np.unique(test_df[\"Class Name\"], return_counts=True)\n",
        "\n",
        "# Sort precision, recall, F1 scores, and class counts in descending order based on F1 scores\n",
        "sorted_indices = np.argsort(f1)[::-1]\n",
        "precision_sorted = precision[sorted_indices]\n",
        "recall_sorted = recall[sorted_indices]\n",
        "f1_sorted = f1[sorted_indices]\n",
        "classes_sorted = classes[sorted_indices]\n",
        "class_counts_sorted = class_counts[sorted_indices]\n",
        "\n",
        "# Calculate mean IoU score for each class\n",
        "class_iou_scores = []\n",
        "\n",
        "for class_label in classes_sorted:\n",
        "    class_indices = np.where(test_labels == class_label)[0]\n",
        "    class_pred_boxes = pred_boxes[class_indices]\n",
        "    class_test_boxes = test_boxes[class_indices]\n",
        "\n",
        "    iou_scores = []\n",
        "\n",
        "    for i in range(len(class_indices)):\n",
        "        iou_score = calculate_iou(class_test_boxes[i], class_pred_boxes[i])\n",
        "        iou_scores.append(iou_score)\n",
        "\n",
        "    mean_iou_score = np.mean(iou_scores)\n",
        "\n",
        "    class_iou_scores.append(mean_iou_score)\n",
        "\n",
        "# Sort the mean IoU scores from best to worst\n",
        "class_iou_scores_sorted = np.array(class_iou_scores)[sorted_indices]\n",
        "\n",
        "# Create a DataFrame to store the results\n",
        "results_df_3 = pd.DataFrame({\n",
        "    'Class': classes_sorted,\n",
        "    'F1 Score': f1_sorted,\n",
        "    'Mean IoU': class_iou_scores_sorted,\n",
        "    'Class Count': class_counts_sorted\n",
        "})\n",
        "\n",
        "# Save the results to a CSV file\n",
        "results_df_3.to_csv('results_3.csv', index=False)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(results_df_3)"
      ],
      "metadata": {
        "id": "GKDcLdZdUQIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df_3"
      ],
      "metadata": {
        "id": "LC65q3MFVLXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "source_file = \"/content/results_3.csv\"\n",
        "destination_folder = \"/content/drive/MyDrive/project_mark2/\"\n",
        "\n",
        "shutil.copy(source_file, destination_folder)"
      ],
      "metadata": {
        "id": "H7qxy7u6XazP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_file = \"/content/results_2.csv\"\n",
        "destination_folder = \"/content/drive/MyDrive/project_mark2/\"\n",
        "\n",
        "shutil.copy(source_file, destination_folder)"
      ],
      "metadata": {
        "id": "8LH5z50IXv5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_file = \"/content/results_1.csv\"\n",
        "destination_folder = \"/content/drive/MyDrive/project_mark2/\"\n",
        "\n",
        "shutil.copy(source_file, destination_folder)"
      ],
      "metadata": {
        "id": "T3LBOXAEXvY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('results_3.csv')\n",
        "\n",
        "# Multiply the count column by 5\n",
        "df['Class Count'] = df['Class Count'] * 5\n",
        "\n",
        "# Define the image count ranges\n",
        "ranges = [\n",
        "    (0, 100),\n",
        "    (100, 250),\n",
        "    (250, 450),\n",
        "    (450, float('inf'))\n",
        "]\n",
        "\n",
        "# Create a mapping for the summarized classes\n",
        "class_mapping = {\n",
        "    0: 'Class 0-100',\n",
        "    1: 'Class 100-250',\n",
        "    2: 'Class 250-450',\n",
        "    3: 'Class 450+'\n",
        "}\n",
        "\n",
        "# Create an empty DataFrame for the new CSV\n",
        "new_df = pd.DataFrame(columns=['Class', 'Image Count Range', 'Mean IoU', 'Mean F1', 'Total Images'])\n",
        "\n",
        "# Calculate the mean scores and total images for each summarized class and image count range\n",
        "for i, (start, end) in enumerate(ranges):\n",
        "    filtered_df = df[(df['Class Count'] >= start) & (df['Class Count'] < end)]\n",
        "    mean_iou = filtered_df['Mean IoU'].mean()\n",
        "    mean_f1 = filtered_df['F1 Score'].mean()\n",
        "    total_images = filtered_df['Class Count'].sum()\n",
        "    new_df.loc[i] = [class_mapping[i], f'{start} - {end}', mean_iou, mean_f1, total_images]\n",
        "\n",
        "# Save the new DataFrame to a CSV file\n",
        "new_df.to_csv('outputs_3_iou.csv', index=False)\n"
      ],
      "metadata": {
        "id": "Mn2AG_EnXzaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.head()"
      ],
      "metadata": {
        "id": "rAkri82zBVXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('outputs_3_iou.csv')\n",
        "\n",
        "# Set the plot style using Seaborn\n",
        "sns.set(style='whitegrid')\n",
        "\n",
        "# Set the color palette\n",
        "colors = ['#6C8EBF', '#A1C1D9']\n",
        "\n",
        "# Create a figure and axes\n",
        "fig, ax = plt.subplots(figsize=(12, 14))\n",
        "\n",
        "# Plot the mean IoU and mean F1 scores\n",
        "df.plot(x='Class', y=['Mean IoU', 'Mean F1'], kind='bar', ax=ax, rot=0, legend=True, color=colors)\n",
        "\n",
        "# Set the title and axis labels\n",
        "ax.set_title('Mean IoU and Mean F1 Scores by Class (Top then Full Training // Loss = \"MSE\")', fontsize=16, fontweight='bold')\n",
        "ax.set_xlabel('Class', fontsize=14)\n",
        "ax.set_ylabel('Score', fontsize=12)\n",
        "\n",
        "# Customize the tick labels and font size\n",
        "ax.tick_params(axis='x', labelrotation=45, labelsize=10)\n",
        "ax.tick_params(axis='y', labelsize=10)\n",
        "\n",
        "# Set the legend\n",
        "ax.legend(['Mean IoU', 'Mean F1'], loc='upper right', fontsize=10)\n",
        "\n",
        "# Add data labels to the bars\n",
        "for p in ax.patches:\n",
        "    x = p.get_x() + p.get_width() / 2.\n",
        "    y = p.get_height()\n",
        "    ax.annotate(f'{y:.3f}', (x, y), ha='center', va='center', xytext=(0, 5), textcoords='offset points', fontsize=10, fontweight='bold')\n",
        "\n",
        "# Remove the top and right spines\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "\n",
        "# Add a horizontal grid\n",
        "ax.yaxis.grid(True, linestyle='dashed')\n",
        "\n",
        "# Adjust the layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "sH4U4Y8f--mQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('results_2.csv')\n",
        "\n",
        "# Multiply the count column by 5\n",
        "df['Class Count'] = df['Class Count'] * 5\n",
        "\n",
        "# Define the image count ranges\n",
        "ranges = [\n",
        "    (0, 100),\n",
        "    (100, 250),\n",
        "    (250, 450),\n",
        "    (450, float('inf'))\n",
        "]\n",
        "\n",
        "# Create a mapping for the summarized classes\n",
        "class_mapping = {\n",
        "    0: 'Class 0-100',\n",
        "    1: 'Class 100-250',\n",
        "    2: 'Class 250-450',\n",
        "    3: 'Class 450+'\n",
        "}\n",
        "\n",
        "# Create an empty DataFrame for the new CSV\n",
        "new_df = pd.DataFrame(columns=['Class', 'Image Count Range', 'Mean IoU', 'Mean F1', 'Total Images'])\n",
        "\n",
        "# Calculate the mean scores and total images for each summarized class and image count range\n",
        "for i, (start, end) in enumerate(ranges):\n",
        "    filtered_df = df[(df['Class Count'] >= start) & (df['Class Count'] < end)]\n",
        "    mean_iou = filtered_df['Mean IoU'].mean()\n",
        "    mean_f1 = filtered_df['F1 Score'].mean()\n",
        "    total_images = filtered_df['Class Count'].sum()\n",
        "    new_df.loc[i] = [class_mapping[i], f'{start} - {end}', mean_iou, mean_f1, total_images]\n",
        "\n",
        "# Save the new DataFrame to a CSV file\n",
        "new_df.to_csv('outputs_2_iou.csv', index=False)\n"
      ],
      "metadata": {
        "id": "hWwA8R-s_ACB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('outputs_2_iou.csv')\n",
        "\n",
        "# Set the plot style using Seaborn\n",
        "sns.set(style='whitegrid')\n",
        "\n",
        "# Set the color palette\n",
        "colors = ['#6C8EBF', '#A1C1D9']\n",
        "\n",
        "# Create a figure and axes\n",
        "fig, ax = plt.subplots(figsize=(12, 14))\n",
        "\n",
        "# Plot the mean IoU and mean F1 scores\n",
        "df.plot(x='Class', y=['Mean IoU', 'Mean F1'], kind='bar', ax=ax, rot=0, legend=True, color=colors)\n",
        "\n",
        "# Set the title and axis labels\n",
        "ax.set_title('Mean IoU and Mean F1 Scores by Class (Top-only Training // Loss = \"MSE\")', fontsize=16, fontweight='bold')\n",
        "ax.set_xlabel('Class', fontsize=14)\n",
        "ax.set_ylabel('Score', fontsize=12)\n",
        "\n",
        "# Customize the tick labels and font size\n",
        "ax.tick_params(axis='x', labelrotation=45, labelsize=10)\n",
        "ax.tick_params(axis='y', labelsize=10)\n",
        "\n",
        "# Set the legend\n",
        "ax.legend(['Mean IoU', 'Mean F1'], loc='upper right', fontsize=10)\n",
        "\n",
        "# Add data labels to the bars\n",
        "for p in ax.patches:\n",
        "    x = p.get_x() + p.get_width() / 2.\n",
        "    y = p.get_height()\n",
        "    ax.annotate(f'{y:.3f}', (x, y), ha='center', va='center', xytext=(0, 5), textcoords='offset points', fontsize=10, fontweight='bold')\n",
        "\n",
        "# Remove the top and right spines\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "\n",
        "# Add a horizontal grid\n",
        "ax.yaxis.grid(True, linestyle='dashed')\n",
        "\n",
        "# Adjust the layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "N-NQ3oeGC4jK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('results_1.csv')\n",
        "\n",
        "# Multiply the count column by 5\n",
        "df['Class Count'] = df['Class Count'] * 5\n",
        "\n",
        "# Define the image count ranges\n",
        "ranges = [\n",
        "    (0, 100),\n",
        "    (100, 250),\n",
        "    (250, 450),\n",
        "    (450, float('inf'))\n",
        "]\n",
        "\n",
        "# Create a mapping for the summarized classes\n",
        "class_mapping = {\n",
        "    0: 'Class 0-100',\n",
        "    1: 'Class 100-250',\n",
        "    2: 'Class 250-450',\n",
        "    3: 'Class 450+'\n",
        "}\n",
        "\n",
        "# Create an empty DataFrame for the new CSV\n",
        "new_df = pd.DataFrame(columns=['Class', 'Image Count Range', 'Mean IoU', 'Mean F1', 'Total Images'])\n",
        "\n",
        "# Calculate the mean scores and total images for each summarized class and image count range\n",
        "for i, (start, end) in enumerate(ranges):\n",
        "    filtered_df = df[(df['Class Count'] >= start) & (df['Class Count'] < end)]\n",
        "    mean_iou = filtered_df['Mean IoU'].mean()\n",
        "    mean_f1 = filtered_df['F1 Score'].mean()\n",
        "    total_images = filtered_df['Class Count'].sum()\n",
        "    new_df.loc[i] = [class_mapping[i], f'{start} - {end}', mean_iou, mean_f1, total_images]\n",
        "\n",
        "# Save the new DataFrame to a CSV file\n",
        "new_df.to_csv('outputs_1_iou.csv', index=False)\n"
      ],
      "metadata": {
        "id": "tyRPp8GVC91K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('outputs_1_iou.csv')\n",
        "\n",
        "# Set the plot style using Seaborn\n",
        "sns.set(style='whitegrid')\n",
        "\n",
        "# Set the color palette\n",
        "colors = ['#6C8EBF', '#A1C1D9']\n",
        "\n",
        "# Create a figure and axes\n",
        "fig, ax = plt.subplots(figsize=(12, 14))\n",
        "\n",
        "# Plot the mean IoU and mean F1 scores\n",
        "df.plot(x='Class', y=['Mean IoU', 'Mean F1'], kind='bar', ax=ax, rot=0, legend=True, color=colors)\n",
        "\n",
        "# Set the title and axis labels\n",
        "ax.set_title('Mean IoU and Mean F1 Scores by Class (Full Training // Loss = \"MSE\")', fontsize=16, fontweight='bold')\n",
        "ax.set_xlabel('Class', fontsize=14)\n",
        "ax.set_ylabel('Score', fontsize=12)\n",
        "\n",
        "# Customize the tick labels and font size\n",
        "ax.tick_params(axis='x', labelrotation=45, labelsize=10)\n",
        "ax.tick_params(axis='y', labelsize=10)\n",
        "\n",
        "# Set the legend\n",
        "ax.legend(['Mean IoU', 'Mean F1'], loc='upper right', fontsize=10)\n",
        "\n",
        "# Add data labels to the bars\n",
        "for p in ax.patches:\n",
        "    x = p.get_x() + p.get_width() / 2.\n",
        "    y = p.get_height()\n",
        "    ax.annotate(f'{y:.3f}', (x, y), ha='center', va='center', xytext=(0, 5), textcoords='offset points', fontsize=10, fontweight='bold')\n",
        "\n",
        "# Remove the top and right spines\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "\n",
        "# Add a horizontal grid\n",
        "ax.yaxis.grid(True, linestyle='dashed')\n",
        "\n",
        "# Adjust the layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "c4-c_mQ-DBaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "source_file = \"/content/outputs_3_iou.csv\"\n",
        "destination_folder = \"/content/drive/MyDrive/project_mark2/\"\n",
        "\n",
        "shutil.copy(source_file, destination_folder)"
      ],
      "metadata": {
        "id": "JTA2f9GWDIw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "source_file = \"/content/outputs_2_iou.csv\"\n",
        "destination_folder = \"/content/drive/MyDrive/project_mark2/\"\n",
        "\n",
        "shutil.copy(source_file, destination_folder)"
      ],
      "metadata": {
        "id": "RTJnqHukDujH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "source_file = \"/content/outputs_1_iou.csv\"\n",
        "destination_folder = \"/content/drive/MyDrive/project_mark2/\"\n",
        "\n",
        "shutil.copy(source_file, destination_folder)"
      ],
      "metadata": {
        "id": "s0du_lMfDucR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Save test_carside_df to CSV\n",
        "# test_carside_df.to_csv(os.path.join(parent_dir, \"test_carside_df.csv\"), index=False)\n",
        "\n",
        "# # Save val_carside_df to CSV\n",
        "# val_carside_df.to_csv(os.path.join(parent_dir, \"val_carside_df.csv\"), index=False)\n",
        "\n",
        "# # Save carside_df to CSV\n",
        "# carside_df.to_csv(os.path.join(parent_dir, \"carside_df.csv\"), index=False)\n"
      ],
      "metadata": {
        "id": "KzBcHBghEM2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/project_mark2/test_carside_df.csv'\n",
        "test_carside_df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "2dQ070DHh9F4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/project_mark2/val_carside_df.csv'\n",
        "val_carside_df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "kB7bkxFSh877"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/project_mark2/carside_df.csv'\n",
        "carside_df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "KDo8xcFgh85T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = ['Image Path', 'Class Name', 'Image Name', 'Bounding Box', 'Height', 'Width', 'label',\n",
        "                'normalized', 'Xmin', 'Ymin', 'Xmax', 'Ymax']\n",
        "\n",
        "\n",
        "test_carside_df.columns = column_names\n",
        "val_carside_df.columns = column_names\n",
        "carside_df.columns = column_names"
      ],
      "metadata": {
        "id": "TFcfGNNqFhAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "    image = image.astype(np.float32) / 255.0\n",
        "    return image"
      ],
      "metadata": {
        "id": "IqWKn78fFg-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_images_with_bboxes(df):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
        "    for i, row in df.head(5).iterrows():\n",
        "        image_path = row['Image Path']\n",
        "        class_name = row['Class Name']\n",
        "        image_name = row['Image Name']\n",
        "        xmin, ymin, xmax, ymax = row['Xmin']*224, row['Ymin']*224, row['Xmax']*224, row['Ymax']*224\n",
        "\n",
        "        image = load_image(image_path)\n",
        "\n",
        "        ax = axes[i]\n",
        "        ax.imshow(image)\n",
        "        ax.axis('off')\n",
        "\n",
        "        # Add bounding box\n",
        "        bbox = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, linewidth=2, edgecolor='r', facecolor='none')\n",
        "        ax.add_patch(bbox)\n",
        "\n",
        "        ax.set_title(f'Class: {class_name}\\nImage: {image_name}')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Plot images with bounding boxes for val_df, test_df, train_df\n",
        "plot_images_with_bboxes(val_carside_df)\n",
        "plot_images_with_bboxes(test_carside_df)\n",
        "plot_images_with_bboxes(carside_df)"
      ],
      "metadata": {
        "id": "06UTdlpxGFpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####################################################\n",
        "############## MOST IMPORTANT PART #################\n",
        "####################################################\n",
        "def resize_image(image, target_size):\n",
        "    return cv2.resize(image, target_size)\n",
        "\n",
        "def plot_images(images, boxes, labels, dataset_name):\n",
        "    fig, axes = plt.subplots(1, len(images), figsize=(12, 4))\n",
        "    for i, ax in enumerate(axes):\n",
        "        ax.imshow(images[i])\n",
        "        xmin, ymin, xmax, ymax = boxes[i]\n",
        "        ax.add_patch(plt.Rectangle((xmin*224, ymin*224), xmax*224 - xmin*224, ymax*224 - ymin*224, fill=False, color='red', linewidth=2))\n",
        "        ax.set_title(labels[i])\n",
        "        ax.axis('off')\n",
        "    plt.suptitle(f'{dataset_name} Images with Bounding Boxes')\n",
        "    plt.show()\n",
        "\n",
        "# Append data from val_df into arrays\n",
        "val_images = []\n",
        "val_boxes = []\n",
        "val_labels = []\n",
        "\n",
        "for index, row in val_carside_df.iterrows():\n",
        "    image_path = row['Image Path']\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = resize_image(image, (224, 224))\n",
        "    val_images.append(image)\n",
        "\n",
        "    xmin, ymin, xmax, ymax = map(float, [row['Xmin'], row['Ymin'], row['Xmax'], row['Ymax']])\n",
        "    val_boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "    label = row['Class Name']\n",
        "    val_labels.append(label)\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "val_images = np.array(val_images, dtype='float32')\n",
        "val_boxes = np.array(val_boxes, dtype='float32')\n",
        "val_labels = np.array(val_labels)\n",
        "\n",
        "# Normalize the images\n",
        "val_images = val_images / 255.0\n",
        "\n",
        "\n",
        "\n",
        "# Append data from train_df into arrays\n",
        "train_images = []\n",
        "train_boxes = []\n",
        "train_labels = []\n",
        "\n",
        "for index, row in carside_df.iterrows():\n",
        "    image_path = row['Image Path']\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = resize_image(image, (224, 224))\n",
        "    train_images.append(image)\n",
        "\n",
        "    xmin, ymin, xmax, ymax = map(float, [row['Xmin'], row['Ymin'], row['Xmax'], row['Ymax']])\n",
        "    train_boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "    label = row['Class Name']\n",
        "    train_labels.append(label)\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "train_images = np.array(train_images, dtype='float32')\n",
        "train_boxes = np.array(train_boxes, dtype='float32')\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "# Normalize the images\n",
        "train_images = train_images / 255.0\n",
        "\n",
        "\n",
        "\n",
        "# Append data from test_df into arrays\n",
        "test_images = []\n",
        "test_boxes = []\n",
        "test_labels = []\n",
        "\n",
        "for index, row in test_carside_df.iterrows():\n",
        "    image_path = row['Image Path']\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = resize_image(image, (224, 224))\n",
        "    test_images.append(image)\n",
        "\n",
        "    xmin, ymin, xmax, ymax = map(float, [row['Xmin'], row['Ymin'], row['Xmax'], row['Ymax']])\n",
        "    test_boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "    label = row['Class Name']\n",
        "    test_labels.append(label)\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "test_images = np.array(test_images, dtype='float32')\n",
        "test_boxes = np.array(test_boxes, dtype='float32')\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "# Normalize the images\n",
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "id": "R_eXq2LdGNjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"len -- val images: \", len(val_images))\n",
        "print(\"len -- test images: \", len(test_images))\n",
        "print(\"len -- train images: \", len(train_images))\n",
        "\n",
        "\n",
        "print(\"type -- test images: \", type(test_images))\n",
        "print(\"type -- train images: \", type(train_images))\n",
        "print(\"type -- val images: \", type(val_images))\n"
      ],
      "metadata": {
        "id": "Vc3BJVgYqNNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"shape test_boxes: \", test_boxes.shape)\n",
        "print(\"shape val_boxes: \", val_boxes.shape)\n",
        "print(\"shape train_boxes: \", train_boxes.shape)\n"
      ],
      "metadata": {
        "id": "ZRCilaWfq9nB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels"
      ],
      "metadata": {
        "id": "W-uIJ6PyrgDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels"
      ],
      "metadata": {
        "id": "RYhfD-Fksu4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_boxes"
      ],
      "metadata": {
        "id": "w7lZwwOOtENn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Carside -- Imagenet Trainable = False Test - IoU**"
      ],
      "metadata": {
        "id": "bxu5M4YJxTg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "Oc558l8Pw3Kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "test_images = np.array(test_images, dtype='float32')\n",
        "test_boxes = np.array(test_boxes, dtype='float32')\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "train_images = np.array(train_images, dtype='float32')\n",
        "train_boxes = np.array(train_boxes, dtype='float32')\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "val_images = np.array(val_images, dtype='float32')\n",
        "val_boxes = np.array(val_boxes, dtype='float32')\n",
        "val_labels = np.array(val_labels)"
      ],
      "metadata": {
        "id": "yzLoxTPJwELc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform label encoding on the target labels\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
        "val_labels_encoded = label_encoder.transform(val_labels)\n",
        "test_labels_encoded = label_encoder.transform(test_labels)\n",
        "\n",
        "# Convert the encoded labels to one-hot encoding\n",
        "num_classes = len(label_encoder.classes_)\n",
        "train_labels_onehot = to_categorical(train_labels_encoded, num_classes=num_classes)\n",
        "val_labels_onehot = to_categorical(val_labels_encoded, num_classes=num_classes)\n",
        "test_labels_onehot = to_categorical(test_labels_encoded, num_classes=num_classes)\n"
      ],
      "metadata": {
        "id": "S9DnCWEgvUVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model architecture\n",
        "input_layer = Input(shape=(224, 224, 3))\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=input_layer)\n",
        "\n",
        "\n",
        "flatten = Flatten()(base_model.output)\n",
        "\n",
        "bboxHead = Dense(1024, activation=\"relu\")(flatten)\n",
        "bboxHead = Dense(512, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(256, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(128, activation=\"relu\")(bboxHead)\n",
        "bbox_output = Dense(4, activation='linear', name='bbox_output')(bboxHead)\n",
        "\n",
        "\n",
        "\n",
        "carside_test_1 = Model(inputs=input_layer, outputs=[bbox_output])\n"
      ],
      "metadata": {
        "id": "fiw0N8wPxDhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "losses = {\n",
        "    'bbox_output': 'mse'\n",
        "}"
      ],
      "metadata": {
        "id": "Xy95yXiHekBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-4\n",
        "\n",
        "carside_test_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss=losses)\n",
        "\n",
        "carside_test_1.summary()"
      ],
      "metadata": {
        "id": "0CK_VXAAxF54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=7)\n",
        "\n",
        "carside_test_1_history  = carside_test_1.fit(train_images, {'bbox_output': train_boxes},\n",
        "                                                   validation_data=(val_images, {'bbox_output': val_boxes}),\n",
        "                                                   epochs=300, batch_size=32, callbacks=[callback])"
      ],
      "metadata": {
        "id": "hoDFAX2xxJIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get the loss values from the history object\n",
        "loss = carside_test_1_history.history['loss']\n",
        "val_loss = carside_test_1_history.history['val_loss']\n",
        "\n",
        "# Plot the loss and validation loss\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.semilogy(epochs, loss, 'b', label='Training Loss')\n",
        "plt.semilogy(epochs, val_loss, 'r', label='Validation Loss')\n",
        "\n",
        "# Customize the plot appearance\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.xticks(fontsize=8)\n",
        "plt.yticks(fontsize=8)\n",
        "plt.legend()\n",
        "\n",
        "# Add labels to the first and last data points\n",
        "plt.text(1, loss[0], f'{loss[0]:.4f}', ha='center', va='bottom', fontsize=8, color='b')\n",
        "plt.text(1, val_loss[0], f'{val_loss[0]:.4f}', ha='center', va='top', fontsize=8, color='r')\n",
        "plt.text(len(loss), loss[-1], f'{loss[-1]:.4f}', ha='center', va='bottom', fontsize=8, color='b')\n",
        "plt.text(len(val_loss), val_loss[-1], f'{val_loss[-1]:.4f}', ha='center', va='top', fontsize=8, color='r')\n",
        "\n",
        "# Plot markers for the first and last data points\n",
        "plt.plot(1, loss[0], marker='o', markersize=4, color='b')\n",
        "plt.plot(1, val_loss[0], marker='o', markersize=4, color='r')\n",
        "plt.plot(len(loss), loss[-1], marker='o', markersize=4, color='b')\n",
        "plt.plot(len(val_loss), val_loss[-1], marker='o', markersize=4, color='r')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CNkdX_X1CM-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "carside_test_1.save('/content/drive/MyDrive/project_mark2/carside_test_1_model.h5')"
      ],
      "metadata": {
        "id": "q0ns4tvDDTWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the history\n",
        "with open('/content/drive/MyDrive/project_mark2/carside_test_1_history.pkl', 'wb') as file:\n",
        "    pickle.dump(carside_test_1_history.history, file)"
      ],
      "metadata": {
        "id": "z33pOnyhDVUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_carside_df.head()"
      ],
      "metadata": {
        "id": "N6YQRHVXEMbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract loss values from the history\n",
        "loss = carside_test_1_history.history['loss']\n",
        "val_loss = carside_test_1_history.history['val_loss']\n",
        "\n",
        "# Print first and last values\n",
        "print(\"Training Loss:\")\n",
        "print(f\"  First value: {loss[0]:.4f}\")\n",
        "print(f\"   Last value: {loss[-1]:.4f}\")\n",
        "print(\"Validation Loss:\")\n",
        "print(f\"  First value: {val_loss[0]:.4f}\")\n",
        "print(f\"   Last value: {val_loss[-1]:.4f}\")\n",
        "\n",
        "# Calculate min and max values\n",
        "loss_min = min(loss)\n",
        "loss_max = max(loss)\n",
        "val_loss_min = min(val_loss)\n",
        "val_loss_max = max(val_loss)\n",
        "\n",
        "# Plot the losses\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
        "plt.title('Training Loss and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Annotate min and max values\n",
        "plt.annotate(f\"Min: {loss_min:.4f}\", xy=(epochs[loss.index(loss_min)], loss_min),\n",
        "             xytext=(10, 20), textcoords='offset points',\n",
        "             arrowprops=dict(arrowstyle=\"->\", lw=1.5))\n",
        "plt.annotate(f\"Max: {loss_max:.4f}\", xy=(epochs[loss.index(loss_max)], loss_max),\n",
        "             xytext=(-70, -30), textcoords='offset points',\n",
        "             arrowprops=dict(arrowstyle=\"->\", lw=1.5))\n",
        "plt.annotate(f\"Min: {val_loss_min:.4f}\", xy=(epochs[val_loss.index(val_loss_min)], val_loss_min),\n",
        "             xytext=(-70, 20), textcoords='offset points',\n",
        "             arrowprops=dict(arrowstyle=\"->\", lw=1.5))\n",
        "plt.annotate(f\"Max: {val_loss_max:.4f}\", xy=(epochs[val_loss.index(val_loss_max)], val_loss_max),\n",
        "             xytext=(10, -30), textcoords='offset points',\n",
        "             arrowprops=dict(arrowstyle=\"->\", lw=1.5))\n",
        "\n",
        "# Adjust plot layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aUKhIMnxC1hF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "65obvPo7f4ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the history object to a file using pickle\n",
        "with open('/content/drive/MyDrive/project_mark2/carside_test_1_history.pkl', 'wb') as file:\n",
        "    pickle.dump(carside_test_1_history.history, file)"
      ],
      "metadata": {
        "id": "YkUdV9gZgQNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "file_path = '/content/drive/My Drive/project_mark2/carside_test_1_model.h5'\n",
        "destination_path = 'carside_test_1_model.h5'\n",
        "\n",
        "shutil.copyfile(file_path, destination_path)"
      ],
      "metadata": {
        "id": "MLIoro-_jo2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "model = keras.models.load_model('carside_test_1_model.h5')"
      ],
      "metadata": {
        "id": "P8dFrokDkQ9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###################### ^^^^^^^^^^^ after training ^^^^^^^^^^^^^^^^^^^ #########################"
      ],
      "metadata": {
        "id": "l3Oh3vV8kaPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_boxes[:5]"
      ],
      "metadata": {
        "id": "kJuhjXpBsOFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_carside_df"
      ],
      "metadata": {
        "id": "Wai8co9XtszM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming you have the test_images array and your_model variable\n",
        "\n",
        "# Create an empty list to store bounding box information\n",
        "bbox_data = []\n",
        "\n",
        "# Iterate over the test_images array\n",
        "for image in test_images:\n",
        "    # Perform inference using your model to get the predicted bounding box coordinates\n",
        "\n",
        "\n",
        "    # Reshape the image to match the expected input shape of the model\n",
        "    reshaped_image = np.expand_dims(image, axis=0)\n",
        "\n",
        "    # Perform inference using your model to get the predicted bounding box coordinates\n",
        "    predicted_bbox = model.predict(reshaped_image)\n",
        "    print(predicted_bbox)\n",
        "\n",
        "    # Append the image path and predicted bounding box coordinates to the bbox_data list\n",
        "    bbox_data.append({\n",
        "        'Image Path': image_path,  # Replace with the actual image path if available\n",
        "        'p_Xmin': predicted_bbox[0][0],\n",
        "        'p_Ymin': predicted_bbox[0][1],\n",
        "        'p_Xmax': predicted_bbox[0][2],\n",
        "        'p_Ymax': predicted_bbox[0][3]\n",
        "    })\n",
        "\n",
        "# Create a dataframe from the bbox_data list\n",
        "bounding_boxes_df = pd.DataFrame(bbox_data)\n",
        "\n",
        "# Print the dataframe\n",
        "print(bounding_boxes_df)"
      ],
      "metadata": {
        "id": "ZaNxcK1IuoWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bounding_boxes_df"
      ],
      "metadata": {
        "id": "aBT4imRqu_Jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming you have the predicted bounding boxes dataframe stored in pred_df\n",
        "# and the original dataframe stored in test_carside_df\n",
        "\n",
        "merged_df = test_carside_df.merge(bounding_boxes_df, on=\"Image Path\", how=\"inner\")"
      ],
      "metadata": {
        "id": "FG4W8i18vrfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df"
      ],
      "metadata": {
        "id": "hrewYG3fwQ5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Function to calculate IoU\n",
        "def calculate_iou(bb1, bb2):\n",
        "    \"\"\"\n",
        "    Calculate the Intersection over Union (IoU) of two bounding boxes.\n",
        "    :param bb1: Bounding box 1 [xmin, ymin, xmax, ymax]\n",
        "    :param bb2: Bounding box 2 [xmin, ymin, xmax, ymax]\n",
        "    :return: IoU value\n",
        "    \"\"\"\n",
        "    # Calculate the intersection area\n",
        "    x_left = max(bb1[0], bb2[0])\n",
        "    y_top = max(bb1[1], bb2[1])\n",
        "    x_right = min(bb1[2], bb2[2])\n",
        "    y_bottom = min(bb1[3], bb2[3])\n",
        "\n",
        "    if x_right < x_left or y_bottom < y_top:\n",
        "        return 0.0\n",
        "\n",
        "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
        "\n",
        "    # Calculate the union area\n",
        "    bb1_area = (bb1[2] - bb1[0]) * (bb1[3] - bb1[1])\n",
        "    bb2_area = (bb2[2] - bb2[0]) * (bb2[3] - bb2[1])\n",
        "    union_area = bb1_area + bb2_area - intersection_area\n",
        "\n",
        "    # Calculate IoU\n",
        "    iou = intersection_area / union_area\n",
        "    return iou\n",
        "\n",
        "# Calculate mean IoU for each image\n",
        "def calculate_mean_iou(df):\n",
        "    \"\"\"\n",
        "    Calculate the mean Intersection over Union (IoU) for each image in the dataframe.\n",
        "    :param df: Dataframe containing bounding box information\n",
        "    :return: Series with mean IoU for each image\n",
        "    \"\"\"\n",
        "    mean_ious = []\n",
        "    unique_images = df['Image Name'].unique()\n",
        "\n",
        "    for image_name in unique_images:\n",
        "        image_df = df[df['Image Name'] == image_name]\n",
        "\n",
        "        ious = []\n",
        "        for i in range(len(image_df)):\n",
        "            row = image_df.iloc[i]\n",
        "            bb1 = [row['p_Xmin'], row['p_Ymin'], row['p_Xmax'], row['p_Ymax']]\n",
        "            bb2 = [row['Xmin'], row['Ymin'], row['Xmax'], row['Ymax']]\n",
        "            iou = calculate_iou(bb1, bb2)\n",
        "            ious.append(iou)\n",
        "\n",
        "        mean_iou = sum(ious) / len(ious)\n",
        "        mean_ious.append(mean_iou)\n",
        "\n",
        "    return pd.Series(mean_ious, index=unique_images)\n",
        "\n",
        "\n",
        "# Calculate mean IoU for each image\n",
        "mean_ious = calculate_mean_iou(merged_df)\n",
        "print(mean_ious)"
      ],
      "metadata": {
        "id": "CdfxSgTtwSsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Calculate the mean IoU for each image\n",
        "merged_df['mean_IoU'] = merged_df.apply(lambda row: (row['p_Xmax'] - row['p_Xmin']) * (row['p_Ymax'] - row['p_Ymin']), axis=1)\n",
        "\n",
        "# Group the dataframe by image name and calculate the mean IoU\n",
        "mean_IoU_per_image = merged_df.groupby('Image Name')['mean_IoU'].mean().reset_index()\n",
        "\n",
        "# Merge the mean IoU values back to the original dataframe\n",
        "merged_df = pd.merge(merged_df, mean_IoU_per_image, on='Image Name')\n",
        "\n",
        "# Display the updated dataframe\n",
        "print(merged_df)"
      ],
      "metadata": {
        "id": "-jT-4LF_wzIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df"
      ],
      "metadata": {
        "id": "MnyoSK32xDVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Calculate the IoU for each bounding box in the x-axis and y-axis\n",
        "merged_df['IoU_x'] = merged_df.apply(lambda row: row['p_Xmax'] - row['p_Xmin'], axis=1)\n",
        "merged_df['IoU_y'] = merged_df.apply(lambda row: row['p_Ymax'] - row['p_Ymin'], axis=1)\n",
        "\n",
        "# Calculate the total mean IoU\n",
        "mean_IoU = (merged_df['IoU_x'].mean() + merged_df['IoU_y'].mean()) / 2\n",
        "\n",
        "# Display the total mean IoU\n",
        "print(\"Total Mean IoU:\", mean_IoU)"
      ],
      "metadata": {
        "id": "LhPGemnOxIIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df"
      ],
      "metadata": {
        "id": "FZnf-WGzxlQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "\n",
        "# Function to plot normalized bounding boxes on images\n",
        "def plot_normalized_bounding_boxes(df):\n",
        "    # Iterate over each row in the DataFrame\n",
        "    for index, row in df.iterrows():\n",
        "        # Read image path\n",
        "        image_path = row['Image Path']\n",
        "\n",
        "        # Load image as RGB\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "        # Create figure and axes\n",
        "        fig, ax = plt.subplots(1)\n",
        "\n",
        "        # Display the image\n",
        "        ax.imshow(image)\n",
        "\n",
        "        # Retrieve normalized bounding box coordinates\n",
        "        xmin = row['p_Xmin'] * row['Width']\n",
        "        ymin = row['p_Ymin'] * row['Height']\n",
        "        xmax = row['p_Xmax'] * row['Width']\n",
        "        ymax = row['p_Ymax'] * row['Height']\n",
        "\n",
        "        # Create a Rectangle patch for the predicted bounding box\n",
        "        pred_box = patches.Rectangle((xmin, ymin), (xmax - xmin), (ymax - ymin), linewidth=2, edgecolor='r', facecolor='none')\n",
        "        ax.add_patch(pred_box)\n",
        "\n",
        "        # Create a Rectangle patch for the original bounding box\n",
        "        orig_box = patches.Rectangle((row['Xmin'], row['Ymin']), (row['Xmax'] - row['Xmin']), (row['Ymax'] - row['Ymin']), linewidth=2, edgecolor='g', facecolor='none')\n",
        "        ax.add_patch(orig_box)\n",
        "\n",
        "        # Set title\n",
        "        ax.set_title(\"Image: {}\".format(row['Image Name']))\n",
        "\n",
        "        # Show the plot\n",
        "        plt.show()\n",
        "\n",
        "# Call the function with your DataFrame\n",
        "plot_normalized_bounding_boxes(merged_df)\n"
      ],
      "metadata": {
        "id": "hJPGI89cxndZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images"
      ],
      "metadata": {
        "id": "iG95O7HPyaeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Append data from test_df into arrays\n",
        "test_images = []\n",
        "test_boxes = []\n",
        "test_labels = []\n",
        "\n",
        "for index, row in test_carside_df.iterrows():\n",
        "    image_path = row['Image Path']\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = resize_image(image, (224, 224))\n",
        "    test_images.append(image)\n",
        "\n",
        "    xmin, ymin, xmax, ymax = map(float, [row['Xmin'], row['Ymin'], row['Xmax'], row['Ymax']])\n",
        "    test_boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "    label = row['Class Name']\n",
        "    test_labels.append(label)\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "test_images = np.array(test_images, dtype='float32')\n",
        "test_boxes = np.array(test_boxes, dtype='float32')\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "# Normalize the images\n",
        "test_images = test_images / 255.0\n",
        "\n"
      ],
      "metadata": {
        "id": "jxNVvER5yvTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images"
      ],
      "metadata": {
        "id": "_RCBzWcPzh2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_boxes"
      ],
      "metadata": {
        "id": "IYtPqcxW0Vxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images[1]"
      ],
      "metadata": {
        "id": "nvuZR1dj0gFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_images(images):\n",
        "    for i in range(len(images)):\n",
        "        plt.imshow(images[i])\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "plot_images(test_images)"
      ],
      "metadata": {
        "id": "euWMU1741GcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_boxes\n"
      ],
      "metadata": {
        "id": "5hLBMW9J1trv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "def plot_images_with_boxes(images, boxes):\n",
        "    for i in range(len(images)):\n",
        "        image = images[i]\n",
        "        box = boxes[i]\n",
        "\n",
        "        # Create figure and axes\n",
        "        fig, ax = plt.subplots()\n",
        "\n",
        "        # Display the image\n",
        "        ax.imshow(image)\n",
        "\n",
        "        # Create a rectangle patch for the bounding box\n",
        "        rect = patches.Rectangle((box[1]*255, box[0]*255), box[3]*255-box[1]*255, box[2]*255-box[0]*255, linewidth=2, edgecolor='r', facecolor='none')\n",
        "\n",
        "        # Add the rectangle to the plot\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "        # Remove axis ticks and labels\n",
        "        ax.axis('off')\n",
        "\n",
        "        # Show the plot\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "plot_images_with_boxes(test_images, test_boxes)"
      ],
      "metadata": {
        "id": "FvZDAHXm2KEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_images_with_boxes(images, boxes):\n",
        "    for i in range(len(images)):\n",
        "        image = images[i]\n",
        "        box = boxes[i]\n",
        "\n",
        "        # Multiply bounding box values by 255\n",
        "        xmin = box[0] * 255\n",
        "        ymin = box[1] * 255\n",
        "        xmax = box[2] * 255\n",
        "        ymax = box[3] * 255\n",
        "\n",
        "        # Plot the image\n",
        "        plt.imshow(image)\n",
        "\n",
        "        # Plot the bounding box\n",
        "        rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
        "                             edgecolor='r', facecolor='none')\n",
        "        plt.gca().add_patch(rect)\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "plot_images_with_boxes(test_images, test_boxes)"
      ],
      "metadata": {
        "id": "Cfw_jMPy2Wke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df\n",
        "\n"
      ],
      "metadata": {
        "id": "9irGlwKm272M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "def plot_images_with_boxes(data):\n",
        "    for i, row in data.iterrows():\n",
        "        image_path = row['Image Path']\n",
        "        class_name = row['Class Name']\n",
        "        image_name = row['Image Name']\n",
        "        xmin = int(row['Xmin'] * 255)\n",
        "        ymin = int(row['Ymin'] * 255)\n",
        "        xmax = int(row['Xmax'] * 255)\n",
        "        ymax = int(row['Ymax'] * 255)\n",
        "        p_xmin = int(row['p_Xmin'] * 255)\n",
        "        p_ymin = int(row['p_Ymin'] * 255)\n",
        "        p_xmax = int(row['p_Xmax'] * 255)\n",
        "        p_ymax = int(row['p_Ymax'] * 255)\n",
        "\n",
        "        # Load the image\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        # Draw the original bounding box\n",
        "        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0, 0, 255), 2)\n",
        "\n",
        "        # Draw the predicted bounding box\n",
        "        cv2.rectangle(image, (p_xmin, p_ymin), (p_xmax, p_ymax), (0, 255, 0), 2)\n",
        "\n",
        "        # Display the image\n",
        "        plt.imshow(data)"
      ],
      "metadata": {
        "id": "Ku9kYpcA3_SH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_images_with_boxes(merged_df)\n"
      ],
      "metadata": {
        "id": "Wp5uNOqR4Hrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "\n",
        "# Define a function to plot images with bounding boxes\n",
        "def plot_images_with_bounding_boxes(dataframe):\n",
        "    fig, axs = plt.subplots(nrows=len(dataframe), figsize=(8, 8 * len(dataframe)))\n",
        "\n",
        "    for idx, row in dataframe.iterrows():\n",
        "        # Load the image\n",
        "        image_path = row['Image Path']\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "        # Plot the image\n",
        "        ax = axs[idx]\n",
        "        ax.imshow(image)\n",
        "        ax.axis('off')\n",
        "\n",
        "        # Get ground truth bounding box coordinates\n",
        "        xmin_gt = row['Xmin'] * row['Width']\n",
        "        ymin_gt = row['Ymin'] * row['Height']\n",
        "        xmax_gt = row['Xmax'] * row['Width']\n",
        "        ymax_gt = row['Ymax'] * row['Height']\n",
        "\n",
        "        # Calculate ground truth bounding box width and height\n",
        "        width_gt = xmax_gt - xmin_gt\n",
        "        height_gt = ymax_gt - ymin_gt\n",
        "\n",
        "        # Create a ground truth rectangle patch\n",
        "        rect_gt = patches.Rectangle((xmin_gt, ymin_gt), width_gt, height_gt, linewidth=2, edgecolor='r', facecolor='none')\n",
        "        ax.add_patch(rect_gt)\n",
        "\n",
        "        # Get predicted bounding box coordinates\n",
        "        xmin_pred = row['p_Xmin'] * row['Width']\n",
        "        ymin_pred = row['p_Ymin'] * row['Height']\n",
        "        xmax_pred = row['p_Xmax'] * row['Width']\n",
        "        ymax_pred = row['p_Ymax'] * row['Height']\n",
        "\n",
        "        # Calculate predicted bounding box width and height\n",
        "        width_pred = xmax_pred - xmin_pred\n",
        "        height_pred = ymax_pred - ymin_pred\n",
        "\n",
        "        # Create a predicted rectangle patch\n",
        "        rect_pred = patches.Rectangle((xmin_pred, ymin_pred), width_pred, height_pred, linewidth=2, edgecolor='g', facecolor='none')\n",
        "        ax.add_patch(rect_pred)\n",
        "\n",
        "    # Show the plot\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Call the function with your merged_df\n",
        "plot_images_with_bounding_boxes(merged_df)"
      ],
      "metadata": {
        "id": "bA0r2yoD4VFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "\n",
        "# Define a function to plot images with bounding boxes\n",
        "def plot_images_with_bounding_boxes(dataframe):\n",
        "    for _, row in dataframe.iterrows():\n",
        "        # Load the image\n",
        "        image_path = row['Image Path']\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "        # Create a figure and axis\n",
        "        fig, ax = plt.subplots()\n",
        "\n",
        "        # Plot the image\n",
        "        ax.imshow(image)\n",
        "        ax.axis('off')\n",
        "\n",
        "        # Get bounding box coordinates\n",
        "        xmin = row['Xmin']\n",
        "        ymin = row['Ymin']\n",
        "        xmax = row['Xmax']\n",
        "        ymax = row['Ymax']\n",
        "\n",
        "        # Calculate bounding box width and height\n",
        "        width = xmax - xmin\n",
        "        height = ymax - ymin\n",
        "\n",
        "        # Create a rectangle patch\n",
        "        rect = patches.Rectangle((xmin, ymin), width, height, linewidth=2, edgecolor='r', facecolor='none')\n",
        "\n",
        "        # Add the rectangle patch to the plot\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "        # Show the plot\n",
        "        plt.show()\n",
        "\n",
        "# Call the function with your merged_df\n",
        "plot_images_with_bounding_boxes(merged_df)"
      ],
      "metadata": {
        "id": "Cm72mYMV5JbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w2MPFjVb6nBy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}