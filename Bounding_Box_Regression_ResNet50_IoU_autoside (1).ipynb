{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **BOUNDING BOX REGRESSION WITH RESNET 50**\n",
        "**WE ARE GOING TO USE CALTECH-101 DATASET, I HAVE UPDATED THE DATASET FOR OUR PURPOSE, ZUERST IMPLEMENTIEREN DIE DATASET**"
      ],
      "metadata": {
        "id": "XKOn5h2TnlUT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BP4fCzQRmu8i"
      },
      "outputs": [],
      "source": [
        "#### ZUERST IMPLEMENTIREN WIR DIE BIBLIOTHEKEN, DI WIR BRAUCHEN KÖNNEN:\n",
        "import os\n",
        "import cv2\n",
        "import imutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import pickle\n",
        "import zipfile # importing the 'zipfile' module\n",
        "\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "!pip install send2trash\n",
        "\n",
        "from send2trash import send2trash\n",
        "import pandas as pd\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "import cv2\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "from keras.models import Sequential\n",
        "## Import from keras_preprocessing not from keras.preprocessing\n",
        "## from keras_preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import regularizers, optimizers\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf1\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "######################################################\n",
        "############## RESNET50 ##############################\n",
        "######################################################\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import MeanIoU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://vijayabhaskar96.medium.com/tutorial-on-keras-flow-from-dataframe-1fd4493d237c\n",
        "# https://studymachinelearning.com/keras-imagedatagenerator-with-flow_from_dataframe/\n",
        "# https://stackoverflow.com/questions/66424141/imagedatagenerator-flow-from-dataframe-multi-output-regression-and-classificatio\n",
        "# https://stackoverflow.com/questions/50781562/stratified-splitting-of-pandas-dataframe-into-training-validation-and-test-set\n",
        "\n",
        "##################################################\n",
        "########### DATA LOADER LINKS ####################\n",
        "##################################################\n"
      ],
      "metadata": {
        "id": "6Nc6hVp7p0df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## WE ARE GOING TO IMPORT THE ZIP FILE, WHICH CONSIST THE IMAGES:\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "XiD5QAYYtmnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_file_name = \"/content/drive/MyDrive/caltech-101_m2.zip\"  # Zip dosyasının adını güncelleyin\n",
        "\n",
        "with zipfile.ZipFile(zip_file_name, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"caltech_files/\")"
      ],
      "metadata": {
        "id": "VwkJK_a6t13l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install send2trash\n",
        "\n",
        "from send2trash import send2trash\n",
        "\n",
        "file_path = 'caltech-101_new/101_ObjectCategories/BACKGROUND_Google'\n",
        "\n",
        "try:\n",
        "    send2trash(file_path)\n",
        "    print(f\"File '{file_path}' has been moved to the trash.\")\n",
        "except OSError:\n",
        "    print(f\"Failed to delete file '{file_path}'.\")"
      ],
      "metadata": {
        "id": "TQINMAVyt2Yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## LET'S IMPORT THE DATAFRAMES FOR VALIDATION, TEST AND TRAIN\n",
        "\n",
        "train_path = '/content/drive/My Drive/train_df.csv'\n",
        "train_df = pd.read_csv(train_path)\n",
        "\n",
        "val_path = '/content/drive/My Drive/val_df.csv'\n",
        "val_df = pd.read_csv(val_path)\n",
        "\n",
        "test_path = '/content/drive/My Drive/test_df.csv'\n",
        "test_df = pd.read_csv(test_path)"
      ],
      "metadata": {
        "id": "Ve6e4rmEt5jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(train_df))\n",
        "print(type(test_df))\n",
        "print(type(val_df))\n",
        "\n",
        "\n",
        "print(len(train_df))\n",
        "print(len(test_df))\n",
        "print(len(val_df))\n"
      ],
      "metadata": {
        "id": "Tt9AICizun1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_csv('/content/train_df.csv', index=False)\n",
        "val_df.to_csv('/content/val_df.csv', index=False)\n",
        "test_df.to_csv('/content/test_df.csv', index=False)\n"
      ],
      "metadata": {
        "id": "BVo4qBdSut4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "id": "K8oPQAbLw_X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "metadata": {
        "id": "laoRMC64xFcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_df.head()"
      ],
      "metadata": {
        "id": "fZSw2q8nxHh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_eda(dataframe):\n",
        "    # Count the number of unique classes\n",
        "    num_classes = len(dataframe['Class Name'].unique())\n",
        "\n",
        "    # Count the number of images\n",
        "    num_images = dataframe.shape[0]\n",
        "\n",
        "    # Count the number of images per class\n",
        "    images_per_class = dataframe['Class Name'].value_counts()\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    plt.barh(range(num_classes), images_per_class.values)\n",
        "    plt.yticks(range(num_classes), images_per_class.index)\n",
        "    plt.xlabel('Number of Images')\n",
        "    plt.ylabel('Class')\n",
        "    plt.title('Number of Images per Class')\n",
        "\n",
        "    # Display the number of images\n",
        "    for i, v in enumerate(images_per_class.values):\n",
        "        plt.text(v, i, str(v), color='black', va='center')\n",
        "\n",
        "    # Adjust the layout and display the plot\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "-cJISgo30TTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the function for each dataframe\n",
        "plot_eda(train_df)\n",
        "plot_eda(val_df)\n",
        "plot_eda(test_df)"
      ],
      "metadata": {
        "id": "MElEvyzR08uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the dataframes\n",
        "combined_df = pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
        "\n",
        "def plot_combined_eda(dataframe):\n",
        "    # Count the number of unique classes\n",
        "    num_classes = len(dataframe['Class Name'].unique())\n",
        "\n",
        "    # Count the number of images\n",
        "    num_images = dataframe.shape[0]\n",
        "\n",
        "    # Count the number of images per class\n",
        "    images_per_class = dataframe['Class Name'].value_counts()\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    plt.barh(range(num_classes), images_per_class.values, height=0.5)\n",
        "\n",
        "    # Adjust the spacing between the y-tick labels\n",
        "    plt.gca().set_yticks(range(num_classes))\n",
        "    plt.gca().set_yticklabels(images_per_class.index, ha='right')\n",
        "\n",
        "    plt.xlabel('Number of Images')\n",
        "    plt.ylabel('Class')\n",
        "    plt.title('Number of Images per Class (Combined)')\n",
        "\n",
        "    # Display the number of images\n",
        "    for i, v in enumerate(images_per_class.values):\n",
        "        plt.text(v + 5, i, str(v), color='black', va='center')\n",
        "\n",
        "    # Display the total number of images\n",
        "    plt.text(0, num_classes+1, f'Total Images: {num_images}', fontsize=12, fontweight='bold')\n",
        "\n",
        "    # Adjust the layout and display the plot\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Call the function for the combined dataframe\n",
        "plot_combined_eda(combined_df)"
      ],
      "metadata": {
        "id": "0Y6jMa4UNwA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **WE HAVE THE DATAFRAMES FOR TRAINING, VALIDATION AND TEST LET'S CONTINUE WITH TRAINING THE MODEL**"
      ],
      "metadata": {
        "id": "g_Cfyveu0U2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/content/drive/My Drive/train_df.csv')\n",
        "val_df = pd.read_csv('/content/drive/My Drive/val_df.csv')\n",
        "test_df = pd.read_csv('/content/drive/My Drive/test_df.csv')"
      ],
      "metadata": {
        "id": "wsC9oPBQxvAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = ['Image Path', 'Class Name', 'Image Name', 'Bounding Box', 'Height', 'Width', 'label',\n",
        "                'normalized', 'Xmin', 'Ymin', 'Xmax', 'Ymax']\n",
        "\n",
        "\n",
        "carside_df.columns = column_names\n",
        "val_carside_df.columns = column_names\n",
        "test_carside_df.columns = column_names"
      ],
      "metadata": {
        "id": "F11rRRO9Qiq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "    image = image.astype(np.float32) / 255.0\n",
        "    return image"
      ],
      "metadata": {
        "id": "AMBWKrx9Qn-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_images_with_bboxes(df):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
        "    for i, row in df.head(5).iterrows():\n",
        "        image_path = row['Image Path']\n",
        "        class_name = row['Class Name']\n",
        "        image_name = row['Image Name']\n",
        "        xmin, ymin, xmax, ymax = row['Xmin']*224, row['Ymin']*224, row['Xmax']*224, row['Ymax']*224\n",
        "\n",
        "        image = load_image(image_path)\n",
        "\n",
        "        ax = axes[i]\n",
        "        ax.imshow(image)\n",
        "        ax.axis('off')\n",
        "\n",
        "        # Add bounding box\n",
        "        bbox = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, linewidth=2, edgecolor='r', facecolor='none')\n",
        "        ax.add_patch(bbox)\n",
        "\n",
        "        ax.set_title(f'Class: {class_name}\\nImage: {image_name}')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Plot images with bounding boxes for val_df, test_df, train_df\n",
        "plot_images_with_bboxes(val_carside_df)\n",
        "plot_images_with_bboxes(test_carside_df)\n",
        "plot_images_with_bboxes(carside_df)"
      ],
      "metadata": {
        "id": "DL7hTnj1Qvd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####################################################\n",
        "############## MOST IMPORTANT PART #################\n",
        "####################################################\n",
        "\n",
        "\n",
        "\n",
        "def resize_image(image, target_size):\n",
        "    return cv2.resize(image, target_size)\n",
        "\n",
        "def plot_images(images, boxes, labels, dataset_name):\n",
        "    fig, axes = plt.subplots(1, len(images), figsize=(12, 4))\n",
        "    for i, ax in enumerate(axes):\n",
        "        ax.imshow(images[i])\n",
        "        xmin, ymin, xmax, ymax = boxes[i]\n",
        "        ax.add_patch(plt.Rectangle((xmin*224, ymin*224), xmax*224 - xmin*224, ymax*224 - ymin*224, fill=False, color='red', linewidth=2))\n",
        "        ax.set_title(labels[i])\n",
        "        ax.axis('off')\n",
        "    plt.suptitle(f'{dataset_name} Images with Bounding Boxes')\n",
        "    plt.show()\n",
        "\n",
        "# Append data from val_df into arrays\n",
        "val_images = []\n",
        "val_boxes = []\n",
        "val_labels = []\n",
        "\n",
        "for index, row in val_carside_df.iterrows():\n",
        "    image_path = row['Image Path']\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = resize_image(image, (224, 224))\n",
        "    val_images.append(image)\n",
        "\n",
        "    xmin, ymin, xmax, ymax = map(float, [row['Xmin'], row['Ymin'], row['Xmax'], row['Ymax']])\n",
        "    val_boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "    label = row['Class Name']\n",
        "    val_labels.append(label)\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "val_images = np.array(val_images, dtype='float32')\n",
        "val_boxes = np.array(val_boxes, dtype='float32')\n",
        "val_labels = np.array(val_labels)\n",
        "\n",
        "# Normalize the images\n",
        "val_images = val_images / 255.0\n",
        "\n",
        "# Plot the images, bounding boxes, and class names for the first 4 images from the val_df dataset\n",
        "plot_images(val_images[:5], val_boxes[:5], val_labels[:5], 'Validation')\n",
        "\n",
        "# Append data from train_df into arrays\n",
        "train_images = []\n",
        "train_boxes = []\n",
        "train_labels = []\n",
        "\n",
        "for index, row in carside_df.iterrows():\n",
        "    image_path = row['Image Path']\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = resize_image(image, (224, 224))\n",
        "    train_images.append(image)\n",
        "\n",
        "    xmin, ymin, xmax, ymax = map(float, [row['Xmin'], row['Ymin'], row['Xmax'], row['Ymax']])\n",
        "    train_boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "    label = row['Class Name']\n",
        "    train_labels.append(label)\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "train_images = np.array(train_images, dtype='float32')\n",
        "train_boxes = np.array(train_boxes, dtype='float32')\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "# Normalize the images\n",
        "train_images = train_images / 255.0\n",
        "\n",
        "# Plot the images, bounding boxes, and class names for the first 4 images from the train_df dataset\n",
        "plot_images(train_images[:5], train_boxes[:5], train_labels[:5], 'Train')\n",
        "\n",
        "# Append data from test_df into arrays\n",
        "test_images = []\n",
        "test_boxes = []\n",
        "test_labels = []\n",
        "\n",
        "for index, row in test_carside_df.iterrows():\n",
        "    image_path = row['Image Path']\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = resize_image(image, (224, 224))\n",
        "    test_images.append(image)\n",
        "\n",
        "    xmin, ymin, xmax, ymax = map(float, [row['Xmin'], row['Ymin'], row['Xmax'], row['Ymax']])\n",
        "    test_boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "    label = row['Class Name']\n",
        "    test_labels.append(label)\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "test_images = np.array(test_images, dtype='float32')\n",
        "test_boxes = np.array(test_boxes, dtype='float32')\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "# Normalize the images\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Plot the images, bounding boxes, and class names for the first 4 images from the test_df dataset\n",
        "plot_images(test_images[:5], test_boxes[:5], test_labels[:5], 'Test')\n"
      ],
      "metadata": {
        "id": "WA-6WBR1ZIpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Perform label encoding on the target labels\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
        "val_labels_encoded = label_encoder.transform(val_labels)\n",
        "\n",
        "# Convert the encoded labels to one-hot encoding\n",
        "train_labels_onehot = to_categorical(train_labels_encoded, num_classes=101)\n",
        "val_labels_onehot = to_categorical(val_labels_encoded, num_classes=101)\n",
        "\n",
        "\n",
        "# Model architecture\n",
        "input_layer = Input(shape=(224, 224, 3))\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=input_layer)\n",
        "\n",
        "flatten = Flatten()(base_model.output)\n",
        "\n",
        "bboxHead = Dense(1024, activation=\"relu\")(flatten)\n",
        "\n",
        "\n",
        "\n",
        "bboxHead = Dense(512, activation=\"relu\")(bboxHead)\n",
        "\n",
        "\n",
        "bboxHead = Dense(256, activation=\"relu\")(bboxHead)\n",
        "\n",
        "\n",
        "\n",
        "bboxHead = Dense(128, activation=\"relu\")(bboxHead)\n",
        "\n",
        "\n",
        "\n",
        "bboxHead = Dense(64, activation=\"relu\")(bboxHead)\n",
        "\n",
        "\n",
        "bboxHead = Dense(32, activation=\"relu\")(bboxHead)\n",
        "\n",
        "bbox_output = Dense(4, activation='linear', name='bounding_box')(bboxHead)\n",
        "\n",
        "\n",
        "\n",
        "softmaxHead = Dense(1024, activation=\"relu\")(flatten)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "\n",
        "\n",
        "softmaxHead = Dense(512, activation=\"relu\")(softmaxHead)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "\n",
        "softmaxHead = Dense(256, activation=\"relu\")(softmaxHead)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "\n",
        "softmaxHead = Dense(128, activation=\"relu\")(softmaxHead)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "\n",
        "class_output = Dense(101, activation='softmax', name='class_output')(softmaxHead)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=[class_output, bbox_output])\n",
        "\n",
        "# Loss function\n",
        "losses = {\n",
        "    'class_output': 'categorical_crossentropy',\n",
        "    'bounding_box': 'mean_squared_error'\n",
        "}\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss=losses)\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "0if34ot5ym-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EEAl_CXkWamg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nrdG_13SWaZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=7)\n",
        "\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(train_images, {'class_output': train_labels_onehot, 'bounding_box': train_boxes},\n",
        "                    validation_data=(val_images, {'class_output': val_labels_onehot, 'bounding_box': val_boxes}),\n",
        "                    epochs=50, batch_size=32)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('/content/drive/MyDrive/trained_model.h5')"
      ],
      "metadata": {
        "id": "_XoO_eHHzM0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the label encoder\n",
        "with open('/content/label_encoder.pkl', 'wb') as file:\n",
        "    pickle.dump(label_encoder, file)"
      ],
      "metadata": {
        "id": "bRRiBnP34MOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the losses\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.style.use('seaborn')\n",
        "\n",
        "# Classification Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['class_output_loss'], label='Train Classification Loss', color='blue')\n",
        "plt.plot(history.history['val_class_output_loss'], label='Validation Classification Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Classification Loss', fontsize=14)\n",
        "plt.legend()\n",
        "\n",
        "# Bounding Box Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['bounding_box_loss'], label='Train Bounding Box Loss', color='blue')\n",
        "plt.plot(history.history['val_bounding_box_loss'], label='Validation Bounding Box Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Bounding Box Loss', fontsize=14)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "e8KpUEkHzNXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the best and worst validation losses\n",
        "best_val_class_loss = min(history.history['val_class_output_loss'])\n",
        "worst_val_class_loss = max(history.history['val_class_output_loss'])\n",
        "best_val_bbox_loss = min(history.history['val_bounding_box_loss'])\n",
        "worst_val_bbox_loss = max(history.history['val_bounding_box_loss'])\n",
        "\n",
        "# Plot the losses\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.style.use('seaborn')\n",
        "\n",
        "# Classification Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['class_output_loss'], label='Train Classification Loss', color='blue')\n",
        "plt.plot(history.history['val_class_output_loss'], label='Validation Classification Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Classification Loss', fontsize=14)\n",
        "plt.legend()\n",
        "\n",
        "# Bounding Box Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['bounding_box_loss'], label='Train Bounding Box Loss', color='blue')\n",
        "plt.plot(history.history['val_bounding_box_loss'], label='Validation Bounding Box Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Bounding Box Loss', fontsize=14)\n",
        "plt.legend()\n",
        "\n",
        "# Display the best and worst values\n",
        "plt.text(len(history.history['val_class_output_loss']) // 2, best_val_class_loss, f'Best: {best_val_class_loss:.4f}', color='green', ha='center')\n",
        "plt.text(len(history.history['val_class_output_loss']) // 2, worst_val_class_loss, f'Worst: {worst_val_class_loss:.4f}', color='red', ha='center')\n",
        "plt.text(len(history.history['val_bounding_box_loss']) // 2, best_val_bbox_loss, f'Best: {best_val_bbox_loss:.4f}', color='green', ha='center')\n",
        "plt.text(len(history.history['val_bounding_box_loss']) // 2, worst_val_bbox_loss, f'Worst: {worst_val_bbox_loss:.4f}', color='red', ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2mPJNCD72GeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the best and worst validation losses\n",
        "best_val_class_loss = min(history.history['val_class_output_loss'])\n",
        "worst_val_class_loss = max(history.history['val_class_output_loss'])\n",
        "best_val_bbox_loss = min(history.history['val_bounding_box_loss'])\n",
        "worst_val_bbox_loss = max(history.history['val_bounding_box_loss'])\n",
        "\n",
        "# Plot the Classification Loss\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(history.history['class_output_loss'], label='Train Classification Loss', color='blue')\n",
        "plt.plot(history.history['val_class_output_loss'], label='Validation Classification Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Classification Loss', fontsize=14)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Display the best and worst values for Classification Loss\n",
        "print(f'Best Validation Classification Loss: {best_val_class_loss:.4f}')\n",
        "print(f'Worst Validation Classification Loss: {worst_val_class_loss:.4f}')\n",
        "print()\n",
        "\n",
        "# Plot the Bounding Box Loss\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(history.history['bounding_box_loss'], label='Train Bounding Box Loss', color='blue')\n",
        "plt.plot(history.history['val_bounding_box_loss'], label='Validation Bounding Box Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Bounding Box Loss', fontsize=14)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Display the best and worst values for Bounding Box Loss\n",
        "print(f'Best Validation Bounding Box Loss: {best_val_bbox_loss:.4f}')\n",
        "print(f'Worst Validation Bounding Box Loss: {worst_val_bbox_loss:.4f}')\n"
      ],
      "metadata": {
        "id": "RZwPW-Qc2U0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the best and worst losses\n",
        "best_train_class_loss = min(history.history['class_output_loss'])\n",
        "worst_train_class_loss = max(history.history['class_output_loss'])\n",
        "best_train_bbox_loss = min(history.history['bounding_box_loss'])\n",
        "worst_train_bbox_loss = max(history.history['bounding_box_loss'])\n",
        "\n",
        "# Find the best and worst validation losses\n",
        "best_val_class_loss = min(history.history['val_class_output_loss'])\n",
        "worst_val_class_loss = max(history.history['val_class_output_loss'])\n",
        "best_val_bbox_loss = min(history.history['val_bounding_box_loss'])\n",
        "worst_val_bbox_loss = max(history.history['val_bounding_box_loss'])\n",
        "\n",
        "# Plot the Classification Loss\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(history.history['class_output_loss'], label='Train Classification Loss', color='blue')\n",
        "plt.plot(history.history['val_class_output_loss'], label='Validation Classification Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Classification Loss', fontsize=14)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Display the best and worst values for Classification Loss\n",
        "print(f'Best Train Classification Loss: {best_train_class_loss:.4f}')\n",
        "print(f'Worst Train Classification Loss: {worst_train_class_loss:.4f}')\n",
        "print(f'Best Validation Classification Loss: {best_val_class_loss:.4f}')\n",
        "print(f'Worst Validation Classification Loss: {worst_val_class_loss:.4f}')\n",
        "print()\n",
        "\n",
        "# Plot the Bounding Box Loss\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(history.history['bounding_box_loss'], label='Train Bounding Box Loss', color='blue')\n",
        "plt.plot(history.history['val_bounding_box_loss'], label='Validation Bounding Box Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Bounding Box Loss', fontsize=14)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Display the best and worst values for Bounding Box Loss\n",
        "print(f'Best Train Bounding Box Loss: {best_train_bbox_loss:.4f}')\n",
        "print(f'Worst Train Bounding Box Loss: {worst_train_bbox_loss:.4f}')\n",
        "print(f'Best Validation Bounding Box Loss: {best_val_bbox_loss:.4f}')\n",
        "print(f'Worst Validation Bounding Box Loss: {worst_val_bbox_loss:.4f}')\n"
      ],
      "metadata": {
        "id": "PQdDQ9ho2jYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QE5xTg7f2nec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z-oWuxa7Vh8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "PgzZhhr9Vh5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Model architecture\n",
        "input_layer = Input(shape=(224, 224, 3))\n",
        "base_model = ResNet50(weights=None, include_top=False, input_tensor=input_layer)\n"
      ],
      "metadata": {
        "id": "1pj-4f_jVh3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flatten = Flatten()(base_model.output)\n",
        "\n",
        "bboxHead = Dense(1024, activation=\"relu\")(flatten)\n",
        "bboxHead = Dense(512, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(256, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(128, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(64, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(32, activation=\"relu\")(bboxHead)\n",
        "\n",
        "bbox_output = Dense(4, activation='linear', name='bounding_box')(bboxHead)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=bbox_output)\n",
        "\n",
        "# Load the trained model weights\n",
        "model.load_weights('/content/drive/MyDrive/project_mark1/model_top_layers.h5')\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "metadata": {
        "id": "Y_G0dCafVhpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Model architecture\n",
        "input_layer = Input(shape=(224, 224, 3))\n",
        "base_model = ResNet50(weights=None, include_top=False, input_tensor=input_layer)\n",
        "\n",
        "flatten = Flatten()(base_model.output)\n",
        "\n",
        "bboxHead = Dense(1024, activation=\"relu\")(flatten)\n",
        "bboxHead = Dense(512, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(256, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(128, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(64, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(32, activation=\"relu\")(bboxHead)\n",
        "\n",
        "bbox_output = Dense(4, activation='linear', name='bounding_box')(bboxHead)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=bbox_output)\n",
        "\n",
        "# Load the weights of the top layers\n",
        "model.load_weights('/content/drive/MyDrive/project_mark1/model_top_layers.h5', by_name=True)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Define early stopping callback\n",
        "callback = EarlyStopping(monitor='loss', patience=7)\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(train_images, train_boxes,\n",
        "                    validation_data=(val_images, val_boxes),\n",
        "                    epochs=50, batch_size=32, callbacks=[callback])\n",
        "\n",
        "# Save the trained model\n",
        "model.save('/content/drive/MyDrive/trained_bbox_model.h5')\n"
      ],
      "metadata": {
        "id": "T68bL8UmVhm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fHZzTSCGZzRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SxjREO34ZzPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4trMagC_ZzMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mlU_7p4LZzJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best and worst values of val_loss and loss\n",
        "best_val_loss = min(loss_callback.val_losses)\n",
        "worst_val_loss = max(loss_callback.val_losses)\n",
        "best_loss = min(loss_callback.losses)\n",
        "worst_loss = max(loss_callback.losses)\n",
        "\n",
        "# Plot the best and worst values\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(loss_callback.val_losses)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation Loss')\n",
        "plt.title(f'Best: {best_val_loss:.4f}\\nWorst: {worst_val_loss:.4f}')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(loss_callback.losses)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title(f'Best: {best_loss:.4f}\\nWorst: {worst_loss:.4f}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UmlG0YXk18_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.patches as patches\n",
        "\n",
        "# Define a function to plot images with bounding boxes\n",
        "def plot_images(images, boxes, labels, dataset_name):\n",
        "    fig, axes = plt.subplots(1, len(images), figsize=(12, 4))\n",
        "    for i, ax in enumerate(axes):\n",
        "        ax.imshow(images[i])\n",
        "        xmin, ymin, xmax, ymax = boxes[i]\n",
        "        ax.add_patch(plt.Rectangle((xmin*224, ymin*224), (xmax-xmin)*224, (ymax-ymin)*224, fill=False, color='red', linewidth=2))\n",
        "        ax.set_title(labels[i])\n",
        "        ax.axis('off')\n",
        "    plt.suptitle(f'{dataset_name} Images with Bounding Boxes')\n",
        "    plt.show()\n",
        "\n",
        "# Get the predictions on the test data\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# Calculate the IoU scores for each predicted bounding box\n",
        "iou_scores = []\n",
        "for i in range(len(predictions)):\n",
        "    pred_box = predictions[i][:4] * np.array([190, 300, 190, 300])\n",
        "    true_box = test_boxes[i]\n",
        "    iou = calculate_iou(pred_box, true_box)\n",
        "    iou_scores.append(iou)\n",
        "\n",
        "# Sort the images based on the IoU scores (best and worst)\n",
        "best_indices = np.argsort(iou_scores)[-5:]  # Get indices of images with highest IoU scores\n",
        "worst_indices = np.argsort(iou_scores)[:5]  # Get indices of images with lowest IoU scores\n",
        "\n",
        "# Plot the images with the best bounding box predictions\n",
        "best_images = test_images[best_indices]\n",
        "best_boxes = predictions[best_indices][:, :4] * np.array([190, 300, 190, 300])\n",
        "best_labels = [test_labels[i] for i in best_indices]\n",
        "plot_images(best_images, best_boxes, best_labels, 'Best Predictions')\n",
        "\n",
        "# Plot the images with the worst bounding box predictions\n",
        "worst_images = test_images[worst_indices]\n",
        "worst_boxes = predictions[worst_indices][:, :4] * np.array([190, 300, 190, 300])\n",
        "worst_labels = [test_labels[i] for i in worst_indices]\n",
        "plot_images(worst_images, worst_boxes, worst_labels, 'Worst Predictions')\n"
      ],
      "metadata": {
        "id": "woc7eYlw0vdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the IoU scores for each predicted bounding box\n",
        "iou_scores = []\n",
        "for i in range(len(predictions)):\n",
        "    pred_box = predictions[i][4:8] * np.array([190, 300, 190, 300])\n",
        "    true_box = test_boxes[i]\n",
        "    iou = calculate_iou(pred_box, true_box)\n",
        "    iou_scores.append(iou)\n",
        "\n",
        "# Sort the images based on the IoU scores (best and worst)\n",
        "best_indices = np.argsort(iou_scores)[-5:]  # Get indices of images with highest IoU scores\n",
        "worst_indices = np.argsort(iou_scores)[:5]  # Get indices of images with lowest IoU scores\n",
        "\n",
        "# Plot the images with the best bounding box predictions\n",
        "best_images = test_images[best_indices]\n",
        "best_boxes = predictions[best_indices][:, 4:8] * np.array([190, 300, 190, 300])\n",
        "best_labels = [test_labels[i] for i in best_indices]\n",
        "plot_images(best_images, best_boxes, best_labels, 'Best Predictions')\n",
        "\n",
        "# Plot the images with the worst bounding box predictions\n",
        "worst_images = test_images[worst_indices]\n",
        "worst_boxes = predictions[worst_indices][:, 4:8] * np.array([190, 300, 190, 300])\n",
        "worst_labels = [test_labels[i] for i in worst_indices]\n",
        "plot_images(worst_images, worst_boxes, worst_labels, 'Worst Predictions')\n"
      ],
      "metadata": {
        "id": "pMj4dpx81tE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best and worst values of val_loss and loss\n",
        "best_val_loss = min(loss_callback.val_losses)\n",
        "worst_val_loss = max(loss_callback.val_losses)\n",
        "best_loss = min(loss_callback.losses)\n",
        "worst_loss = max(loss_callback.losses)\n",
        "\n",
        "# Plot the best and worst values\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(loss_callback.val_losses)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation Loss')\n",
        "plt.title(f'Best: {best_val_loss:.4f}\\nWorst: {worst_val_loss:.4f}')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(loss_callback.losses)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title(f'Best: {best_loss:.4f}\\nWorst: {worst_loss:.4f}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "P8nOzwx01tBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zdxQk7-R1s-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Perform label encoding on the target labels\n",
        "test_labels_encoded = label_encoder.transform(test_labels)\n",
        "\n",
        "# Convert the encoded labels to one-hot encoding\n",
        "test_labels_onehot = to_categorical(test_labels_encoded, num_classes=100)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_class_output_loss, test_bbox_output_loss = model.evaluate(test_images, {'class_output': test_labels_onehot, 'bounding_box': test_boxes})\n",
        "\n",
        "print('Test Loss:', test_loss)\n",
        "print('Test Classification Loss:', test_class_output_loss)\n",
        "print('Test Bounding Box Loss:', test_bbox_output_loss)"
      ],
      "metadata": {
        "id": "-47I88Er8Y7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.patches as patches\n",
        "from sklearn.metrics import jaccard_score\n",
        "\n",
        "# Define a function to calculate the IoU score\n",
        "def calculate_iou(box1, box2):\n",
        "    # Extract coordinates from the bounding boxes\n",
        "    xmin1, ymin1, xmax1, ymax1 = box1\n",
        "    xmin2, ymin2, xmax2, ymax2 = box2\n",
        "\n",
        "    # Calculate the coordinates of the intersection rectangle\n",
        "    xmin_inter = max(xmin1, xmin2)\n",
        "    ymin_inter = max(ymin1, ymin2)\n",
        "    xmax_inter = min(xmax1, xmax2)\n",
        "    ymax_inter = min(ymax1, ymax2)\n",
        "\n",
        "    # Calculate the area of intersection rectangle\n",
        "    inter_area = max(0, xmax_inter - xmin_inter + 1) * max(0, ymax_inter - ymin_inter + 1)\n",
        "\n",
        "    # Calculate the areas of the bounding boxes\n",
        "    box1_area = (xmax1 - xmin1 + 1) * (ymax1 - ymin1 + 1)\n",
        "    box2_area = (xmax2 - xmin2 + 1) * (ymax2 - ymin2 + 1)\n",
        "\n",
        "    # Calculate the IoU score\n",
        "    iou = inter_area / float(box1_area + box2_area - inter_area)\n",
        "    return iou\n",
        "\n",
        "# Define a function to plot test images with predicted bounding box, original bounding box, predicted class, and original class\n",
        "def plot_test_images(test_images, test_boxes, test_labels, pred_boxes, pred_labels, step=10):\n",
        "    num_plots = min(len(test_images), 10)\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    for i in range(0, len(test_images), step):\n",
        "        if i // step >= num_plots:\n",
        "            break\n",
        "        plt.subplot(5, 2, (i // step) + 1)\n",
        "\n",
        "        # Denormalize the bounding box coordinates\n",
        "        x1, y1, x2, y2 = test_boxes[i] * 224\n",
        "        xmin = int(x1)\n",
        "        ymin = int(y1)\n",
        "        xmax = int(x2)\n",
        "        ymax = int(y2)\n",
        "\n",
        "        # Denormalize the image array\n",
        "        image = test_images[i] * 255\n",
        "        image = image.astype(np.uint8)\n",
        "\n",
        "        plt.imshow(image)\n",
        "        plt.axis('off')\n",
        "        plt.title(f\"Original Class: {test_labels[i]}\\nPredicted Class: {pred_labels[i]}\")\n",
        "\n",
        "        # Plot original bounding box\n",
        "        rect = patches.Rectangle((xmin, ymin), (xmax - xmin), (ymax - ymin), linewidth=2, edgecolor='r', facecolor='none')\n",
        "        plt.gca().add_patch(rect)\n",
        "\n",
        "        # Denormalize the predicted bounding box coordinates\n",
        "        x1, y1, x2, y2 = pred_boxes[i] * 224\n",
        "        xmin = int(x1)\n",
        "        ymin = int(y1)\n",
        "        xmax = int(x2)\n",
        "        ymax = int(y2)\n",
        "\n",
        "        # Plot predicted bounding box\n",
        "        rect = patches.Rectangle((xmin, ymin), (xmax - xmin), (ymax - ymin), linewidth=2, edgecolor='g', facecolor='none')\n",
        "        plt.gca().add_patch(rect)\n",
        "\n",
        "        # Calculate IoU score\n",
        "        iou_score = calculate_iou(test_boxes[i] * 224, pred_boxes[i] * 224)\n",
        "        plt.text(xmin, ymin, f\"IoU: {iou_score:.2f}\", color='b', fontsize=8, backgroundcolor='w')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Perform predictions on the test data\n",
        "preds = model.predict(test_images)\n",
        "pred_labels = label_encoder.inverse_transform(np.argmax(preds[0], axis=1))\n",
        "pred_boxes = preds[1]\n",
        "\n",
        "# Plot every 10th test image with predicted bounding box, original bounding box, predicted class, original class, and IoU score\n",
        "plot_test_images(test_images, test_boxes, test_labels, pred_boxes, pred_labels, step=1)\n"
      ],
      "metadata": {
        "id": "EWXGJZ8W-HLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Calculate precision, recall, and F1 scores for each class\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_labels, pred_labels, average=None)\n",
        "\n",
        "# Get the unique class labels\n",
        "classes = np.unique(test_labels)\n",
        "\n",
        "# Set the width of the bars\n",
        "bar_width = 0.35\n",
        "\n",
        "# Set the x locations of the bars\n",
        "index = np.arange(len(classes))\n",
        "\n",
        "# Set the figure size\n",
        "plt.figure(figsize=(12, 12))\n",
        "\n",
        "# Plot the recall scores\n",
        "plt.bar(index, recall, bar_width, label='Recall', color='skyblue')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Recall Scores by Class')\n",
        "plt.xticks(index, classes, rotation='vertical')\n",
        "\n",
        "# Add scores as text inside each bar\n",
        "for i, v in enumerate(recall):\n",
        "    plt.text(i, v, f\"{v:.2f}\", color='black', ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Set the figure size\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot the F1 scores\n",
        "plt.bar(index, f1, bar_width, label='F1 Score', color='lightgreen')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Score')\n",
        "plt.title('F1 Scores by Class')\n",
        "plt.xticks(index, classes, rotation='vertical')\n",
        "\n",
        "# Add scores as text inside each bar\n",
        "for i, v in enumerate(f1):\n",
        "    plt.text(i, v, f\"{v:.2f}\", color='black', ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6jev0sbVAbpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_iou_scores = []\n",
        "\n",
        "# Calculate the mean IoU score for each class\n",
        "for class_label in classes:\n",
        "    # Get the indices of samples belonging to the current class\n",
        "    class_indices = np.where(test_labels == class_label)[0]\n",
        "\n",
        "    # Extract the predicted and ground truth bounding boxes for the current class\n",
        "    class_pred_boxes = pred_boxes[class_indices]\n",
        "    class_test_boxes = test_boxes[class_indices]\n",
        "\n",
        "    # Calculate the IoU score for each sample\n",
        "    iou_scores = []\n",
        "\n",
        "    for i in range(len(class_indices)):\n",
        "        iou_score = calculate_iou(class_test_boxes[i], class_pred_boxes[i])\n",
        "        iou_scores.append(iou_score)\n",
        "\n",
        "    # Calculate the mean IoU score for the current class\n",
        "    mean_iou_score = np.mean(iou_scores)\n",
        "\n",
        "    # Append the class label and mean IoU score to the list of class IoU scores\n",
        "    class_iou_scores.append((class_label, mean_iou_score))\n",
        "\n",
        "# Sort the mean IoU scores from best to worst\n",
        "class_iou_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Extract the class labels and mean IoU scores into separate lists\n",
        "sorted_classes = [x[0] for x in class_iou_scores]\n",
        "sorted_scores = [x[1] for x in class_iou_scores]\n",
        "\n",
        "# Calculate the total mean IoU score\n",
        "total_mean_iou = np.mean(sorted_scores)\n",
        "\n",
        "# Plot the mean IoU scores for each class\n",
        "fig, ax = plt.subplots(figsize=(12, 12))\n",
        "bars = ax.barh(range(len(sorted_classes)), sorted_scores, color='purple')\n",
        "ax.set_xlabel('Mean IoU Score')\n",
        "ax.set_ylabel('Class')\n",
        "ax.set_title('Mean IoU Scores by Class')\n",
        "ax.set_yticks(range(len(sorted_classes)))\n",
        "ax.set_yticklabels(sorted_classes)\n",
        "ax.invert_yaxis()\n",
        "\n",
        "# Add scores as text inside each bar\n",
        "for bar, score in zip(bars, sorted_scores):\n",
        "    ax.text(bar.get_width() + 0.005, bar.get_y() + bar.get_height() / 2, f\"{score:.2f}\",\n",
        "            va='center', fontsize=7)\n",
        "\n",
        "# Add total mean IoU score as text at the top\n",
        "ax.text(0, -1, f\"Total Mean IoU: {total_mean_iou:.2f}\", ha='left', va='center', fontsize=12)\n",
        "\n",
        "# Add a vertical line at x=0.5 for reference\n",
        "ax.axvline(x=0.5, color='red', linestyle='--', linewidth=1)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u3ysj2hgFvcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# Assuming you have already loaded your model\n",
        "model = load_model('/content/drive/MyDrive/project_mark1/model_top_layers.h5')\n",
        "\n",
        "# Plot the model architecture\n",
        "plot_model(model, to_file='model_architecture.png', show_shapes=True)"
      ],
      "metadata": {
        "id": "ahgnuogw3aeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "34g32a_64dGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JjRdiBax4dEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CxhMtbVR3aWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D7ueV9hf3aTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s0GuudKn0lA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V0yLXfvo0k-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lFcS7wVO0kw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Get the number of images for each class from test_df\n",
        "class_counts = test_df[\"Class Name\"].value_counts()\n",
        "\n",
        "# Set the figure size\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot the number of images per class\n",
        "class_counts.plot(kind='bar')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of Images')\n",
        "plt.title('Number of Images per Class')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rbXziPejLf63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Calculate precision, recall, and F1 scores for each class\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_df[\"Class Name\"], pred_labels, average=None)\n",
        "\n",
        "# Get the unique class labels\n",
        "classes = np.unique(test_df[\"Class Name\"])\n",
        "\n",
        "# Sort precision, recall, and F1 scores in descending order\n",
        "sorted_indices = np.argsort(f1)[::-1]\n",
        "precision_sorted = precision[sorted_indices]\n",
        "recall_sorted = recall[sorted_indices]\n",
        "f1_sorted = f1[sorted_indices]\n",
        "classes_sorted = classes[sorted_indices]\n",
        "class_counts_sorted = class_counts[classes_sorted]\n",
        "\n",
        "# Set the figure size\n",
        "plt.figure(figsize=(12, 12))\n",
        "\n",
        "# Plot the precision scores\n",
        "plt.bar(range(len(classes)), precision_sorted, width=0.3, label='Precision', color='lightblue')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Precision Scores by Class')\n",
        "plt.xticks(range(len(classes)), classes_sorted, rotation='vertical')\n",
        "\n",
        "# Add scores and class counts as text above each bar\n",
        "for i, v in enumerate(precision_sorted):\n",
        "    plt.text(i, v, f\"{v:.2f}\\n({class_counts_sorted[i]})\", color='black', ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Set the figure size\n",
        "plt.figure(figsize=(12, 12))\n",
        "\n",
        "# Plot the recall scores\n",
        "plt.bar(range(len(classes)), recall_sorted, width=0.3, label='Recall', color='lightgreen')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Recall Scores by Class')\n",
        "plt.xticks(range(len(classes)), classes_sorted, rotation='vertical')\n",
        "\n",
        "# Add scores and class counts as text above each bar\n",
        "for i, v in enumerate(recall_sorted):\n",
        "    plt.text(i, v, f\"{v:.2f}\\n({class_counts_sorted[i]})\", color='black', ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Set the figure size\n",
        "plt.figure(figsize=(12, 12))\n",
        "\n",
        "# Plot the F1 scores\n",
        "plt.bar(range(len(classes)), f1_sorted, width=0.3, label='F1 Score', color='orange')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Score')\n",
        "plt.title('F1 Scores by Class')\n",
        "plt.xticks(range(len(classes)), classes_sorted, rotation='vertical')\n",
        "\n",
        "# Add scores and class counts as text above each bar\n",
        "for i, v in enumerate(f1_sorted):\n",
        "    plt.text(i, v, f\"{v:.2f}\\n({class_counts_sorted[i]})\", color='black', ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JUB_NvZWJ9RI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()\n",
        "\n"
      ],
      "metadata": {
        "id": "ZOgNw1B0K_wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Calculate precision, recall, and F1 scores for each class\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_df[\"Class Name\"], pred_labels, average=None)\n",
        "\n",
        "# Calculate the mean F1 score\n",
        "mean_f1 = np.mean(f1)\n",
        "\n",
        "# Get the unique class labels and their counts\n",
        "classes, class_counts = np.unique(test_df[\"Class Name\"], return_counts=True)\n",
        "\n",
        "# Sort precision, recall, F1 scores, and class counts in descending order\n",
        "sorted_indices = np.argsort(f1)[::-1]\n",
        "precision_sorted = precision[sorted_indices]\n",
        "recall_sorted = recall[sorted_indices]\n",
        "f1_sorted = f1[sorted_indices]\n",
        "classes_sorted = classes[sorted_indices]\n",
        "class_counts_sorted = class_counts[sorted_indices]\n",
        "\n",
        "# Set the figure size and create subplots\n",
        "fig, ax = plt.subplots(figsize=(12, 12))\n",
        "\n",
        "# Set the width of the bars\n",
        "bar_width = 0.8\n",
        "\n",
        "# Plot the F1 scores\n",
        "bars = ax.barh(np.arange(len(classes_sorted)), f1_sorted, height=bar_width, color='purple')\n",
        "\n",
        "# Add F1 scores as text inside each bar\n",
        "for i, (bar, score) in enumerate(zip(bars, f1_sorted)):\n",
        "    ax.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height() / 2, f\"{score:.2f}\",\n",
        "            va='center', ha='left', fontsize=7)\n",
        "\n",
        "# Set y-axis ticks and labels\n",
        "ax.set_yticks(np.arange(len(classes_sorted)))\n",
        "ax.set_yticklabels(classes_sorted, fontsize=7)\n",
        "\n",
        "# Set x-axis label and limits\n",
        "ax.set_xlabel('F1 Score', fontsize=10)\n",
        "ax.set_xlim(0, 1)\n",
        "\n",
        "# Add class counts as text near the class names\n",
        "for i, count in enumerate(class_counts_sorted):\n",
        "    ax.text(-0.07, i, f\"  ({count})\", va='center', ha='right', fontsize=8)\n",
        "\n",
        "# Set plot title\n",
        "ax.set_title('F1 Scores by Class', fontsize=12)\n",
        "\n",
        "# Remove spines and ticks\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['left'].set_visible(False)\n",
        "ax.spines['bottom'].set_visible(False)\n",
        "ax.tick_params(left=False, bottom=False)\n",
        "\n",
        "# Add a grid to the plot\n",
        "ax.grid(axis='x', color='lightgray', linestyle='--')\n",
        "\n",
        "# Adjust layout\n",
        "fig.tight_layout()\n",
        "\n",
        "# Invert the y-axis\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Fr4yxMbQM2EF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_iou_scores = []\n",
        "\n",
        "# Calculate the mean IoU score for each class\n",
        "for class_label in classes:\n",
        "    # Get the indices of samples belonging to the current class\n",
        "    class_indices = np.where(test_labels == class_label)[0]\n",
        "\n",
        "    # Extract the predicted and ground truth bounding boxes for the current class\n",
        "    class_pred_boxes = pred_boxes[class_indices]\n",
        "    class_test_boxes = test_boxes[class_indices]\n",
        "\n",
        "    # Calculate the IoU score for each sample\n",
        "    iou_scores = []\n",
        "\n",
        "    for i in range(len(class_indices)):\n",
        "        iou_score = calculate_iou(class_test_boxes[i], class_pred_boxes[i])\n",
        "        iou_scores.append(iou_score)\n",
        "\n",
        "    # Calculate the mean IoU score for the current class\n",
        "    mean_iou_score = np.mean(iou_scores)\n",
        "\n",
        "    # Append the class label, mean IoU score, and number of images to the list of class IoU scores\n",
        "    class_iou_scores.append((class_label, mean_iou_score, len(class_indices)))\n",
        "\n",
        "# Sort the mean IoU scores from best to worst\n",
        "class_iou_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Extract the class labels, mean IoU scores, and number of images into separate lists\n",
        "sorted_classes = [x[0] for x in class_iou_scores]\n",
        "sorted_scores = [x[1] for x in class_iou_scores]\n",
        "num_images = [x[2] for x in class_iou_scores]\n",
        "\n",
        "# Calculate the total mean IoU score\n",
        "total_mean_iou = np.mean(sorted_scores)\n",
        "\n",
        "# Plot the mean IoU scores for each class\n",
        "fig, ax = plt.subplots(figsize=(12, 12))\n",
        "bars = ax.barh(range(len(sorted_classes)), sorted_scores, color='purple')\n",
        "ax.set_xlabel('Mean IoU Score')\n",
        "ax.set_ylabel('Class')\n",
        "ax.set_title('Mean IoU Scores by Class')\n",
        "ax.set_yticks(range(len(sorted_classes)))\n",
        "ax.set_yticklabels(sorted_classes)\n",
        "\n",
        "for i, count in enumerate(class_counts_sorted):\n",
        "    ax.text(-0.1, i, f\"  ({count})\", va='center', ha='right', fontsize=8)\n",
        "\n",
        "# Add scores as text inside each bar\n",
        "for bar, score in zip(bars, sorted_scores):\n",
        "    ax.text(bar.get_width() + 0.005, bar.get_y() + bar.get_height() / 2, f\"{score:.2f}\",\n",
        "            va='center', fontsize=7)\n",
        "\n",
        "# Add total mean IoU score as text at the top\n",
        "ax.text(0, len(sorted_classes), f\"Total Mean IoU: {total_mean_iou:.2f}\", ha='left', va='center', fontsize=12)\n",
        "\n",
        "# Add a vertical line at x=0.5 for reference\n",
        "ax.axvline(x=0.5, color='red', linestyle='--', linewidth=1)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_Znfr_uBQ5TC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate precision, recall, and F1 scores for each class\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_df[\"Class Name\"], pred_labels, average=None)\n",
        "\n",
        "# Calculate the mean F1 score\n",
        "mean_f1 = np.mean(f1)\n",
        "\n",
        "# Get the unique class labels and their counts\n",
        "classes, class_counts = np.unique(test_df[\"Class Name\"], return_counts=True)\n",
        "\n",
        "# Sort precision, recall, F1 scores, and class counts in descending order based on F1 scores\n",
        "sorted_indices = np.argsort(f1)[::-1]\n",
        "precision_sorted = precision[sorted_indices]\n",
        "recall_sorted = recall[sorted_indices]\n",
        "f1_sorted = f1[sorted_indices]\n",
        "classes_sorted = classes[sorted_indices]\n",
        "class_counts_sorted = class_counts[sorted_indices]\n",
        "\n",
        "# Calculate mean IoU score for each class\n",
        "class_iou_scores = []\n",
        "\n",
        "for class_label in classes_sorted:\n",
        "    class_indices = np.where(test_labels == class_label)[0]\n",
        "    class_pred_boxes = pred_boxes[class_indices]\n",
        "    class_test_boxes = test_boxes[class_indices]\n",
        "\n",
        "    iou_scores = []\n",
        "\n",
        "    for i in range(len(class_indices)):\n",
        "        iou_score = calculate_iou(class_test_boxes[i], class_pred_boxes[i])\n",
        "        iou_scores.append(iou_score)\n",
        "\n",
        "    mean_iou_score = np.mean(iou_scores)\n",
        "\n",
        "    class_iou_scores.append(mean_iou_score)\n",
        "\n",
        "# Sort the mean IoU scores from best to worst\n",
        "class_iou_scores_sorted = np.array(class_iou_scores)[sorted_indices]\n",
        "\n",
        "# Set the figure size and create subplots\n",
        "fig, ax = plt.subplots(figsize=(12, 12))\n",
        "\n",
        "# Set the width of the bars\n",
        "bar_width = 0.4\n",
        "\n",
        "# Plot the F1 scores\n",
        "f1_bars = ax.barh(np.arange(len(classes_sorted)), f1_sorted, height=bar_width, color='purple', label='F1 Score')\n",
        "\n",
        "# Plot the mean IoU scores\n",
        "iou_bars = ax.barh(np.arange(len(classes_sorted)) + bar_width, class_iou_scores_sorted, height=bar_width, color='blue', label='Mean IoU')\n",
        "\n",
        "# Add F1 scores as text inside each bar\n",
        "for i, (bar, score) in enumerate(zip(f1_bars, f1_sorted)):\n",
        "    ax.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height() / 2, f\"{score:.2f}\",\n",
        "            va='center', ha='left', fontsize=7)\n",
        "\n",
        "# Add mean IoU scores as text inside each bar\n",
        "for i, (bar, score) in enumerate(zip(iou_bars, class_iou_scores_sorted)):\n",
        "    ax.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height() / 2, f\"{score:.2f}\",\n",
        "            va='center', ha='left', fontsize=7, color='white')\n",
        "\n",
        "# Set y-axis ticks and labels\n",
        "ax.set_yticks(np.arange(len(classes_sorted)) + bar_width / 2)\n",
        "ax.set_yticklabels(classes_sorted, fontsize=7)\n",
        "\n",
        "# Set x-axis label and limits\n",
        "ax.set_xlabel('Scores', fontsize=10)\n",
        "ax.set_xlim(0, 1)\n",
        "\n",
        "# Add class counts as text near the class names\n",
        "for i, count in enumerate(class_counts_sorted):\n",
        "    ax.text(-0.07, i + bar_width / 2, f\"  ({count})\", va='center', ha='right', fontsize=8)\n",
        "\n",
        "# Set plot title\n",
        "ax.set_title('F1 Scores and Mean IoU Scores by Class', fontsize=12)\n",
        "\n",
        "# Remove spines and ticks\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['left'].set_visible(False)\n",
        "ax.spines['bottom'].set_visible(False)\n",
        "ax.tick_params(left=False, bottom=False)\n",
        "\n",
        "# Add a grid to the plot\n",
        "ax.grid(axis='x', color='lightgray', linestyle='--')\n",
        "\n",
        "# Adjust layout\n",
        "fig.tight_layout()\n",
        "\n",
        "# Invert the y-axis\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "# Show the legend\n",
        "ax.legend(loc='lower right')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "i3Eyf7Y9RUs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate precision, recall, and F1 scores for each class\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_df[\"Class Name\"], pred_labels, average=None)\n",
        "\n",
        "# Calculate the mean F1 score\n",
        "mean_f1 = np.mean(f1)\n",
        "\n",
        "# Get the unique class labels and their counts\n",
        "classes, class_counts = np.unique(test_df[\"Class Name\"], return_counts=True)\n",
        "\n",
        "# Sort precision, recall, F1 scores, and class counts in descending order based on F1 scores\n",
        "sorted_indices = np.argsort(f1)[::-1]\n",
        "precision_sorted = precision[sorted_indices]\n",
        "recall_sorted = recall[sorted_indices]\n",
        "f1_sorted = f1[sorted_indices]\n",
        "classes_sorted = classes[sorted_indices]\n",
        "class_counts_sorted = class_counts[sorted_indices]\n",
        "\n",
        "# Calculate mean IoU score for each class\n",
        "class_iou_scores = []\n",
        "\n",
        "for class_label in classes_sorted:\n",
        "    class_indices = np.where(test_labels == class_label)[0]\n",
        "    class_pred_boxes = pred_boxes[class_indices]\n",
        "    class_test_boxes = test_boxes[class_indices]\n",
        "\n",
        "    iou_scores = []\n",
        "\n",
        "    for i in range(len(class_indices)):\n",
        "        iou_score = calculate_iou(class_test_boxes[i], class_pred_boxes[i])\n",
        "        iou_scores.append(iou_score)\n",
        "\n",
        "    mean_iou_score = np.mean(iou_scores)\n",
        "\n",
        "    class_iou_scores.append(mean_iou_score)\n",
        "\n",
        "# Sort the mean IoU scores from best to worst\n",
        "class_iou_scores_sorted = np.array(class_iou_scores)[sorted_indices]\n",
        "\n",
        "# Set the figure size and create subplots\n",
        "fig, ax = plt.subplots(figsize=(12, 12))\n",
        "\n",
        "# Set the width of the bars\n",
        "bar_width = 0.4\n",
        "\n",
        "# Plot the F1 scores\n",
        "f1_bars = ax.barh(np.arange(len(classes_sorted)), f1_sorted, height=bar_width, color='green', label='F1 Score')\n",
        "\n",
        "# Plot the mean IoU scores\n",
        "iou_bars = ax.barh(np.arange(len(classes_sorted)) + bar_width, class_iou_scores_sorted, height=bar_width, color='blue', label='Mean IoU')\n",
        "\n",
        "# Add F1 scores as text inside each bar\n",
        "for i, (bar, score) in enumerate(zip(f1_bars, f1_sorted)):\n",
        "    ax.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height() / 2, f\"{score:.2f}\",\n",
        "            va='center', ha='left', fontsize=7, fontweight='bold', color='red')\n",
        "\n",
        "# Add mean IoU scores as text inside each bar\n",
        "for i, (bar, score) in enumerate(zip(iou_bars, class_iou_scores_sorted)):\n",
        "    ax.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height() / 2, f\"{score:.2f}\",\n",
        "            va='center', ha='left', fontsize=7, fontweight='bold', color='red')\n",
        "\n",
        "# Set y-axis ticks and labels\n",
        "ax.set_yticks(np.arange(len(classes_sorted)) + bar_width / 2)\n",
        "ax.set_yticklabels(classes_sorted, fontsize=7, fontweight='bold', color='black')\n",
        "\n",
        "# Set x-axis label and limits\n",
        "ax.set_xlabel('Scores', fontsize=7, color='red')\n",
        "ax.set_xlim(0, 1)\n",
        "\n",
        "# Add class counts as text near the class names\n",
        "for i, count in enumerate(class_counts_sorted):\n",
        "    ax.text(-0.1, i + bar_width / 2, f\"  ({count})\", va='center', ha='right', fontsize=7, fontweight='bold', color='red')\n",
        "\n",
        "# Set plot title\n",
        "ax.set_title('F1 Scores and Mean IoU Scores by Class', fontsize=14, fontweight='bold', color='red')\n",
        "\n",
        "# Remove spines and ticks\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['left'].set_visible(False)\n",
        "ax.spines['bottom'].set_visible(False)\n",
        "ax.tick_params(left=False, bottom=False)\n",
        "\n",
        "# Add a grid to the plot\n",
        "ax.grid(axis='x', color='lightgray', linestyle='--')\n",
        "\n",
        "# Show the legend\n",
        "ax.legend(loc='upper right', fontsize=7)\n",
        "\n",
        "# Invert the y-axis\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mTeBXeVfTS-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## WE ARE GOING TO SEPERATE CARSIDE DATASET FROM TRAINING ARRAYS:\n",
        "## (WE ARE GOING TO ACCOMPLISH OUR EXPERIMENTS WITH 100 DATASET CLASSES)\n",
        "\n",
        "\n",
        "## * RESNET50 --> MSE --> TRAINABLE = FALSE (TOP ONLY)\n",
        "## * RESNET50 --> MSE --> TRAINABLE = TRUE (ONLY FULL)\n",
        "## * RESNET50 --> MSE --> TRAINABLE = FALSE --> THEN --> TRAINABLE = TRUE (TRAIN SAME MODEL WITH SMALLER LEARNING RATE)\n",
        "\n",
        "\n",
        "## SAME FOR IOU\n",
        "\n",
        "## THEN SHOE THE RESULTS OF CARSIDE\n",
        "\n",
        "\n",
        "## CREATE TABLE TO SHOW OUTPUTS IN BETTER WAY"
      ],
      "metadata": {
        "id": "XYn7goIeTeAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## LET'S IMPORT THE DATAFRAMES FOR VALIDATION, TEST AND TRAIN\n",
        "\n",
        "train_path = '/content/drive/My Drive/train_df.csv'\n",
        "train_df = pd.read_csv(train_path)\n",
        "\n",
        "val_path = '/content/drive/My Drive/val_df.csv'\n",
        "val_df = pd.read_csv(val_path)\n",
        "\n",
        "test_path = '/content/drive/My Drive/test_df.csv'\n",
        "test_df = pd.read_csv(test_path)"
      ],
      "metadata": {
        "id": "fThg0N2P1D_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_df))\n",
        "print(len(test_df))\n",
        "print(len(val_df))\n"
      ],
      "metadata": {
        "id": "e6zChmml1SjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Filter rows with 'carside' class and create a new DataFrame\n",
        "carside_df = train_df[train_df['Class Name'] == 'carside'].copy()\n",
        "\n",
        "# Remove rows with 'carside' class from the original DataFrame\n",
        "train_df = train_df[train_df['Class Name'] != 'carside']\n",
        "\n",
        "# Reset the index of the new DataFrame\n",
        "carside_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Reset the index of the original DataFrame\n",
        "train_df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "8V5jvjAr1aTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(carside_df))\n",
        "print(len(train_df))"
      ],
      "metadata": {
        "id": "HeLB5_za1m67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Filter rows with 'carside' class and create a new DataFrame\n",
        "val_carside_df = val_df[val_df['Class Name'] == 'carside'].copy()\n",
        "\n",
        "# Remove rows with 'carside' class from the original DataFrame\n",
        "val_df = val_df[val_df['Class Name'] != 'carside']\n",
        "\n",
        "# Reset the index of the new DataFrame\n",
        "val_carside_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Reset the index of the original DataFrame\n",
        "val_df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "BPDEpySH1uHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(val_carside_df))\n",
        "print(len(val_df))"
      ],
      "metadata": {
        "id": "iWN9k5i_1_c2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Filter rows with 'carside' class and create a new DataFrame\n",
        "test_carside_df = test_df[test_df['Class Name'] == 'carside'].copy()\n",
        "\n",
        "# Remove rows with 'carside' class from the original DataFrame\n",
        "test_df = test_df[test_df['Class Name'] != 'carside']\n",
        "\n",
        "# Reset the index of the new DataFrame\n",
        "test_carside_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Reset the index of the original DataFrame\n",
        "test_df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "dvp_bJ-g2Dnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(test_carside_df))\n",
        "print(len(test_df))"
      ],
      "metadata": {
        "id": "fN8P5LG-2N_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Set the parent directory path\n",
        "parent_dir = \"/content/drive/MyDrive/\"\n",
        "\n",
        "# Set the directory name\n",
        "directory_name = \"project_mark1\"\n",
        "\n",
        "# Combine the parent directory path and directory name\n",
        "directory_path = os.path.join(parent_dir, directory_name)\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(directory_path, exist_ok=True)\n",
        "\n",
        "# Print the path of the created directory\n",
        "print(\"Directory created:\", directory_path)"
      ],
      "metadata": {
        "id": "BRQ3TV_a2Rkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Set the parent directory path\n",
        "parent_dir = \"/content/drive/MyDrive/project_mark1\"\n",
        "\n",
        "# Save train_df to CSV\n",
        "train_df.to_csv(os.path.join(parent_dir, \"train_df.csv\"), index=False)\n",
        "\n",
        "# Save val_df to CSV\n",
        "val_df.to_csv(os.path.join(parent_dir, \"val_df.csv\"), index=False)\n",
        "\n",
        "# Save test_df to CSV\n",
        "test_df.to_csv(os.path.join(parent_dir, \"test_df.csv\"), index=False)\n",
        "\n",
        "# Save test_carside_df to CSV\n",
        "test_carside_df.to_csv(os.path.join(parent_dir, \"test_carside_df.csv\"), index=False)\n",
        "\n",
        "# Save val_carside_df to CSV\n",
        "val_carside_df.to_csv(os.path.join(parent_dir, \"val_carside_df.csv\"), index=False)\n",
        "\n",
        "# Save carside_df to CSV\n",
        "carside_df.to_csv(os.path.join(parent_dir, \"carside_df.csv\"), index=False)\n",
        "\n",
        "print(\"Files saved in directory:\", parent_dir)"
      ],
      "metadata": {
        "id": "pGCZDy5t3Bw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#########################################\n",
        "####### controls for 'carside' ##########\n",
        "\n",
        "test_carside_df.head()"
      ],
      "metadata": {
        "id": "JAUgZO4C3WT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_carside_df.head()"
      ],
      "metadata": {
        "id": "_7pAn52R3dHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "carside_df.head()"
      ],
      "metadata": {
        "id": "oGeBtETw3xVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the occurrences of each class name in the train_df DataFrame\n",
        "class_counts = train_df['Class Name'].value_counts()\n",
        "\n",
        "# Check if the class name 'carside' exists in the DataFrame\n",
        "if 'carside' in class_counts:\n",
        "    # Get the number of classes with the class name 'carside'\n",
        "    num_classes_carside = class_counts['carside']\n",
        "    print(f\"The number of classes with the class name 'carside': {num_classes_carside}\")\n",
        "else:\n",
        "    print(\"No classes with the class name 'carside' found.\")"
      ],
      "metadata": {
        "id": "bKYgOH4q3zAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the occurrences of each class name in the train_df DataFrame\n",
        "class_counts = val_df['Class Name'].value_counts()\n",
        "\n",
        "# Check if the class name 'carside' exists in the DataFrame\n",
        "if 'carside' in class_counts:\n",
        "    # Get the number of classes with the class name 'carside'\n",
        "    num_classes_carside = class_counts['carside']\n",
        "    print(f\"The number of classes with the class name 'carside': {num_classes_carside}\")\n",
        "else:\n",
        "    print(\"No classes with the class name 'carside' found.\")"
      ],
      "metadata": {
        "id": "eI_Q5WAL34cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the occurrences of each class name in the train_df DataFrame\n",
        "class_counts = test_df['Class Name'].value_counts()\n",
        "\n",
        "# Check if the class name 'carside' exists in the DataFrame\n",
        "if 'carside' in class_counts:\n",
        "    # Get the number of classes with the class name 'carside'\n",
        "    num_classes_carside = class_counts['carside']\n",
        "    print(f\"The number of classes with the class name 'carside': {num_classes_carside}\")\n",
        "else:\n",
        "    print(\"No classes with the class name 'carside' found.\")"
      ],
      "metadata": {
        "id": "mvopCTpK36Qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the occurrences of each class name in the train_df DataFrame\n",
        "class_counts = carside_df['Class Name'].value_counts()\n",
        "\n",
        "# Check if the class name 'carside' exists in the DataFrame\n",
        "if 'carside' in class_counts:\n",
        "    # Get the number of classes with the class name 'carside'\n",
        "    num_classes_carside = class_counts['carside']\n",
        "    print(f\"The number of classes with the class name 'carside': {num_classes_carside}\")\n",
        "else:\n",
        "    print(\"No classes with the class name 'carside' found.\")"
      ],
      "metadata": {
        "id": "wH27oWc938Wf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the occurrences of each class name in the train_df DataFrame\n",
        "class_counts = val_carside_df['Class Name'].value_counts()\n",
        "\n",
        "# Check if the class name 'carside' exists in the DataFrame\n",
        "if 'carside' in class_counts:\n",
        "    # Get the number of classes with the class name 'carside'\n",
        "    num_classes_carside = class_counts['carside']\n",
        "    print(f\"The number of classes with the class name 'carside': {num_classes_carside}\")\n",
        "else:\n",
        "    print(\"No classes with the class name 'carside' found.\")"
      ],
      "metadata": {
        "id": "B7oKGMl73-ZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the occurrences of each class name in the train_df DataFrame\n",
        "class_counts = test_carside_df['Class Name'].value_counts()\n",
        "\n",
        "# Check if the class name 'carside' exists in the DataFrame\n",
        "if 'carside' in class_counts:\n",
        "    # Get the number of classes with the class name 'carside'\n",
        "    num_classes_carside = class_counts['carside']\n",
        "    print(f\"The number of classes with the class name 'carside': {num_classes_carside}\")\n",
        "else:\n",
        "    print(\"No classes with the class name 'carside' found.\")"
      ],
      "metadata": {
        "id": "c4XRtJtL4B_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################################################\n",
        "######## okey we have now train - test - val df's ##########\n",
        "############################################################\n",
        "################# we also have carside dataset ###########\n",
        "############################################################\n"
      ],
      "metadata": {
        "id": "f-4fYSTZ4Kd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **100 classes resnet50 - mse - trainable = Ture**"
      ],
      "metadata": {
        "id": "ChbuPwvi4i3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def iou_loss(y_true, y_pred):\n",
        "    # Extract the normalized coordinates of the predicted and ground truth boxes\n",
        "    pred_x1, pred_y1, pred_x2, pred_y2 = tf.unstack(y_pred, axis=1)\n",
        "    true_x1, true_y1, true_x2, true_y2 = tf.unstack(y_true, axis=1)\n",
        "\n",
        "    # Convert normalized coordinates to absolute coordinates\n",
        "    pred_x1 = pred_x1 * 512\n",
        "    pred_y1 = pred_y1 * 512\n",
        "    pred_x2 = pred_x2 * 512\n",
        "    pred_y2 = pred_y2 * 512\n",
        "    true_x1 = true_x1 * 512\n",
        "    true_y1 = true_y1 * 512\n",
        "    true_x2 = true_x2 * 512\n",
        "    true_y2 = true_y2 * 512\n",
        "\n",
        "    # Calculate the coordinates of the intersection rectangle\n",
        "    x1 = tf.maximum(pred_x1, true_x1)\n",
        "    y1 = tf.maximum(pred_y1, true_y1)\n",
        "    x2 = tf.minimum(pred_x2, true_x2)\n",
        "    y2 = tf.minimum(pred_y2, true_y2)\n",
        "\n",
        "    # Calculate the area of intersection\n",
        "    intersection = tf.maximum(0.0, x2 - x1) * tf.maximum(0.0, y2 - y1)\n",
        "\n",
        "    # Calculate the area of predicted and ground truth boxes\n",
        "    pred_area = (pred_x2 - pred_x1) * (pred_y2 - pred_y1)\n",
        "    true_area = (true_x2 - true_x1) * (true_y2 - true_y1)\n",
        "\n",
        "    # Calculate the union area\n",
        "    union = pred_area + true_area - intersection\n",
        "\n",
        "    # Calculate the IoU\n",
        "    iou = intersection / (union + tf.keras.backend.epsilon())\n",
        "\n",
        "    # Calculate the IoU loss\n",
        "    iou_loss = 1.0 - iou\n",
        "\n",
        "    return iou_loss"
      ],
      "metadata": {
        "id": "sgu2XP1JpOWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import get_custom_objects\n",
        "\n",
        "\n",
        "losses = {\n",
        "    \"class_label\": \"categorical_crossentropy\",\n",
        "    \"bounding_box\": \"iou_loss\",\n",
        "}\n",
        "\n",
        "get_custom_objects().update({'iou_loss': iou_loss})\n"
      ],
      "metadata": {
        "id": "VsWvyAuspiyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####################################################\n",
        "############## MOST IMPORTANT PART #################\n",
        "####################################################\n",
        "def resize_image(image, target_size):\n",
        "    return cv2.resize(image, target_size)\n",
        "\n",
        "def plot_images(images, boxes, labels, dataset_name):\n",
        "    fig, axes = plt.subplots(1, len(images), figsize=(12, 4))\n",
        "    for i, ax in enumerate(axes):\n",
        "        ax.imshow(images[i])\n",
        "        xmin, ymin, xmax, ymax = boxes[i]\n",
        "        ax.add_patch(plt.Rectangle((xmin*224, ymin*224), xmax*224 - xmin*224, ymax*224 - ymin*224, fill=False, color='red', linewidth=2))\n",
        "        ax.set_title(labels[i])\n",
        "        ax.axis('off')\n",
        "    plt.suptitle(f'{dataset_name} Images with Bounding Boxes')\n",
        "    plt.show()\n",
        "\n",
        "# Append data from val_df into arrays\n",
        "val_images = []\n",
        "val_boxes = []\n",
        "val_labels = []\n",
        "\n",
        "for index, row in val_df.iterrows():\n",
        "    image_path = row['Image Path']\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = resize_image(image, (224, 224))\n",
        "    val_images.append(image)\n",
        "\n",
        "    xmin, ymin, xmax, ymax = map(float, [row['Xmin'], row['Ymin'], row['Xmax'], row['Ymax']])\n",
        "    val_boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "    label = row['Class Name']\n",
        "    val_labels.append(label)\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "val_images = np.array(val_images, dtype='float32')\n",
        "val_boxes = np.array(val_boxes, dtype='float32')\n",
        "val_labels = np.array(val_labels)\n",
        "\n",
        "# Normalize the images\n",
        "val_images = val_images / 255.0\n",
        "\n",
        "\n",
        "\n",
        "# Append data from train_df into arrays\n",
        "train_images = []\n",
        "train_boxes = []\n",
        "train_labels = []\n",
        "\n",
        "for index, row in train_df.iterrows():\n",
        "    image_path = row['Image Path']\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = resize_image(image, (224, 224))\n",
        "    train_images.append(image)\n",
        "\n",
        "    xmin, ymin, xmax, ymax = map(float, [row['Xmin'], row['Ymin'], row['Xmax'], row['Ymax']])\n",
        "    train_boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "    label = row['Class Name']\n",
        "    train_labels.append(label)\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "train_images = np.array(train_images, dtype='float32')\n",
        "train_boxes = np.array(train_boxes, dtype='float32')\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "# Normalize the images\n",
        "train_images = train_images / 255.0\n",
        "\n",
        "\n",
        "\n",
        "# Append data from test_df into arrays\n",
        "test_images = []\n",
        "test_boxes = []\n",
        "test_labels = []\n",
        "\n",
        "for index, row in test_df.iterrows():\n",
        "    image_path = row['Image Path']\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = resize_image(image, (224, 224))\n",
        "    test_images.append(image)\n",
        "\n",
        "    xmin, ymin, xmax, ymax = map(float, [row['Xmin'], row['Ymin'], row['Xmax'], row['Ymax']])\n",
        "    test_boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "    label = row['Class Name']\n",
        "    test_labels.append(label)\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "test_images = np.array(test_images, dtype='float32')\n",
        "test_boxes = np.array(test_boxes, dtype='float32')\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "# Normalize the images\n",
        "test_images = test_images / 255.0\n"
      ],
      "metadata": {
        "id": "DTCVCXx-4rpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Perform label encoding on the target labels\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
        "val_labels_encoded = label_encoder.transform(val_labels)\n",
        "\n",
        "# Convert the encoded labels to one-hot encoding\n",
        "train_labels_onehot = to_categorical(train_labels_encoded, num_classes=100) ## ==> update number of classes\n",
        "val_labels_onehot = to_categorical(val_labels_encoded, num_classes=100) ## ==> update number of classes\n",
        "\n",
        "# Model architecture\n",
        "input_layer = Input(shape=(224, 224, 3))\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=input_layer)\n",
        "\n",
        "\n",
        "flatten = Flatten()(base_model.output)\n",
        "\n",
        "\n",
        "bboxHead = Dense(1024, activation=\"relu\")(flatten)\n",
        "\n",
        "bboxHead = Dense(512, activation=\"relu\")(bboxHead)\n",
        "\n",
        "bbox_output = Dense(4, activation='linear', name='bounding_box')(bboxHead)\n",
        "\n",
        "\n",
        "\n",
        "softmaxHead = Dense(1024, activation=\"relu\")(flatten)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "\n",
        "softmaxHead = Dense(512, activation=\"relu\")(softmaxHead)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "\n",
        "class_output = Dense(100, activation='softmax', name='class_output')(softmaxHead) ## ==> update number of classes\n",
        "\n",
        "model_resnet_mse_1 = Model(inputs=input_layer, outputs=[class_output, bbox_output])\n",
        "\n",
        "\n",
        "\n",
        "# Set the learning rate\n",
        "learning_rate = 1e-4\n",
        "\n",
        "# Create the optimizer with the desired learning rate\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=optimizer, loss={'class_output': 'categorical_crossentropy', 'bounding_box': iou_loss})\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "ZPYiBABI7Khh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "#Your Model code here use the Keras Sequential Architecture\n",
        "\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "hANp4fjGnI4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualkeras.layered_view(model).show()\n"
      ],
      "metadata": {
        "id": "xq617fynnI17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualkeras.layered_view(model, scale_xy=1, scale_z=1, max_z=100)\n"
      ],
      "metadata": {
        "id": "5u6J9B6DqUaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualkeras.layered_view(model, legend=True, draw_volume=False,spacing=30, scale_xy=1, scale_z=1, max_z=100)\n"
      ],
      "metadata": {
        "id": "ADgrli4lvBrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n"
      ],
      "metadata": {
        "id": "9SyvpgiCvnad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import graphviz\n",
        "\n",
        "\n",
        "ann_viz(model , view=True, title= 'My Model')\n"
      ],
      "metadata": {
        "id": "wl03zfLknIxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualkeras.layered_view(model, legend=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BTWFss5Vs1nQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualkeras.layered_view(model, scale_xy=1, scale_z=1, max_z=200)\n"
      ],
      "metadata": {
        "id": "gjbHqoNMuMBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_dot(model)\n"
      ],
      "metadata": {
        "id": "boIOCmETs1kS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "28w7ZRWCs1hT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5THjQxgbs1fJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(\n",
        "    model,\n",
        "    to_file=\"model.png\",\n",
        "    show_shapes=False,\n",
        "    show_dtype=False,\n",
        "    show_layer_names=True,\n",
        "    rankdir=\"TB\",\n",
        "    expand_nested=False,\n",
        "    dpi=96,\n",
        "    layer_range=None,\n",
        "    show_layer_activations=False,\n",
        "    show_trainable=False,\n",
        ")"
      ],
      "metadata": {
        "id": "a346ms__nIvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=7)\n",
        "\n",
        "\n",
        "# Train the model with early stopping\n",
        "model = model.fit(train_images, {'class_output': train_labels_onehot, 'bounding_box': train_boxes},\n",
        "                    validation_data=(val_images, {'class_output': val_labels_onehot, 'bounding_box': val_boxes}),\n",
        "                    epochs=300, batch_size=128, callbacks=[callback])\n",
        "\n",
        "# Save the trained model\n",
        "model.save('/content/drive/MyDrive/model__model.h5')\n"
      ],
      "metadata": {
        "id": "vnJY4Skr9-ZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FOeYDCoOlGM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "coPzfPCXlGKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iBOzAVo3lGHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the label encoder\n",
        "with open('/content/drive/MyDrive/project_mark1/model_resnet_mse_1_label_encoder.pkl', 'wb') as file:\n",
        "    pickle.dump(label_encoder, file)"
      ],
      "metadata": {
        "id": "cwAvCpoW7-ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the losses\n",
        "plt.figure(figsize=(24, 12))\n",
        "plt.style.use('seaborn')\n",
        "\n",
        "# Classification Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(model_resnet_mse_1_history.history['class_output_loss'], label='Train Classification Loss', color='blue')\n",
        "plt.plot(model_resnet_mse_1_history.history['val_class_output_loss'], label='Validation Classification Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Classification Loss', fontsize=12)\n",
        "plt.legend()\n",
        "\n",
        "# Bounding Box Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(model_resnet_mse_1_history.history['bounding_box_loss'], label='Train Bounding Box Loss', color='blue')\n",
        "plt.plot(model_resnet_mse_1_history.history['val_bounding_box_loss'], label='Validation Bounding Box Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Bounding Box Loss', fontsize=12)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1houJfbe9xEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pf3MpKNjqJ4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the history object to a file using pickle\n",
        "with open('model_resnet_mse_1_history.pkl', 'wb') as file:\n",
        "    pickle.dump(model_resnet_mse_1_history.history, file)"
      ],
      "metadata": {
        "id": "bNoiHSnYEnjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the entire model to a HDF5 file\n",
        "model_resnet_mse_1.save('/content/drive/MyDrive/project_mark1/model_resnet_mse_1.h5')"
      ],
      "metadata": {
        "id": "O0UP2bi2Eu1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the history object to a file using pickle\n",
        "with open('/content/drive/MyDrive/project_mark1/model_resnet_mse_1_history.pkl', 'wb') as file:\n",
        "    pickle.dump(model_resnet_mse_1_history.history, file)\n"
      ],
      "metadata": {
        "id": "7NjnGfY2FMhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### --> instead of iou names I have the mse names for results of iou"
      ],
      "metadata": {
        "id": "x9xNSfnhF73n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **100 classes resnet50 - mse - trainable = false**"
      ],
      "metadata": {
        "id": "Ho5QxGu4GtBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Perform label encoding on the target labels\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
        "val_labels_encoded = label_encoder.transform(val_labels)\n",
        "\n",
        "# Convert the encoded labels to one-hot encoding\n",
        "train_labels_onehot = to_categorical(train_labels_encoded, num_classes=100) ## ==> update number of classes\n",
        "val_labels_onehot = to_categorical(val_labels_encoded, num_classes=100) ## ==> update number of classes\n",
        "\n",
        "# Model architecture\n",
        "input_layer = Input(shape=(224, 224, 3))\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=input_layer)\n",
        "\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "\n",
        "flatten = Flatten()(base_model.output)\n",
        "\n",
        "\n",
        "bboxHead = Dense(1024, activation=\"relu\")(flatten)\n",
        "\n",
        "bboxHead = Dense(512, activation=\"relu\")(bboxHead)\n",
        "\n",
        "bboxHead = Dense(256, activation=\"relu\")(bboxHead)\n",
        "\n",
        "bboxHead = Dense(128, activation=\"relu\")(bboxHead)\n",
        "\n",
        "bboxHead = Dense(64, activation=\"relu\")(bboxHead)\n",
        "\n",
        "\n",
        "bboxHead = Dense(32, activation=\"relu\")(bboxHead)\n",
        "\n",
        "\n",
        "\n",
        "bbox_output = Dense(4, activation='linear', name='bounding_box')(bboxHead)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "softmaxHead = Dense(1024, activation=\"relu\")(flatten)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "\n",
        "softmaxHead = Dense(512, activation=\"relu\")(softmaxHead)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "\n",
        "softmaxHead = Dense(256, activation=\"relu\")(softmaxHead)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "\n",
        "softmaxHead = Dense(128, activation=\"relu\")(softmaxHead)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "\n",
        "class_output = Dense(100, activation='softmax', name='class_output')(softmaxHead) ## ==> update number of classes\n",
        "\n",
        "\n",
        "\n",
        "model_resnet_mse_2 = Model(inputs=input_layer, outputs=[class_output, bbox_output])\n",
        "\n",
        "# Set the learning rate\n",
        "learning_rate = 1e-4\n",
        "\n",
        "# Create the optimizer with the desired learning rate\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model_resnet_mse_2.compile(optimizer= optimizer, loss={'class_output': 'categorical_crossentropy', 'bounding_box': iou_loss})\n",
        "\n",
        "model_resnet_mse_2.summary()"
      ],
      "metadata": {
        "id": "SkBHsw_qG123"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## at least we understand how we are going to train them:"
      ],
      "metadata": {
        "id": "yutrZo6dI8v4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=7)\n",
        "\n",
        "\n",
        "# Train the model with early stopping\n",
        "model_resnet_mse_2_history = model_resnet_mse_2.fit(train_images, {'class_output': train_labels_onehot, 'bounding_box': train_boxes},\n",
        "                    validation_data=(val_images, {'class_output': val_labels_onehot, 'bounding_box': val_boxes}),\n",
        "                    epochs=300, batch_size=32, callbacks=[callback])\n",
        "\n",
        "# Save the trained model\n",
        "model_resnet_mse_2.save('/content/drive/MyDrive/project_mark1/model_resnet_mse_2_trained_model.h5')"
      ],
      "metadata": {
        "id": "RpYnwHjRHEgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the losses\n",
        "plt.figure(figsize=(12, 7))\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "\n",
        "# Classification Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(model_resnet_mse_2_history.history['class_output_loss'], label='Train Classification Loss', color='blue')\n",
        "plt.plot(model_resnet_mse_2_history.history['val_class_output_loss'], label='Validation Classification Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Classification Loss', fontsize=12)\n",
        "plt.legend()\n",
        "\n",
        "# Bounding Box Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(model_resnet_mse_2_history.history['bounding_box_loss'], label='Train Bounding Box Loss', color='blue')\n",
        "plt.plot(model_resnet_mse_2_history.history['val_bounding_box_loss'], label='Validation Bounding Box Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Bounding Box Loss', fontsize=12)\n",
        "plt.legend()\n",
        "\n",
        "# Set plot limits and tick parameters\n",
        "num_epochs = len(model_resnet_mse_2_history.history['class_output_loss'])\n",
        "max_loss = max(max(model_resnet_mse_2_history.history['class_output_loss']), max(model_resnet_mse_2_history.history['bounding_box_loss']))\n",
        "plt.xlim(0, num_epochs - 1)\n",
        "plt.ylim(0, max_loss)\n",
        "plt.xticks(fontsize=10)\n",
        "plt.yticks(fontsize=10)\n",
        "\n",
        "# Add annotations for the first and last values\n",
        "first_class_loss = model_resnet_mse_2_history.history['class_output_loss'][0]\n",
        "last_class_loss = model_resnet_mse_2_history.history['class_output_loss'][-1]\n",
        "first_bbox_loss = model_resnet_mse_2_history.history['bounding_box_loss'][0]\n",
        "last_bbox_loss = model_resnet_mse_2_history.history['bounding_box_loss'][-1]\n",
        "plt.annotate(f'First: {first_class_loss:.4f}', xy=(0, first_class_loss), xytext=(10, 5), textcoords='offset points', color='blue', fontsize=10)\n",
        "plt.annotate(f'Last: {last_class_loss:.4f}', xy=(num_epochs - 1, last_class_loss), xytext=(-60, -15), textcoords='offset points', color='blue', fontsize=10)\n",
        "plt.annotate(f'First: {first_bbox_loss:.4f}', xy=(0, first_bbox_loss), xytext=(10, 5), textcoords='offset points', color='blue', fontsize=10)\n",
        "plt.annotate(f'Last: {last_bbox_loss:.4f}', xy=(num_epochs - 1, last_bbox_loss), xytext=(-60, -15), textcoords='offset points', color='blue', fontsize=10)\n",
        "\n",
        "# Add a grid for better readability\n",
        "plt.grid(color='lightgray')\n",
        "\n",
        "# Adjust the layout to avoid overlapping annotations\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KzD4JXKWduKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d1DCTb_ThW_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iUQ_I8cFhW9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the label encoder\n",
        "with open('/content/drive/MyDrive/project_mark1/model_resnet_mse_2_label_encoder.pkl', 'wb') as file:\n",
        "    pickle.dump(label_encoder, file)"
      ],
      "metadata": {
        "id": "hk5Gu_JZI1ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the losses\n",
        "plt.figure(figsize=(24, 12))\n",
        "plt.style.use('seaborn')\n",
        "\n",
        "# Classification Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(model_resnet_mse_2_history.history['class_output_loss'], label='Train Classification Loss', color='blue')\n",
        "plt.plot(model_resnet_mse_2_history.history['val_class_output_loss'], label='Validation Classification Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Classification Loss', fontsize=12)\n",
        "plt.legend()\n",
        "\n",
        "# Bounding Box Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(model_resnet_mse_2_history.history['bounding_box_loss'], label='Train Bounding Box Loss', color='blue')\n",
        "plt.plot(model_resnet_mse_2_history.history['val_bounding_box_loss'], label='Validation Bounding Box Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Bounding Box Loss', fontsize=12)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "l1t23Ed9I1po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the history object to a file using pickle\n",
        "with open('model_resnet_mse_2_history.pkl', 'wb') as file:\n",
        "    pickle.dump(model_resnet_mse_2_history.history, file)"
      ],
      "metadata": {
        "id": "XZOXo0s5J4z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the entire model to a HDF5 file\n",
        "model_resnet_mse_2.save('/content/drive/MyDrive/project_mark1/model_resnet_mse_2.h5')"
      ],
      "metadata": {
        "id": "8LjGZHKaKgT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the history object to a file using pickle\n",
        "with open('/content/drive/MyDrive/project_mark1/model_resnet_mse_2_history.pkl', 'wb') as file:\n",
        "    pickle.dump(model_resnet_mse_2_history.history, file)"
      ],
      "metadata": {
        "id": "0jAk3OkZKgRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h3PUA8XtLiZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **100 classes resnet50 - mse - trainable = false - then - trainable = true with lower learning rate**"
      ],
      "metadata": {
        "id": "eNoNnQJLLjNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Flatten, Dense, Dropout\n",
        "from keras.applications import ResNet50\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)            ### --> Canan Hocaya sor ???\n",
        "\n",
        "# Perform label encoding on the target labels\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
        "val_labels_encoded = label_encoder.transform(val_labels)\n",
        "\n",
        "# Convert the encoded labels to one-hot encoding\n",
        "num_classes = 100  # Update with the actual number of classes\n",
        "train_labels_onehot = to_categorical(train_labels_encoded, num_classes=num_classes)\n",
        "val_labels_onehot = to_categorical(val_labels_encoded, num_classes=num_classes)\n",
        "\n",
        "# Model architecture\n",
        "input_layer = Input(shape=(224, 224, 3))\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=input_layer)\n",
        "\n",
        "flatten = Flatten()(base_model.output)\n",
        "\n",
        "# Top layers for bounding box regression\n",
        "bboxHead = Dense(1024, activation=\"relu\")(flatten)\n",
        "# bboxHead = Dense(1024, activation=\"relu\")(bboxHead)\n",
        "# bboxHead = Dense(1024, activation=\"relu\")(bboxHead)\n",
        "\n",
        "\n",
        "# bboxHead = Dense(512, activation=\"relu\")(bboxHead)\n",
        "# bboxHead = Dense(512, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(512, activation=\"relu\")(bboxHead)\n",
        "\n",
        "# bboxHead = Dense(256, activation=\"relu\")(bboxHead)\n",
        "# bboxHead = Dense(256, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(256, activation=\"relu\")(bboxHead)\n",
        "\n",
        "# bboxHead = Dense(128, activation=\"relu\")(bboxHead)\n",
        "# bboxHead = Dense(128, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(128, activation=\"relu\")(bboxHead)\n",
        "\n",
        "# bboxHead = Dense(64, activation=\"relu\")(bboxHead)\n",
        "# bboxHead = Dense(64, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(64, activation=\"relu\")(bboxHead)\n",
        "\n",
        "# bboxHead = Dense(32, activation=\"relu\")(bboxHead)\n",
        "# bboxHead = Dense(32, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(32, activation=\"relu\")(bboxHead)\n",
        "\n",
        "# bboxHead = Dense(16, activation=\"relu\")(bboxHead)\n",
        "# bboxHead = Dense(16, activation=\"relu\")(bboxHead)\n",
        "# bboxHead = Dense(16, activation=\"relu\")(bboxHead)\n",
        "\n",
        "# bboxHead = Dense(8, activation=\"relu\")(bboxHead)\n",
        "# bboxHead = Dense(8, activation=\"relu\")(bboxHead)\n",
        "# bboxHead = Dense(8, activation=\"relu\")(bboxHead)\n",
        "\n",
        "\n",
        "bbox_output = Dense(4, activation='linear', name='bounding_box')(bboxHead)\n",
        "\n",
        "# Top layers for classification\n",
        "softmaxHead = Dense(1024, activation=\"relu\")(flatten)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "softmaxHead = Dense(512, activation=\"relu\")(softmaxHead)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "softmaxHead = Dense(256, activation=\"relu\")(softmaxHead)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "softmaxHead = Dense(128, activation=\"relu\")(softmaxHead)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "class_output = Dense(num_classes, activation='softmax', name='class_output')(softmaxHead)\n",
        "\n",
        "# Create the first model (train only the top layers)\n",
        "model_top_layers = Model(inputs=input_layer, outputs=[class_output, bbox_output])\n",
        "\n",
        "# Freeze the base model's layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "learning_rate = 1e-4\n",
        "\n",
        "# Compile the model for training only the top layers\n",
        "model_top_layers.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss={'class_output': 'categorical_crossentropy', 'bounding_box': iou_loss})\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=7)\n",
        "\n",
        "\n",
        "# Train only the top layers\n",
        "model_top_layers_history = model_top_layers.fit(train_images, {'class_output': train_labels_onehot, 'bounding_box': train_boxes},\n",
        "                                                validation_data=(val_images, {'class_output': val_labels_onehot, 'bounding_box': val_boxes}),\n",
        "                                                epochs=300, batch_size=32, callbacks=[callback])\n",
        "\n",
        "\n",
        "\n",
        "# Unfreeze the base model's layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "\n",
        "\n",
        "# Recompile the model with a smaller learning rate for fine-tuning\n",
        "learning_rate = 1e-5  # Update with the desired learning rate\n",
        "model_top_layers.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss={'class_output': 'categorical_crossentropy', 'bounding_box': iou_loss})              #### --> Canan Hocaya sor ???\n",
        "\n",
        "# Train the model with fine-tuning\n",
        "model_fine_tuned_history = model_top_layers.fit(train_images, {'class_output': train_labels_onehot, 'bounding_box': train_boxes},\n",
        "                                                validation_data=(val_images, {'class_output': val_labels_onehot, 'bounding_box': val_boxes}),\n",
        "                                                epochs=300, batch_size=32, callbacks=[callback])\n"
      ],
      "metadata": {
        "id": "oAd0GWg_Ls7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the label encoder\n",
        "with open('/content/drive/MyDrive/project_mark1/model_top_layers_label_encoder.pkl', 'wb') as file:\n",
        "    pickle.dump(label_encoder, file)\n",
        "\n",
        "# Save the entire model to a HDF5 file\n",
        "model_top_layers.save('/content/drive/MyDrive/project_mark1/model_top_layers.h5')\n",
        "\n",
        "# Save the history object to a file using pickle\n",
        "with open('/content/drive/MyDrive/project_mark1/model_fine_tuned_history.pkl', 'wb') as file:\n",
        "    pickle.dump(model_fine_tuned_history.history, file)"
      ],
      "metadata": {
        "id": "PBQ6Su3FMKtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the losses\n",
        "plt.figure(figsize=(24, 12))\n",
        "plt.style.use('seaborn')\n",
        "\n",
        "# Classification Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(model_fine_tuned_history.history['class_output_loss'], label='Train Classification Loss', color='blue')\n",
        "plt.plot(model_fine_tuned_history.history['val_class_output_loss'], label='Validation Classification Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Classification Loss', fontsize=12)\n",
        "plt.legend()\n",
        "\n",
        "# Bounding Box Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(model_fine_tuned_history.history['bounding_box_loss'], label='Train Bounding Box Loss', color='blue')\n",
        "plt.plot(model_fine_tuned_history.history['val_bounding_box_loss'], label='Validation Bounding Box Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Bounding Box Loss', fontsize=12)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "grr96XsPO1E3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the losses\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "\n",
        "# Classification Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(model_resnet_mse_1_history.history['class_output_loss'], label='Train Classification Loss', color='blue')\n",
        "plt.plot(model_resnet_mse_1_history.history['val_class_output_loss'], label='Validation Classification Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Classification Loss', fontsize=12)\n",
        "plt.legend()\n",
        "\n",
        "# Bounding Box Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(model_resnet_mse_1_history.history['bounding_box_loss'], label='Train Bounding Box Loss', color='blue')\n",
        "plt.plot(model_resnet_mse_1_history.history['val_bounding_box_loss'], label='Validation Bounding Box Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Bounding Box Loss', fontsize=12)\n",
        "plt.legend()\n",
        "\n",
        "# Set plot limits and tick parameters\n",
        "num_epochs = len(model_resnet_mse_1_history.history['class_output_loss'])\n",
        "max_loss = max(max(model_resnet_mse_1_history.history['class_output_loss']), max(model_resnet_mse_1_history.history['bounding_box_loss']))\n",
        "plt.xlim(0, num_epochs - 1)\n",
        "plt.ylim(0, max_loss)\n",
        "plt.xticks(fontsize=10)\n",
        "plt.yticks(fontsize=10)\n",
        "\n",
        "# Add annotations for the first and last values\n",
        "first_class_loss = model_resnet_mse_1_history.history['class_output_loss'][0]\n",
        "last_class_loss = model_resnet_mse_1_history.history['class_output_loss'][-1]\n",
        "first_bbox_loss = model_resnet_mse_1_history.history['bounding_box_loss'][0]\n",
        "last_bbox_loss = model_resnet_mse_1_history.history['bounding_box_loss'][-1]\n",
        "plt.annotate(f'First: {first_class_loss:.4f}', xy=(0, first_class_loss), xytext=(10, 5), textcoords='offset points', color='blue', fontsize=10)\n",
        "plt.annotate(f'Last: {last_class_loss:.4f}', xy=(num_epochs - 1, last_class_loss), xytext=(-60, -15), textcoords='offset points', color='blue', fontsize=10)\n",
        "plt.annotate(f'First: {first_bbox_loss:.4f}', xy=(0, first_bbox_loss), xytext=(10, 5), textcoords='offset points', color='blue', fontsize=10)\n",
        "plt.annotate(f'Last: {last_bbox_loss:.4f}', xy=(num_epochs - 1, last_bbox_loss), xytext=(-60, -15), textcoords='offset points', color='blue', fontsize=10)\n",
        "\n",
        "# Add a grid for better readability\n",
        "plt.grid(color='lightgray')\n",
        "\n",
        "# Adjust the layout to avoid overlapping annotations\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AQLdMBV5oLrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E64x88wpdv94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################\n",
        "################ MSE - 1 ######################\n",
        "###############################################"
      ],
      "metadata": {
        "id": "Vd50hiObV0yE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the trained model\n",
        "model_resnet_mse_1 = tf.keras.models.load_model('/content/drive/MyDrive/project_mark1/model_resnet_mse_1_trained_model.h5')\n"
      ],
      "metadata": {
        "id": "6Lrkg7HXq6iU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels\n",
        "test_images\n",
        "test_boxes\n"
      ],
      "metadata": {
        "id": "-JmwcFZ2umt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/caltech_files/caltech-101_new/classes.txt'\n",
        "\n",
        "# Read the class names from the file\n",
        "with open(file_path, 'r') as file:\n",
        "    class_names = [line.strip() for line in file.readlines()]\n",
        "\n",
        "# Print the class names\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "-REMrodowoeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Read the class names from the file\n",
        "with open(file_path, 'r') as file:\n",
        "    class_names = [line.strip() for line in file.readlines()]\n",
        "\n",
        "# Create the Label Encoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit the Label Encoder on the class names\n",
        "label_encoder.fit(class_names)\n",
        "\n",
        "# Print the encoded classes\n",
        "encoded_classes = label_encoder.transform(class_names)\n",
        "print(encoded_classes)\n",
        "\n",
        "# Print the original class names and their corresponding encoded values\n",
        "for class_name, encoded_value in zip(class_names, encoded_classes):\n",
        "    print(f\"{class_name}: {encoded_value}\")\n",
        "\n",
        "# Save the Label Encoder to a file\n",
        "output_path = '/content/drive/MyDrive/project_mark1/label_encoder.pkl'\n",
        "with open(output_path, 'wb') as file:\n",
        "    pickle.dump(label_encoder, file)"
      ],
      "metadata": {
        "id": "Y-pBEFBrw_67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "djhOnv4NyN1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform predictions on the test data\n",
        "preds = model_resnet_mse_1.predict(test_images)\n",
        "pred_labels = label_encoder.inverse_transform(np.argmax(preds[0], axis=1))\n",
        "pred_boxes = preds[1]"
      ],
      "metadata": {
        "id": "24w2en6IQfU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cxSibvECx9Qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# Calculate precision, recall, and F1 scores for each class\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_df[\"Class Name\"], pred_labels, average=None)\n"
      ],
      "metadata": {
        "id": "NZuf2AHbQ7EY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.patches as patches\n",
        "from sklearn.metrics import jaccard_score\n",
        "\n",
        "# Define a function to calculate the IoU score\n",
        "def calculate_iou(box1, box2):\n",
        "    # Extract coordinates from the bounding boxes\n",
        "    xmin1, ymin1, xmax1, ymax1 = box1\n",
        "    xmin2, ymin2, xmax2, ymax2 = box2\n",
        "\n",
        "    # Calculate the coordinates of the intersection rectangle\n",
        "    xmin_inter = max(xmin1, xmin2)\n",
        "    ymin_inter = max(ymin1, ymin2)\n",
        "    xmax_inter = min(xmax1, xmax2)\n",
        "    ymax_inter = min(ymax1, ymax2)\n",
        "\n",
        "    # Calculate the area of intersection rectangle\n",
        "    inter_area = max(0, xmax_inter - xmin_inter + 1) * max(0, ymax_inter - ymin_inter + 1)\n",
        "\n",
        "    # Calculate the areas of the bounding boxes\n",
        "    box1_area = (xmax1 - xmin1 + 1) * (ymax1 - ymin1 + 1)\n",
        "    box2_area = (xmax2 - xmin2 + 1) * (ymax2 - ymin2 + 1)\n",
        "\n",
        "    # Calculate the IoU score\n",
        "    iou = inter_area / float(box1_area + box2_area - inter_area)\n",
        "    return iou\n"
      ],
      "metadata": {
        "id": "dpIe_J63Rifs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate precision, recall, and F1 scores for each class\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_df[\"Class Name\"], pred_labels, average=None)\n",
        "\n",
        "# Calculate the mean F1 score\n",
        "mean_f1 = np.mean(f1)\n",
        "\n",
        "# Get the unique class labels and their counts\n",
        "classes, class_counts = np.unique(test_df[\"Class Name\"], return_counts=True)\n",
        "\n",
        "# Sort precision, recall, F1 scores, and class counts in descending order based on F1 scores\n",
        "sorted_indices = np.argsort(f1)[::-1]\n",
        "precision_sorted = precision[sorted_indices]\n",
        "recall_sorted = recall[sorted_indices]\n",
        "f1_sorted = f1[sorted_indices]\n",
        "classes_sorted = classes[sorted_indices]\n",
        "class_counts_sorted = class_counts[sorted_indices]\n",
        "\n",
        "# Calculate mean IoU score for each class\n",
        "class_iou_scores = []\n",
        "\n",
        "for class_label in classes_sorted:\n",
        "    class_indices = np.where(test_labels == class_label)[0]\n",
        "    class_pred_boxes = pred_boxes[class_indices]\n",
        "    class_test_boxes = test_boxes[class_indices]\n",
        "\n",
        "    iou_scores = []\n",
        "\n",
        "    for i in range(len(class_indices)):\n",
        "        iou_score = calculate_iou(class_test_boxes[i], class_pred_boxes[i])\n",
        "        iou_scores.append(iou_score)\n",
        "\n",
        "    mean_iou_score = np.mean(iou_scores)\n",
        "\n",
        "    class_iou_scores.append(mean_iou_score)\n",
        "\n",
        "# Sort the mean IoU scores from best to worst\n",
        "class_iou_scores_sorted = np.array(class_iou_scores)[sorted_indices]\n",
        "\n",
        "# Set the figure size and create subplots\n",
        "fig, ax = plt.subplots(figsize=(12, 12))\n",
        "\n",
        "# Set the width of the bars\n",
        "bar_width = 0.4\n",
        "\n",
        "# Plot the F1 scores\n",
        "f1_bars = ax.barh(np.arange(len(classes_sorted)), f1_sorted, height=bar_width, color='purple', label='F1 Score')\n",
        "\n",
        "# Plot the mean IoU scores\n",
        "iou_bars = ax.barh(np.arange(len(classes_sorted)) + bar_width, class_iou_scores_sorted, height=bar_width, color='blue', label='Mean IoU')\n",
        "\n",
        "# Add F1 scores as text inside each bar\n",
        "for i, (bar, score) in enumerate(zip(f1_bars, f1_sorted)):\n",
        "    ax.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height() / 2, f\"{score:.2f}\",\n",
        "            va='center', ha='left', fontsize=7, fontweight='bold', color='red')\n",
        "\n",
        "# Add mean IoU scores as text inside each bar\n",
        "for i, (bar, score) in enumerate(zip(iou_bars, class_iou_scores_sorted)):\n",
        "    ax.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height() / 2, f\"{score:.2f}\",\n",
        "            va='center', ha='left', fontsize=7, fontweight='bold', color='red')\n",
        "\n",
        "# Set y-axis ticks and labels\n",
        "ax.set_yticks(np.arange(len(classes_sorted)) + bar_width / 2)\n",
        "ax.set_yticklabels(classes_sorted, fontsize=7, fontweight='bold', color='black')\n",
        "\n",
        "# Set x-axis label and limits\n",
        "ax.set_xlabel('Scores', fontsize=7, color='red')\n",
        "ax.set_xlim(0, 1)\n",
        "\n",
        "# Add class counts as text near the class names\n",
        "for i, count in enumerate(class_counts_sorted):\n",
        "    ax.text(-0.1, i + bar_width / 2, f\"  ({count})\", va='center', ha='right', fontsize=7, fontweight='bold', color='red')\n",
        "\n",
        "# Set plot title\n",
        "ax.set_title('F1 Scores and Mean IoU Scores by Class', fontsize=14, fontweight='bold', color='red')\n",
        "\n",
        "# Remove spines and ticks\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['left'].set_visible(False)\n",
        "ax.spines['bottom'].set_visible(False)\n",
        "ax.tick_params(left=False, bottom=False)\n",
        "\n",
        "# Add a grid to the plot\n",
        "ax.grid(axis='x', color='lightgray', linestyle='--')\n",
        "\n",
        "# Show the legend\n",
        "ax.legend(loc='upper right', fontsize=7)\n",
        "\n",
        "# Invert the y-axis\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rS6C6cORQs7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# Calculate precision, recall, and F1 scores for each class\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_df[\"Class Name\"], pred_labels, average=None)\n",
        "\n",
        "# Calculate mean F1 score\n",
        "mean_f1 = np.mean(f1)\n",
        "\n",
        "# Get the unique class labels and their counts\n",
        "classes, class_counts = np.unique(test_df[\"Class Name\"], return_counts=True)\n",
        "\n",
        "# Sort precision, recall, F1 scores, and class counts in descending order based on F1 scores\n",
        "sorted_indices = np.argsort(f1)[::-1]\n",
        "precision_sorted = precision[sorted_indices]\n",
        "recall_sorted = recall[sorted_indices]\n",
        "f1_sorted = f1[sorted_indices]\n",
        "classes_sorted = classes[sorted_indices]\n",
        "class_counts_sorted = class_counts[sorted_indices]\n",
        "\n",
        "# Calculate mean IoU score for each class\n",
        "class_iou_scores = []\n",
        "\n",
        "for class_label in classes_sorted:\n",
        "    class_indices = np.where(test_labels == class_label)[0]\n",
        "    class_pred_boxes = pred_boxes[class_indices]\n",
        "    class_test_boxes = test_boxes[class_indices]\n",
        "\n",
        "    iou_scores = []\n",
        "\n",
        "    for i in range(len(class_indices)):\n",
        "        iou_score = calculate_iou(class_test_boxes[i], class_pred_boxes[i])\n",
        "        iou_scores.append(iou_score)\n",
        "\n",
        "    mean_iou_score = np.mean(iou_scores)\n",
        "\n",
        "    class_iou_scores.append(mean_iou_score)\n",
        "\n",
        "# Sort the mean IoU scores from best to worst\n",
        "class_iou_scores_sorted = np.array(class_iou_scores)[sorted_indices]\n",
        "\n",
        "# Create a DataFrame to store the results\n",
        "results_df_1 = pd.DataFrame({\n",
        "    'Class': classes_sorted,\n",
        "    'F1 Score': f1_sorted,\n",
        "    'Mean IoU': class_iou_scores_sorted,\n",
        "    'Class Count': class_counts_sorted\n",
        "})\n",
        "\n",
        "# Save the results to a CSV file\n",
        "results_df_1.to_csv('results_1.csv', index=False)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(results_df_1)"
      ],
      "metadata": {
        "id": "9WEfCLSlVkbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Fw9VfClrOqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################################\n",
        "################## MSE -2 ################################"
      ],
      "metadata": {
        "id": "aXRw4Qy7Q499"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform predictions on the test data\n",
        "preds = model_resnet_mse_2.predict(test_images)\n",
        "pred_labels = label_encoder.inverse_transform(np.argmax(preds[0], axis=1))\n",
        "pred_boxes = preds[1]"
      ],
      "metadata": {
        "id": "asWuA9ezSGLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# Calculate precision, recall, and F1 scores for each class\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_df[\"Class Name\"], pred_labels, average=None)"
      ],
      "metadata": {
        "id": "FJSBl3XSSKCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate precision, recall, and F1 scores for each class\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_df[\"Class Name\"], pred_labels, average=None)\n",
        "\n",
        "# Calculate the mean F1 score\n",
        "mean_f1 = np.mean(f1)\n",
        "\n",
        "# Get the unique class labels and their counts\n",
        "classes, class_counts = np.unique(test_df[\"Class Name\"], return_counts=True)\n",
        "\n",
        "# Sort precision, recall, F1 scores, and class counts in descending order based on F1 scores\n",
        "sorted_indices = np.argsort(f1)[::-1]\n",
        "precision_sorted = precision[sorted_indices]\n",
        "recall_sorted = recall[sorted_indices]\n",
        "f1_sorted = f1[sorted_indices]\n",
        "classes_sorted = classes[sorted_indices]\n",
        "class_counts_sorted = class_counts[sorted_indices]\n",
        "\n",
        "# Calculate mean IoU score for each class\n",
        "class_iou_scores = []\n",
        "\n",
        "for class_label in classes_sorted:\n",
        "    class_indices = np.where(test_labels == class_label)[0]\n",
        "    class_pred_boxes = pred_boxes[class_indices]\n",
        "    class_test_boxes = test_boxes[class_indices]\n",
        "\n",
        "    iou_scores = []\n",
        "\n",
        "    for i in range(len(class_indices)):\n",
        "        iou_score = calculate_iou(class_test_boxes[i], class_pred_boxes[i])\n",
        "        iou_scores.append(iou_score)\n",
        "\n",
        "    mean_iou_score = np.mean(iou_scores)\n",
        "\n",
        "    class_iou_scores.append(mean_iou_score)\n",
        "\n",
        "# Sort the mean IoU scores from best to worst\n",
        "class_iou_scores_sorted = np.array(class_iou_scores)[sorted_indices]\n",
        "\n",
        "# Set the figure size and create subplots\n",
        "fig, ax = plt.subplots(figsize=(12, 12))\n",
        "\n",
        "# Set the width of the bars\n",
        "bar_width = 0.4\n",
        "\n",
        "# Plot the F1 scores\n",
        "f1_bars = ax.barh(np.arange(len(classes_sorted)), f1_sorted, height=bar_width, color='purple', label='F1 Score')\n",
        "\n",
        "# Plot the mean IoU scores\n",
        "iou_bars = ax.barh(np.arange(len(classes_sorted)) + bar_width, class_iou_scores_sorted, height=bar_width, color='blue', label='Mean IoU')\n",
        "\n",
        "# Add F1 scores as text inside each bar\n",
        "for i, (bar, score) in enumerate(zip(f1_bars, f1_sorted)):\n",
        "    ax.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height() / 2, f\"{score:.2f}\",\n",
        "            va='center', ha='left', fontsize=7, fontweight='bold', color='red')\n",
        "\n",
        "# Add mean IoU scores as text inside each bar\n",
        "for i, (bar, score) in enumerate(zip(iou_bars, class_iou_scores_sorted)):\n",
        "    ax.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height() / 2, f\"{score:.2f}\",\n",
        "            va='center', ha='left', fontsize=7, fontweight='bold', color='red')\n",
        "\n",
        "# Set y-axis ticks and labels\n",
        "ax.set_yticks(np.arange(len(classes_sorted)) + bar_width / 2)\n",
        "ax.set_yticklabels(classes_sorted, fontsize=7, fontweight='bold', color='black')\n",
        "\n",
        "# Set x-axis label and limits\n",
        "ax.set_xlabel('Scores', fontsize=7, color='red')\n",
        "ax.set_xlim(0, 1)\n",
        "\n",
        "# Add class counts as text near the class names\n",
        "for i, count in enumerate(class_counts_sorted):\n",
        "    ax.text(-0.1, i + bar_width / 2, f\"  ({count})\", va='center', ha='right', fontsize=7, fontweight='bold', color='red')\n",
        "\n",
        "# Set plot title\n",
        "ax.set_title('F1 Scores and Mean IoU Scores by Class', fontsize=14, fontweight='bold', color='red')\n",
        "\n",
        "# Remove spines and ticks\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['left'].set_visible(False)\n",
        "ax.spines['bottom'].set_visible(False)\n",
        "ax.tick_params(left=False, bottom=False)\n",
        "\n",
        "# Add a grid to the plot\n",
        "ax.grid(axis='x', color='lightgray', linestyle='--')\n",
        "\n",
        "# Show the legend\n",
        "ax.legend(loc='upper right', fontsize=7)\n",
        "\n",
        "# Invert the y-axis\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m2RkjseFSdrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# Calculate precision, recall, and F1 scores for each class\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_df[\"Class Name\"], pred_labels, average=None)\n",
        "\n",
        "# Calculate mean F1 score\n",
        "mean_f1 = np.mean(f1)\n",
        "\n",
        "# Get the unique class labels and their counts\n",
        "classes, class_counts = np.unique(test_df[\"Class Name\"], return_counts=True)\n",
        "\n",
        "# Sort precision, recall, F1 scores, and class counts in descending order based on F1 scores\n",
        "sorted_indices = np.argsort(f1)[::-1]\n",
        "precision_sorted = precision[sorted_indices]\n",
        "recall_sorted = recall[sorted_indices]\n",
        "f1_sorted = f1[sorted_indices]\n",
        "classes_sorted = classes[sorted_indices]\n",
        "class_counts_sorted = class_counts[sorted_indices]\n",
        "\n",
        "# Calculate mean IoU score for each class\n",
        "class_iou_scores = []\n",
        "\n",
        "for class_label in classes_sorted:\n",
        "    class_indices = np.where(test_labels == class_label)[0]\n",
        "    class_pred_boxes = pred_boxes[class_indices]\n",
        "    class_test_boxes = test_boxes[class_indices]\n",
        "\n",
        "    iou_scores = []\n",
        "\n",
        "    for i in range(len(class_indices)):\n",
        "        iou_score = calculate_iou(class_test_boxes[i], class_pred_boxes[i])\n",
        "        iou_scores.append(iou_score)\n",
        "\n",
        "    mean_iou_score = np.mean(iou_scores)\n",
        "\n",
        "    class_iou_scores.append(mean_iou_score)\n",
        "\n",
        "# Sort the mean IoU scores from best to worst\n",
        "class_iou_scores_sorted = np.array(class_iou_scores)[sorted_indices]\n",
        "\n",
        "# Create a DataFrame to store the results\n",
        "results_df_2 = pd.DataFrame({\n",
        "    'Class': classes_sorted,\n",
        "    'F1 Score': f1_sorted,\n",
        "    'Mean IoU': class_iou_scores_sorted,\n",
        "    'Class Count': class_counts_sorted\n",
        "})\n",
        "\n",
        "# Save the results to a CSV file\n",
        "results_df_2.to_csv('results_2.csv', index=False)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(results_df_2)"
      ],
      "metadata": {
        "id": "xU9XeyIZVq4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################\n",
        "###################### MSE -3 ##################################"
      ],
      "metadata": {
        "id": "pdjiMrFTVtWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform predictions on the test data\n",
        "preds = model_top_layers.predict(test_images)\n",
        "pred_labels = label_encoder.inverse_transform(np.argmax(preds[0], axis=1))\n",
        "pred_boxes = preds[1]"
      ],
      "metadata": {
        "id": "pLaH8NhDSlC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# Calculate precision, recall, and F1 scores for each class\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_df[\"Class Name\"], pred_labels, average=None)"
      ],
      "metadata": {
        "id": "s0vpPnZLSsc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate precision, recall, and F1 scores for each class\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_df[\"Class Name\"], pred_labels, average=None)\n",
        "\n",
        "# Calculate the mean F1 score\n",
        "mean_f1 = np.mean(f1)\n",
        "\n",
        "# Get the unique class labels and their counts\n",
        "classes, class_counts = np.unique(test_df[\"Class Name\"], return_counts=True)\n",
        "\n",
        "# Sort precision, recall, F1 scores, and class counts in descending order based on F1 scores\n",
        "sorted_indices = np.argsort(f1)[::-1]\n",
        "precision_sorted = precision[sorted_indices]\n",
        "recall_sorted = recall[sorted_indices]\n",
        "f1_sorted = f1[sorted_indices]\n",
        "classes_sorted = classes[sorted_indices]\n",
        "class_counts_sorted = class_counts[sorted_indices]\n",
        "\n",
        "# Calculate mean IoU score for each class\n",
        "class_iou_scores = []\n",
        "\n",
        "for class_label in classes_sorted:\n",
        "    class_indices = np.where(test_labels == class_label)[0]\n",
        "    class_pred_boxes = pred_boxes[class_indices]\n",
        "    class_test_boxes = test_boxes[class_indices]\n",
        "\n",
        "    iou_scores = []\n",
        "\n",
        "    for i in range(len(class_indices)):\n",
        "        iou_score = calculate_iou(class_test_boxes[i], class_pred_boxes[i])\n",
        "        iou_scores.append(iou_score)\n",
        "\n",
        "    mean_iou_score = np.mean(iou_scores)\n",
        "\n",
        "    class_iou_scores.append(mean_iou_score)\n",
        "\n",
        "# Sort the mean IoU scores from best to worst\n",
        "class_iou_scores_sorted = np.array(class_iou_scores)[sorted_indices]\n",
        "\n",
        "# Set the figure size and create subplots\n",
        "fig, ax = plt.subplots(figsize=(12, 12))\n",
        "\n",
        "# Set the width of the bars\n",
        "bar_width = 0.4\n",
        "\n",
        "# Plot the F1 scores\n",
        "f1_bars = ax.barh(np.arange(len(classes_sorted)), f1_sorted, height=bar_width, color='purple', label='F1 Score')\n",
        "\n",
        "# Plot the mean IoU scores\n",
        "iou_bars = ax.barh(np.arange(len(classes_sorted)) + bar_width, class_iou_scores_sorted, height=bar_width, color='blue', label='Mean IoU')\n",
        "\n",
        "# Add F1 scores as text inside each bar\n",
        "for i, (bar, score) in enumerate(zip(f1_bars, f1_sorted)):\n",
        "    ax.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height() / 2, f\"{score:.2f}\",\n",
        "            va='center', ha='left', fontsize=7, fontweight='bold', color='red')\n",
        "\n",
        "# Add mean IoU scores as text inside each bar\n",
        "for i, (bar, score) in enumerate(zip(iou_bars, class_iou_scores_sorted)):\n",
        "    ax.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height() / 2, f\"{score:.2f}\",\n",
        "            va='center', ha='left', fontsize=7, fontweight='bold', color='red')\n",
        "\n",
        "# Set y-axis ticks and labels\n",
        "ax.set_yticks(np.arange(len(classes_sorted)) + bar_width / 2)\n",
        "ax.set_yticklabels(classes_sorted, fontsize=7, fontweight='bold', color='black')\n",
        "\n",
        "# Set x-axis label and limits\n",
        "ax.set_xlabel('Scores', fontsize=7, color='red')\n",
        "ax.set_xlim(0, 1)\n",
        "\n",
        "# Add class counts as text near the class names\n",
        "for i, count in enumerate(class_counts_sorted):\n",
        "    ax.text(-0.1, i + bar_width / 2, f\"  ({count})\", va='center', ha='right', fontsize=7, fontweight='bold', color='red')\n",
        "\n",
        "# Set plot title\n",
        "ax.set_title('F1 Scores and Mean IoU Scores by Class', fontsize=14, fontweight='bold', color='red')\n",
        "\n",
        "# Remove spines and ticks\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['left'].set_visible(False)\n",
        "ax.spines['bottom'].set_visible(False)\n",
        "ax.tick_params(left=False, bottom=False)\n",
        "\n",
        "# Add a grid to the plot\n",
        "ax.grid(axis='x', color='lightgray', linestyle='--')\n",
        "\n",
        "# Show the legend\n",
        "ax.legend(loc='upper right', fontsize=7)\n",
        "\n",
        "# Invert the y-axis\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QLRpY2htSw0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# Calculate precision, recall, and F1 scores for each class\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_df[\"Class Name\"], pred_labels, average=None)\n",
        "\n",
        "# Calculate mean F1 score\n",
        "mean_f1 = np.mean(f1)\n",
        "\n",
        "# Get the unique class labels and their counts\n",
        "classes, class_counts = np.unique(test_df[\"Class Name\"], return_counts=True)\n",
        "\n",
        "# Sort precision, recall, F1 scores, and class counts in descending order based on F1 scores\n",
        "sorted_indices = np.argsort(f1)[::-1]\n",
        "precision_sorted = precision[sorted_indices]\n",
        "recall_sorted = recall[sorted_indices]\n",
        "f1_sorted = f1[sorted_indices]\n",
        "classes_sorted = classes[sorted_indices]\n",
        "class_counts_sorted = class_counts[sorted_indices]\n",
        "\n",
        "# Calculate mean IoU score for each class\n",
        "class_iou_scores = []\n",
        "\n",
        "for class_label in classes_sorted:\n",
        "    class_indices = np.where(test_labels == class_label)[0]\n",
        "    class_pred_boxes = pred_boxes[class_indices]\n",
        "    class_test_boxes = test_boxes[class_indices]\n",
        "\n",
        "    iou_scores = []\n",
        "\n",
        "    for i in range(len(class_indices)):\n",
        "        iou_score = calculate_iou(class_test_boxes[i], class_pred_boxes[i])\n",
        "        iou_scores.append(iou_score)\n",
        "\n",
        "    mean_iou_score = np.mean(iou_scores)\n",
        "\n",
        "    class_iou_scores.append(mean_iou_score)\n",
        "\n",
        "# Sort the mean IoU scores from best to worst\n",
        "class_iou_scores_sorted = np.array(class_iou_scores)[sorted_indices]\n",
        "\n",
        "# Create a DataFrame to store the results\n",
        "results_df_3 = pd.DataFrame({\n",
        "    'Class': classes_sorted,\n",
        "    'F1 Score': f1_sorted,\n",
        "    'Mean IoU': class_iou_scores_sorted,\n",
        "    'Class Count': class_counts_sorted\n",
        "})\n",
        "\n",
        "# Save the results to a CSV file\n",
        "results_df_3.to_csv('results_3.csv', index=False)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(results_df_3)"
      ],
      "metadata": {
        "id": "GKDcLdZdUQIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df_3"
      ],
      "metadata": {
        "id": "LC65q3MFVLXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "source_file = \"/content/results_3.csv\"\n",
        "destination_folder = \"/content/drive/MyDrive/project_mark1/\"\n",
        "\n",
        "shutil.copy(source_file, destination_folder)"
      ],
      "metadata": {
        "id": "H7qxy7u6XazP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_file = \"/content/results_2.csv\"\n",
        "destination_folder = \"/content/drive/MyDrive/project_mark1/\"\n",
        "\n",
        "shutil.copy(source_file, destination_folder)"
      ],
      "metadata": {
        "id": "8LH5z50IXv5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_file = \"/content/results_1.csv\"\n",
        "destination_folder = \"/content/drive/MyDrive/project_mark1/\"\n",
        "\n",
        "shutil.copy(source_file, destination_folder)"
      ],
      "metadata": {
        "id": "T3LBOXAEXvY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('results_3.csv')\n",
        "\n",
        "# Multiply the count column by 5\n",
        "df['Class Count'] = df['Class Count'] * 5\n",
        "\n",
        "# Define the image count ranges\n",
        "ranges = [\n",
        "    (0, 100),\n",
        "    (100, 250),\n",
        "    (250, 450),\n",
        "    (450, float('inf'))\n",
        "]\n",
        "\n",
        "# Create a mapping for the summarized classes\n",
        "class_mapping = {\n",
        "    0: 'Class 0-100',\n",
        "    1: 'Class 100-250',\n",
        "    2: 'Class 250-450',\n",
        "    3: 'Class 450+'\n",
        "}\n",
        "\n",
        "# Create an empty DataFrame for the new CSV\n",
        "new_df = pd.DataFrame(columns=['Class', 'Image Count Range', 'Mean IoU', 'Mean F1', 'Total Images'])\n",
        "\n",
        "# Calculate the mean scores and total images for each summarized class and image count range\n",
        "for i, (start, end) in enumerate(ranges):\n",
        "    filtered_df = df[(df['Class Count'] >= start) & (df['Class Count'] < end)]\n",
        "    mean_iou = filtered_df['Mean IoU'].mean()\n",
        "    mean_f1 = filtered_df['F1 Score'].mean()\n",
        "    total_images = filtered_df['Class Count'].sum()\n",
        "    new_df.loc[i] = [class_mapping[i], f'{start} - {end}', mean_iou, mean_f1, total_images]\n",
        "\n",
        "# Save the new DataFrame to a CSV file\n",
        "new_df.to_csv('outputs_3_iou.csv', index=False)\n"
      ],
      "metadata": {
        "id": "Mn2AG_EnXzaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.head()"
      ],
      "metadata": {
        "id": "rAkri82zBVXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('outputs_3_iou.csv')\n",
        "\n",
        "# Set the plot style using Seaborn\n",
        "sns.set(style='whitegrid')\n",
        "\n",
        "# Set the color palette\n",
        "colors = ['#6C8EBF', '#A1C1D9']\n",
        "\n",
        "# Create a figure and axes\n",
        "fig, ax = plt.subplots(figsize=(12, 14))\n",
        "\n",
        "# Plot the mean IoU and mean F1 scores\n",
        "df.plot(x='Class', y=['Mean IoU', 'Mean F1'], kind='bar', ax=ax, rot=0, legend=True, color=colors)\n",
        "\n",
        "# Set the title and axis labels\n",
        "ax.set_title('Mean IoU and Mean F1 Scores by Class (Top then Full Training // Loss = \"IoU\")', fontsize=16, fontweight='bold')\n",
        "ax.set_xlabel('Class', fontsize=14)\n",
        "ax.set_ylabel('Score', fontsize=12)\n",
        "\n",
        "# Customize the tick labels and font size\n",
        "ax.tick_params(axis='x', labelrotation=45, labelsize=10)\n",
        "ax.tick_params(axis='y', labelsize=10)\n",
        "\n",
        "# Set the legend\n",
        "ax.legend(['Mean IoU', 'Mean F1'], loc='upper right', fontsize=10)\n",
        "\n",
        "# Add data labels to the bars\n",
        "for p in ax.patches:\n",
        "    x = p.get_x() + p.get_width() / 2.\n",
        "    y = p.get_height()\n",
        "    ax.annotate(f'{y:.3f}', (x, y), ha='center', va='center', xytext=(0, 5), textcoords='offset points', fontsize=10, fontweight='bold')\n",
        "\n",
        "# Remove the top and right spines\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "\n",
        "# Add a horizontal grid\n",
        "ax.yaxis.grid(True, linestyle='dashed')\n",
        "\n",
        "# Adjust the layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "sH4U4Y8f--mQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('results_2.csv')\n",
        "\n",
        "# Multiply the count column by 5\n",
        "df['Class Count'] = df['Class Count'] * 5\n",
        "\n",
        "# Define the image count ranges\n",
        "ranges = [\n",
        "    (0, 100),\n",
        "    (100, 250),\n",
        "    (250, 450),\n",
        "    (450, float('inf'))\n",
        "]\n",
        "\n",
        "# Create a mapping for the summarized classes\n",
        "class_mapping = {\n",
        "    0: 'Class 0-100',\n",
        "    1: 'Class 100-250',\n",
        "    2: 'Class 250-450',\n",
        "    3: 'Class 450+'\n",
        "}\n",
        "\n",
        "# Create an empty DataFrame for the new CSV\n",
        "new_df = pd.DataFrame(columns=['Class', 'Image Count Range', 'Mean IoU', 'Mean F1', 'Total Images'])\n",
        "\n",
        "# Calculate the mean scores and total images for each summarized class and image count range\n",
        "for i, (start, end) in enumerate(ranges):\n",
        "    filtered_df = df[(df['Class Count'] >= start) & (df['Class Count'] < end)]\n",
        "    mean_iou = filtered_df['Mean IoU'].mean()\n",
        "    mean_f1 = filtered_df['F1 Score'].mean()\n",
        "    total_images = filtered_df['Class Count'].sum()\n",
        "    new_df.loc[i] = [class_mapping[i], f'{start} - {end}', mean_iou, mean_f1, total_images]\n",
        "\n",
        "# Save the new DataFrame to a CSV file\n",
        "new_df.to_csv('outputs_2_iou.csv', index=False)\n"
      ],
      "metadata": {
        "id": "hWwA8R-s_ACB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('outputs_2_iou.csv')\n",
        "\n",
        "# Set the plot style using Seaborn\n",
        "sns.set(style='whitegrid')\n",
        "\n",
        "# Set the color palette\n",
        "colors = ['#6C8EBF', '#A1C1D9']\n",
        "\n",
        "# Create a figure and axes\n",
        "fig, ax = plt.subplots(figsize=(12, 14))\n",
        "\n",
        "# Plot the mean IoU and mean F1 scores\n",
        "df.plot(x='Class', y=['Mean IoU', 'Mean F1'], kind='bar', ax=ax, rot=0, legend=True, color=colors)\n",
        "\n",
        "# Set the title and axis labels\n",
        "ax.set_title('Mean IoU and Mean F1 Scores by Class (Top-only Training // Loss = \"IoU\")', fontsize=16, fontweight='bold')\n",
        "ax.set_xlabel('Class', fontsize=14)\n",
        "ax.set_ylabel('Score', fontsize=12)\n",
        "\n",
        "# Customize the tick labels and font size\n",
        "ax.tick_params(axis='x', labelrotation=45, labelsize=10)\n",
        "ax.tick_params(axis='y', labelsize=10)\n",
        "\n",
        "# Set the legend\n",
        "ax.legend(['Mean IoU', 'Mean F1'], loc='upper right', fontsize=10)\n",
        "\n",
        "# Add data labels to the bars\n",
        "for p in ax.patches:\n",
        "    x = p.get_x() + p.get_width() / 2.\n",
        "    y = p.get_height()\n",
        "    ax.annotate(f'{y:.3f}', (x, y), ha='center', va='center', xytext=(0, 5), textcoords='offset points', fontsize=10, fontweight='bold')\n",
        "\n",
        "# Remove the top and right spines\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "\n",
        "# Add a horizontal grid\n",
        "ax.yaxis.grid(True, linestyle='dashed')\n",
        "\n",
        "# Adjust the layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "N-NQ3oeGC4jK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('results_1.csv')\n",
        "\n",
        "# Multiply the count column by 5\n",
        "df['Class Count'] = df['Class Count'] * 5\n",
        "\n",
        "# Define the image count ranges\n",
        "ranges = [\n",
        "    (0, 100),\n",
        "    (100, 250),\n",
        "    (250, 450),\n",
        "    (450, float('inf'))\n",
        "]\n",
        "\n",
        "# Create a mapping for the summarized classes\n",
        "class_mapping = {\n",
        "    0: 'Class 0-100',\n",
        "    1: 'Class 100-250',\n",
        "    2: 'Class 250-450',\n",
        "    3: 'Class 450+'\n",
        "}\n",
        "\n",
        "# Create an empty DataFrame for the new CSV\n",
        "new_df = pd.DataFrame(columns=['Class', 'Image Count Range', 'Mean IoU', 'Mean F1', 'Total Images'])\n",
        "\n",
        "# Calculate the mean scores and total images for each summarized class and image count range\n",
        "for i, (start, end) in enumerate(ranges):\n",
        "    filtered_df = df[(df['Class Count'] >= start) & (df['Class Count'] < end)]\n",
        "    mean_iou = filtered_df['Mean IoU'].mean()\n",
        "    mean_f1 = filtered_df['F1 Score'].mean()\n",
        "    total_images = filtered_df['Class Count'].sum()\n",
        "    new_df.loc[i] = [class_mapping[i], f'{start} - {end}', mean_iou, mean_f1, total_images]\n",
        "\n",
        "# Save the new DataFrame to a CSV file\n",
        "new_df.to_csv('outputs_1_iou.csv', index=False)\n"
      ],
      "metadata": {
        "id": "tyRPp8GVC91K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('outputs_1_iou.csv')\n",
        "\n",
        "# Set the plot style using Seaborn\n",
        "sns.set(style='whitegrid')\n",
        "\n",
        "# Set the color palette\n",
        "colors = ['#6C8EBF', '#A1C1D9']\n",
        "\n",
        "# Create a figure and axes\n",
        "fig, ax = plt.subplots(figsize=(12, 14))\n",
        "\n",
        "# Plot the mean IoU and mean F1 scores\n",
        "df.plot(x='Class', y=['Mean IoU', 'Mean F1'], kind='bar', ax=ax, rot=0, legend=True, color=colors)\n",
        "\n",
        "# Set the title and axis labels\n",
        "ax.set_title('Mean IoU and Mean F1 Scores by Class (Full Training // Loss = \"IoU\")', fontsize=16, fontweight='bold')\n",
        "ax.set_xlabel('Class', fontsize=14)\n",
        "ax.set_ylabel('Score', fontsize=12)\n",
        "\n",
        "# Customize the tick labels and font size\n",
        "ax.tick_params(axis='x', labelrotation=45, labelsize=10)\n",
        "ax.tick_params(axis='y', labelsize=10)\n",
        "\n",
        "# Set the legend\n",
        "ax.legend(['Mean IoU', 'Mean F1'], loc='upper right', fontsize=10)\n",
        "\n",
        "# Add data labels to the bars\n",
        "for p in ax.patches:\n",
        "    x = p.get_x() + p.get_width() / 2.\n",
        "    y = p.get_height()\n",
        "    ax.annotate(f'{y:.3f}', (x, y), ha='center', va='center', xytext=(0, 5), textcoords='offset points', fontsize=10, fontweight='bold')\n",
        "\n",
        "# Remove the top and right spines\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "\n",
        "# Add a horizontal grid\n",
        "ax.yaxis.grid(True, linestyle='dashed')\n",
        "\n",
        "# Adjust the layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "c4-c_mQ-DBaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "source_file = \"/content/outputs_3_iou.csv\"\n",
        "destination_folder = \"/content/drive/MyDrive/project_mark1/\"\n",
        "\n",
        "shutil.copy(source_file, destination_folder)"
      ],
      "metadata": {
        "id": "JTA2f9GWDIw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "source_file = \"/content/outputs_2_iou.csv\"\n",
        "destination_folder = \"/content/drive/MyDrive/project_mark1/\"\n",
        "\n",
        "shutil.copy(source_file, destination_folder)"
      ],
      "metadata": {
        "id": "RTJnqHukDujH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "source_file = \"/content/outputs_1_iou.csv\"\n",
        "destination_folder = \"/content/drive/MyDrive/project_mark1/\"\n",
        "\n",
        "shutil.copy(source_file, destination_folder)"
      ],
      "metadata": {
        "id": "s0du_lMfDucR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Save test_carside_df to CSV\n",
        "# test_carside_df.to_csv(os.path.join(parent_dir, \"test_carside_df.csv\"), index=False)\n",
        "\n",
        "# # Save val_carside_df to CSV\n",
        "# val_carside_df.to_csv(os.path.join(parent_dir, \"val_carside_df.csv\"), index=False)\n",
        "\n",
        "# # Save carside_df to CSV\n",
        "# carside_df.to_csv(os.path.join(parent_dir, \"carside_df.csv\"), index=False)\n"
      ],
      "metadata": {
        "id": "KzBcHBghEM2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = ['Image Path', 'Class Name', 'Image Name', 'Bounding Box', 'Height', 'Width', 'label',\n",
        "                'normalized', 'Xmin', 'Ymin', 'Xmax', 'Ymax']\n",
        "\n",
        "\n",
        "test_carside_df.columns = column_names\n",
        "val_carside_df.columns = column_names\n",
        "carside_df.columns = column_names"
      ],
      "metadata": {
        "id": "TFcfGNNqFhAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "    image = image.astype(np.float32) / 255.0\n",
        "    return image"
      ],
      "metadata": {
        "id": "IqWKn78fFg-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_images_with_bboxes(df):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
        "    for i, row in df.head(5).iterrows():\n",
        "        image_path = row['Image Path']\n",
        "        class_name = row['Class Name']\n",
        "        image_name = row['Image Name']\n",
        "        xmin, ymin, xmax, ymax = row['Xmin']*224, row['Ymin']*224, row['Xmax']*224, row['Ymax']*224\n",
        "\n",
        "        image = load_image(image_path)\n",
        "\n",
        "        ax = axes[i]\n",
        "        ax.imshow(image)\n",
        "        ax.axis('off')\n",
        "\n",
        "        # Add bounding box\n",
        "        bbox = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, linewidth=2, edgecolor='r', facecolor='none')\n",
        "        ax.add_patch(bbox)\n",
        "\n",
        "        ax.set_title(f'Class: {class_name}\\nImage: {image_name}')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Plot images with bounding boxes for val_df, test_df, train_df\n",
        "plot_images_with_bboxes(val_carside_df)\n",
        "plot_images_with_bboxes(test_carside_df)\n",
        "plot_images_with_bboxes(carside_df)"
      ],
      "metadata": {
        "id": "06UTdlpxGFpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####################################################\n",
        "############## MOST IMPORTANT PART #################\n",
        "####################################################\n",
        "def resize_image(image, target_size):\n",
        "    return cv2.resize(image, target_size)\n",
        "\n",
        "def plot_images(images, boxes, labels, dataset_name):\n",
        "    fig, axes = plt.subplots(1, len(images), figsize=(12, 4))\n",
        "    for i, ax in enumerate(axes):\n",
        "        ax.imshow(images[i])\n",
        "        xmin, ymin, xmax, ymax = boxes[i]\n",
        "        ax.add_patch(plt.Rectangle((xmin*224, ymin*224), xmax*224 - xmin*224, ymax*224 - ymin*224, fill=False, color='red', linewidth=2))\n",
        "        ax.set_title(labels[i])\n",
        "        ax.axis('off')\n",
        "    plt.suptitle(f'{dataset_name} Images with Bounding Boxes')\n",
        "    plt.show()\n",
        "\n",
        "# Append data from val_df into arrays\n",
        "val_images = []\n",
        "val_boxes = []\n",
        "val_labels = []\n",
        "\n",
        "for index, row in val_carside_df.iterrows():\n",
        "    image_path = row['Image Path']\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = resize_image(image, (224, 224))\n",
        "    val_images.append(image)\n",
        "\n",
        "    xmin, ymin, xmax, ymax = map(float, [row['Xmin'], row['Ymin'], row['Xmax'], row['Ymax']])\n",
        "    val_boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "    label = row['Class Name']\n",
        "    val_labels.append(label)\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "val_images = np.array(val_images, dtype='float32')\n",
        "val_boxes = np.array(val_boxes, dtype='float32')\n",
        "val_labels = np.array(val_labels)\n",
        "\n",
        "# Normalize the images\n",
        "val_images = val_images / 255.0\n",
        "\n",
        "# Plot the images, bounding boxes, and class names for the first 4 images from the val_df dataset\n",
        "plot_images(val_images[:5], val_boxes[:5], val_labels[:5], 'Validation')\n",
        "\n",
        "# Append data from train_df into arrays\n",
        "train_images = []\n",
        "train_boxes = []\n",
        "train_labels = []\n",
        "\n",
        "for index, row in carside_df.iterrows():\n",
        "    image_path = row['Image Path']\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = resize_image(image, (224, 224))\n",
        "    train_images.append(image)\n",
        "\n",
        "    xmin, ymin, xmax, ymax = map(float, [row['Xmin'], row['Ymin'], row['Xmax'], row['Ymax']])\n",
        "    train_boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "    label = row['Class Name']\n",
        "    train_labels.append(label)\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "train_images = np.array(train_images, dtype='float32')\n",
        "train_boxes = np.array(train_boxes, dtype='float32')\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "# Normalize the images\n",
        "train_images = train_images / 255.0\n",
        "\n",
        "# Plot the images, bounding boxes, and class names for the first 4 images from the train_df dataset\n",
        "plot_images(train_images[:5], train_boxes[:5], train_labels[:5], 'Train')\n",
        "\n",
        "# Append data from test_df into arrays\n",
        "test_images = []\n",
        "test_boxes = []\n",
        "test_labels = []\n",
        "\n",
        "for index, row in test_carside_df.iterrows():\n",
        "    image_path = row['Image Path']\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = resize_image(image, (224, 224))\n",
        "    test_images.append(image)\n",
        "\n",
        "    xmin, ymin, xmax, ymax = map(float, [row['Xmin'], row['Ymin'], row['Xmax'], row['Ymax']])\n",
        "    test_boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "    label = row['Class Name']\n",
        "    test_labels.append(label)\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "test_images = np.array(test_images, dtype='float32')\n",
        "test_boxes = np.array(test_boxes, dtype='float32')\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "# Normalize the images\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Plot the images, bounding boxes, and class names for the first 4 images from the test_df dataset\n",
        "plot_images(test_images[:5], test_boxes[:5], test_labels[:5], 'Test')"
      ],
      "metadata": {
        "id": "R_eXq2LdGNjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Perform label encoding on the target labels\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
        "val_labels_encoded = label_encoder.transform(val_labels)\n",
        "\n",
        "# Convert the encoded labels to one-hot encoding\n",
        "train_labels_onehot = to_categorical(train_labels_encoded, num_classes=1) ## ==> update number of classes\n",
        "val_labels_onehot = to_categorical(val_labels_encoded, num_classes=1) ## ==> update number of classes\n",
        "\n",
        "# Model architecture\n",
        "input_layer = Input(shape=(224, 224, 3))\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=input_layer)\n",
        "\n",
        "\n",
        "flatten = Flatten()(base_model.output)\n",
        "\n",
        "\n",
        "bboxHead = Dense(1024, activation=\"relu\")(flatten)\n",
        "\n",
        "bboxHead = Dense(512, activation=\"relu\")(bboxHead)\n",
        "\n",
        "bboxHead = Dense(256, activation=\"relu\")(bboxHead)\n",
        "\n",
        "bboxHead = Dense(128, activation=\"relu\")(bboxHead)\n",
        "\n",
        "bboxHead = Dense(64, activation=\"relu\")(bboxHead)\n",
        "\n",
        "bboxHead = Dense(32, activation=\"relu\")(bboxHead)\n",
        "\n",
        "bbox_output = Dense(4, activation='linear', name='bounding_box')(bboxHead)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "carside_resnet_mse_1 = Model(inputs=input_layer, outputs=[bbox_output])\n",
        "\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "carside_resnet_mse_1.compile(optimizer='adam', loss=\"mse\")\n",
        "carside_resnet_mse_1.summary()"
      ],
      "metadata": {
        "id": "Bx6_-JVMHkGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=7)\n",
        "\n",
        "\n",
        "# Train the model with early stopping\n",
        "carside_resnet_mse_1_history = carside_resnet_mse_1.fit(\n",
        "    train_images,\n",
        "    {'bounding_box': train_boxes},  # Update the label key to 'bounding_box'\n",
        "    validation_data=(val_images, {'bounding_box': val_boxes}),  # Update the label key to 'bounding_box'\n",
        "    epochs=300,\n",
        "    batch_size=32,\n",
        "    callbacks=[callback]\n",
        ")"
      ],
      "metadata": {
        "id": "9ouHNAkHmHNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the label encoder\n",
        "with open('/content/drive/MyDrive/project_mark1/carside_resnet_mse_1_label_encoder.pkl', 'wb') as file:\n",
        "    pickle.dump(label_encoder, file)\n",
        "\n",
        "# Save the entire model to a HDF5 file\n",
        "carside_resnet_mse_1.save('/content/drive/MyDrive/project_mark1/carside_resnet_mse_1_history.h5')\n",
        "\n",
        "# Save the history object to a file using pickle\n",
        "with open('/content/drive/MyDrive/project_mark1/model_fine_tuned_history.pkl', 'wb') as file:\n",
        "    pickle.dump(carside_resnet_mse_1_history.history, file)"
      ],
      "metadata": {
        "id": "XTSpuLYaH-8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load model history from file\n",
        "history_path = '/content/drive/MyDrive/project_mark1/model_resnet_mse_1_history.pkl'\n",
        "with open(history_path, 'rb') as f:\n",
        "    model_resnet_mse_1_history = pickle.load(f)\n",
        "\n",
        "# Print the available keys in the model history\n",
        "print(model_resnet_mse_1_history.keys())\n",
        "\n",
        "# Plot the losses and metrics\n",
        "plt.figure(figsize=(12, 10))\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "\n",
        "# Classification Loss\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(model_resnet_mse_1_history['class_output_loss'], label='Train Classification Loss', color='blue')\n",
        "plt.plot(model_resnet_mse_1_history['val_class_output_loss'], label='Validation Classification Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Classification Loss', fontsize=12)\n",
        "plt.legend()\n",
        "\n",
        "# Bounding Box Loss\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(model_resnet_mse_1_history['bounding_box_loss'], label='Bounding Box Loss', color='blue')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Bounding Box Loss', fontsize=12)\n",
        "plt.legend()\n",
        "\n",
        "# Accuracy\n",
        "if 'class_output_accuracy' in model_resnet_mse_1_history:\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.plot(model_resnet_mse_1_history['class_output_accuracy'], label='Train Accuracy', color='blue')\n",
        "    plt.plot(model_resnet_mse_1_history['val_class_output_accuracy'], label='Validation Accuracy', color='orange')\n",
        "    plt.xlabel('Epoch', fontsize=12)\n",
        "    plt.ylabel('Accuracy', fontsize=12)\n",
        "    plt.title('Classification Accuracy', fontsize=12)\n",
        "    plt.legend()\n",
        "\n",
        "# Validation Loss\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.plot(model_resnet_mse_1_history['val_loss'], label='Validation Loss', color='blue')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Validation Loss', fontsize=12)\n",
        "plt.legend()\n",
        "\n",
        "# Adjust layout and spacing\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plots\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VN_dNEO_kXpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load model history from file\n",
        "history_path = '/content/drive/MyDrive/project_mark1/model_resnet_mse_1_history.pkl'\n",
        "with open(history_path, 'rb') as f:\n",
        "    model_resnet_mse_1_history = pickle.load(f)\n",
        "\n",
        "# Print the available keys in the model history\n",
        "print(model_resnet_mse_1_history.keys())\n",
        "\n",
        "# Plot Classification Loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(model_resnet_mse_1_history['class_output_loss'], label='Train Classification Loss', color='blue')\n",
        "plt.plot(model_resnet_mse_1_history['val_class_output_loss'], label='Validation Classification Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Classification Loss - (Full Training(IoU))', fontsize=12)\n",
        "plt.legend()\n",
        "\n",
        "# Find and annotate best and worst values\n",
        "best_class_loss = min(model_resnet_mse_1_history['class_output_loss'])\n",
        "worst_class_loss = max(model_resnet_mse_1_history['class_output_loss'])\n",
        "plt.annotate(f'Best: {best_class_loss:.4f}', xy=(model_resnet_mse_1_history['class_output_loss'].index(best_class_loss), best_class_loss), xytext=(10, 5),\n",
        "             textcoords='offset points', color='blue', fontsize=10)\n",
        "plt.annotate(f'Worst: {worst_class_loss:.4f}', xy=(model_resnet_mse_1_history['class_output_loss'].index(worst_class_loss), worst_class_loss),\n",
        "             xytext=(-60, -15), textcoords='offset points', color='blue', fontsize=10)\n",
        "\n",
        "# Show Classification Loss plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot Bounding Box Loss and Validation Loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(model_resnet_mse_1_history['bounding_box_loss'], label='Bounding Box Loss', color='blue')\n",
        "plt.plot(model_resnet_mse_1_history['val_loss'], label='Validation Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Bounding Box and Validation Loss - (Full Training(IoU)', fontsize=12)\n",
        "plt.legend()\n",
        "\n",
        "# Find and annotate best and worst values\n",
        "best_bbox_loss = min(model_resnet_mse_1_history['bounding_box_loss'])\n",
        "worst_bbox_loss = max(model_resnet_mse_1_history['bounding_box_loss'])\n",
        "best_val_loss = min(model_resnet_mse_1_history['val_loss'])\n",
        "worst_val_loss = max(model_resnet_mse_1_history['val_loss'])\n",
        "plt.annotate(f'Best BBox: {best_bbox_loss:.4f}', xy=(model_resnet_mse_1_history['bounding_box_loss'].index(best_bbox_loss), best_bbox_loss), xytext=(10, 5),\n",
        "             textcoords='offset points', color='blue', fontsize=10)\n",
        "plt.annotate(f'Worst BBox: {worst_bbox_loss:.4f}', xy=(model_resnet_mse_1_history['bounding_box_loss'].index(worst_bbox_loss), worst_bbox_loss),\n",
        "             xytext=(-60, -15), textcoords='offset points', color='blue', fontsize=10)\n",
        "plt.annotate(f'Best Val: {best_val_loss:.4f}', xy=(model_resnet_mse_1_history['val_loss'].index(best_val_loss), best_val_loss), xytext=(10, 5),\n",
        "             textcoords='offset points', color='orange', fontsize=10)\n",
        "plt.annotate(f'Worst Val: {worst_val_loss:.4f}', xy=(model_resnet_mse_1_history['val_loss'].index(worst_val_loss), worst_val_loss),\n",
        "             xytext=(-60, -15), textcoords='offset points', color='orange', fontsize=10)\n",
        "\n",
        "# Show Bounding Box and Validation Loss plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5K3ddgjQngST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load model history from file\n",
        "history_path = '/content/drive/MyDrive/project_mark1/model_resnet_mse_2_history.pkl'\n",
        "with open(history_path, 'rb') as f:\n",
        "    model_resnet_mse_1_history = pickle.load(f)\n",
        "\n",
        "# Print the available keys in the model history\n",
        "print(model_resnet_mse_1_history.keys())\n",
        "\n",
        "# Plot Classification Loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(model_resnet_mse_1_history['class_output_loss'], label='Train Classification Loss', color='blue')\n",
        "plt.plot(model_resnet_mse_1_history['val_class_output_loss'], label='Validation Classification Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Classification Loss - (Top Only(IoU))', fontsize=12)\n",
        "plt.legend()\n",
        "\n",
        "# Find and annotate best and worst values\n",
        "best_class_loss = min(model_resnet_mse_1_history['class_output_loss'])\n",
        "worst_class_loss = max(model_resnet_mse_1_history['class_output_loss'])\n",
        "plt.annotate(f'Best: {best_class_loss:.4f}', xy=(model_resnet_mse_1_history['class_output_loss'].index(best_class_loss), best_class_loss), xytext=(10, 5),\n",
        "             textcoords='offset points', color='blue', fontsize=10)\n",
        "plt.annotate(f'Worst: {worst_class_loss:.4f}', xy=(model_resnet_mse_1_history['class_output_loss'].index(worst_class_loss), worst_class_loss),\n",
        "             xytext=(-60, -15), textcoords='offset points', color='blue', fontsize=10)\n",
        "\n",
        "# Show Classification Loss plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot Bounding Box Loss and Validation Loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(model_resnet_mse_1_history['bounding_box_loss'], label='Bounding Box Loss', color='blue')\n",
        "plt.plot(model_resnet_mse_1_history['val_loss'], label='Validation Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Bounding Box and Validation Loss - (Top-only(IoU)', fontsize=12)\n",
        "plt.legend()\n",
        "\n",
        "# Find and annotate best and worst values\n",
        "best_bbox_loss = min(model_resnet_mse_1_history['bounding_box_loss'])\n",
        "worst_bbox_loss = max(model_resnet_mse_1_history['bounding_box_loss'])\n",
        "best_val_loss = min(model_resnet_mse_1_history['val_loss'])\n",
        "worst_val_loss = max(model_resnet_mse_1_history['val_loss'])\n",
        "plt.annotate(f'Best BBox: {best_bbox_loss:.4f}', xy=(model_resnet_mse_1_history['bounding_box_loss'].index(best_bbox_loss), best_bbox_loss), xytext=(10, 5),\n",
        "             textcoords='offset points', color='blue', fontsize=10)\n",
        "plt.annotate(f'Worst BBox: {worst_bbox_loss:.4f}', xy=(model_resnet_mse_1_history['bounding_box_loss'].index(worst_bbox_loss), worst_bbox_loss),\n",
        "             xytext=(-60, -15), textcoords='offset points', color='blue', fontsize=10)\n",
        "plt.annotate(f'Best Val: {best_val_loss:.4f}', xy=(model_resnet_mse_1_history['val_loss'].index(best_val_loss), best_val_loss), xytext=(10, 5),\n",
        "             textcoords='offset points', color='orange', fontsize=10)\n",
        "plt.annotate(f'Worst Val: {worst_val_loss:.4f}', xy=(model_resnet_mse_1_history['val_loss'].index(worst_val_loss), worst_val_loss),\n",
        "             xytext=(-60, -15), textcoords='offset points', color='orange', fontsize=10)\n",
        "\n",
        "# Show Bounding Box and Validation Loss plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NMJ8c_odnzWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load model history from file\n",
        "history_path = '/content/drive/MyDrive/project_mark1/model_fine_tuned_history.pkl'\n",
        "with open(history_path, 'rb') as f:\n",
        "    model_resnet_mse_1_history = pickle.load(f)\n",
        "\n",
        "# Print the available keys in the model history\n",
        "print(model_resnet_mse_1_history.keys())\n",
        "\n",
        "# Plot Classification Loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(model_resnet_mse_1_history['class_output_loss'], label='Train Classification Loss', color='blue')\n",
        "plt.plot(model_resnet_mse_1_history['val_class_output_loss'], label='Validation Classification Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Classification Loss - (Top then Full(IoU))', fontsize=12)\n",
        "plt.legend()\n",
        "\n",
        "# Find and annotate best and worst values\n",
        "best_class_loss = min(model_resnet_mse_1_history['class_output_loss'])\n",
        "worst_class_loss = max(model_resnet_mse_1_history['class_output_loss'])\n",
        "plt.annotate(f'Best: {best_class_loss:.4f}', xy=(model_resnet_mse_1_history['class_output_loss'].index(best_class_loss), best_class_loss), xytext=(10, 5),\n",
        "             textcoords='offset points', color='blue', fontsize=10)\n",
        "plt.annotate(f'Worst: {worst_class_loss:.4f}', xy=(model_resnet_mse_1_history['class_output_loss'].index(worst_class_loss), worst_class_loss),\n",
        "             xytext=(-60, -15), textcoords='offset points', color='blue', fontsize=10)\n",
        "\n",
        "# Show Classification Loss plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot Bounding Box Loss and Validation Loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(model_resnet_mse_1_history['bounding_box_loss'], label='Bounding Box Loss', color='blue')\n",
        "plt.plot(model_resnet_mse_1_history['val_loss'], label='Validation Loss', color='orange')\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.title('Bounding Box and Validation Loss - (Top then Full(IoU)', fontsize=12)\n",
        "plt.legend()\n",
        "\n",
        "# Find and annotate best and worst values\n",
        "best_bbox_loss = min(model_resnet_mse_1_history['bounding_box_loss'])\n",
        "worst_bbox_loss = max(model_resnet_mse_1_history['bounding_box_loss'])\n",
        "best_val_loss = min(model_resnet_mse_1_history['val_loss'])\n",
        "worst_val_loss = max(model_resnet_mse_1_history['val_loss'])\n",
        "plt.annotate(f'Best BBox: {best_bbox_loss:.4f}', xy=(model_resnet_mse_1_history['bounding_box_loss'].index(best_bbox_loss), best_bbox_loss), xytext=(10, 5),\n",
        "             textcoords='offset points', color='blue', fontsize=10)\n",
        "plt.annotate(f'Worst BBox: {worst_bbox_loss:.4f}', xy=(model_resnet_mse_1_history['bounding_box_loss'].index(worst_bbox_loss), worst_bbox_loss),\n",
        "             xytext=(-60, -15), textcoords='offset points', color='blue', fontsize=10)\n",
        "plt.annotate(f'Best Val: {best_val_loss:.4f}', xy=(model_resnet_mse_1_history['val_loss'].index(best_val_loss), best_val_loss), xytext=(10, 5),\n",
        "             textcoords='offset points', color='orange', fontsize=10)\n",
        "plt.annotate(f'Worst Val: {worst_val_loss:.4f}', xy=(model_resnet_mse_1_history['val_loss'].index(worst_val_loss), worst_val_loss),\n",
        "             xytext=(-60, -15), textcoords='offset points', color='orange', fontsize=10)\n",
        "\n",
        "# Show Bounding Box and Validation Loss plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RTWtAvrJo1bM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VK6k8rzDa2Vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# Assuming you have already loaded your model\n",
        "model = load_model('/content/drive/MyDrive/project_mark1/model_top_layers.h5')\n",
        "\n",
        "# Plot the model architecture\n",
        "plot_model(model, to_file='model_architecture.png', show_shapes=True)"
      ],
      "metadata": {
        "id": "2IVvUe-hpQcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install visualkeras\n",
        "import visualkeras\n",
        "visualkeras.layered_view(model)"
      ],
      "metadata": {
        "id": "V8U42uuQaptL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten\n",
        "from tensorflow.keras.applications import ResNet50"
      ],
      "metadata": {
        "id": "K-XRfZRKmrxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### --> 0.42\n",
        "### --> only carside --> imagenet --> mse --> Reset50"
      ],
      "metadata": {
        "id": "-ZSmNXM4xxlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Perform label encoding on the target labels\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
        "val_labels_encoded = label_encoder.transform(val_labels)\n",
        "\n",
        "# Convert the encoded labels to one-hot encoding\n",
        "train_labels_onehot = to_categorical(train_labels_encoded, num_classes=1) ## ==> update number of classes\n",
        "val_labels_onehot = to_categorical(val_labels_encoded, num_classes=1) ## ==> update number of classes\n",
        "\n",
        "# Model architecture\n",
        "input_layer = Input(shape=(224, 224, 3))\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=input_layer)\n",
        "\n",
        "flatten = Flatten()(base_model.output)\n",
        "\n",
        "bboxHead = Dense(1024, activation=\"relu\")(flatten)\n",
        "bboxHead = Dense(512, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(256, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(128, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(64, activation=\"relu\")(bboxHead)\n",
        "bboxHead = Dense(32, activation=\"relu\")(bboxHead)\n",
        "bbox_output = Dense(4, activation='linear', name='bounding_box')(bboxHead)\n",
        "\n",
        "carside_resnet_mse_1 = Model(inputs=input_layer, outputs=[bbox_output])\n",
        "\n",
        "# Compile the model\n",
        "carside_resnet_mse_1.compile(optimizer='adam', loss=\"mse\")\n",
        "carside_resnet_mse_1.summary()"
      ],
      "metadata": {
        "id": "wFEg0DyZmuDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)"
      ],
      "metadata": {
        "id": "heU5Sfqpm5IY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model with early stopping\n",
        "carside_resnet_mse_1_history = carside_resnet_mse_1.fit(\n",
        "    train_images,\n",
        "    {'bounding_box': train_boxes},  # Update the label key to 'bounding_box'\n",
        "    validation_data=(val_images, {'bounding_box': val_boxes}),  # Update the label key to 'bounding_box'\n",
        "    epochs=300,\n",
        "    batch_size=32,\n",
        "    callbacks=[callback]\n",
        ")"
      ],
      "metadata": {
        "id": "38YblzUemyWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the label encoder\n",
        "with open('/content/drive/MyDrive/project_mark1/carside_resnet_mse_1_label_encoder.pkl', 'wb') as file:\n",
        "    pickle.dump(label_encoder, file)\n",
        "\n",
        "# Save the entire model to a HDF5 file\n",
        "carside_resnet_mse_1.save('/content/drive/MyDrive/project_mark1/carside_resnet_mse_1_history.h5')\n",
        "\n",
        "# Save the history object to a file using pickle\n",
        "with open('/content/drive/MyDrive/project_mark1/model_fine_tuned_history.pkl', 'wb') as file:\n",
        "    pickle.dump(carside_resnet_mse_1_history.history, file)"
      ],
      "metadata": {
        "id": "RtQMptdKm09S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get the loss values from the history object\n",
        "train_loss = carside_resnet_mse_1_history.history['loss']\n",
        "val_loss = carside_resnet_mse_1_history.history['val_loss']\n",
        "\n",
        "# Plot the loss values\n",
        "plt.plot(train_loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.title('Loss Curve')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EnRx1iYVnRJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_train_loss = min(train_loss)\n",
        "best_val_loss = min(val_loss)\n",
        "worst_train_loss = max(train_loss)\n",
        "worst_val_loss = max(val_loss)\n",
        "\n",
        "print(\"Best Training Loss:\", best_train_loss)\n",
        "print(\"Best Validation Loss:\", best_val_loss)\n",
        "print(\"Worst Training Loss:\", worst_train_loss)\n",
        "print(\"Worst Validation Loss:\", worst_val_loss)"
      ],
      "metadata": {
        "id": "-1Ylpw-nnSbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get the loss and accuracy values from the history object\n",
        "train_loss = carside_resnet_mse_1_history.history['loss']\n",
        "val_loss = carside_resnet_mse_1_history.history['val_loss']\n",
        "train_accuracy = carside_resnet_mse_1_history.history['accuracy']\n",
        "val_accuracy = carside_resnet_mse_1_history.history['val_accuracy']\n",
        "\n",
        "# Create subplots for loss and accuracy\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 8))\n",
        "\n",
        "# Plot loss values\n",
        "ax1.plot(train_loss, label='Training Loss')\n",
        "ax1.plot(val_loss, label='Validation Loss')\n",
        "ax1.set_title('Loss')\n",
        "ax1.set_xlabel('Epochs')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.legend()\n",
        "ax1.grid(True)\n",
        "\n",
        "# Plot accuracy values\n",
        "ax2.plot(train_accuracy, label='Training Accuracy')\n",
        "ax2.plot(val_accuracy, label='Validation Accuracy')\n",
        "ax2.set_title('Accuracy')\n",
        "ax2.set_xlabel('Epochs')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "ax2.legend()\n",
        "ax2.grid(True)\n",
        "\n",
        "# Adjust spacing between subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XzjF4TEeniMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_iou(box1, box2):\n",
        "    # Extract coordinates from the bounding boxes\n",
        "    x1_min, y1_min, x1_max, y1_max = box1\n",
        "    x2_min, y2_min, x2_max, y2_max = box2\n",
        "\n",
        "    # Calculate the intersection area\n",
        "    intersection_area = max(0, min(x1_max, x2_max*19) - max(x1_min, x2_min*19)) * max(0, min(y1_max, y2_max*30) - max(y1_min, y2_min*30))\n",
        "\n",
        "    # Calculate the union area\n",
        "    box1_area = (x1_max - x1_min) * (y1_max - y1_min)\n",
        "    box2_area = (x2_max*19 - x2_min*19) * (y2_max*30 - y2_min*30)\n",
        "    union_area = box1_area + box2_area - intersection_area\n",
        "\n",
        "    # Calculate the IoU\n",
        "    iou = intersection_area / union_area\n",
        "\n",
        "    return iou"
      ],
      "metadata": {
        "id": "6avMlpm3oDUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test images\n",
        "predictions = carside_resnet_mse_1.predict(test_images)\n",
        "\n",
        "# Calculate IoU for each image\n",
        "iou_scores = []\n",
        "for i in range(len(predictions)):\n",
        "    pred_box = predictions[i]\n",
        "    true_box = test_boxes[i]\n",
        "    iou = calculate_iou(pred_box, true_box)\n",
        "    iou_scores.append(iou)\n",
        "\n",
        "# Display predicted and original bounding box values with IoU scores\n",
        "for i in range(len(predictions)):\n",
        "    print(\"Image\", i+1)\n",
        "    print(\"Predicted Bounding Box:\", predictions[i])\n",
        "    print(\"Original Bounding Box:\", test_boxes[i])\n",
        "\n",
        "    print(\"IoU Score:\", iou_scores[i])\n",
        "    print()"
      ],
      "metadata": {
        "id": "uCSjFh4dn-6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uM8x3dYgw7Os"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Load the saved model\n",
        "model_top = load_model('/content/drive/MyDrive/project_mark2/model_resnet_mse_1.h5')\n"
      ],
      "metadata": {
        "id": "pQ_CbJ1Pb_A_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model architecture\n",
        "input_layer = Input(shape=(224, 224, 3))\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=input_layer)"
      ],
      "metadata": {
        "id": "xwAzM9Xfb-5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flatten = Flatten()(base_model.output)\n",
        "\n",
        "bboxHead = Dense(1024, activation=\"relu\")(flatten)\n",
        "bboxHead = Dense(512, activation=\"relu\")(bboxHead)\n",
        "\n",
        "\n",
        "\n",
        "bbox_output = Dense(4, activation='linear', name='bounding_box')(bboxHead)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=bbox_output)\n"
      ],
      "metadata": {
        "id": "xJ1s8cMnb-1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved weights layer by layer\n",
        "for layer in model.layers:\n",
        "    if layer.name in model_top.layers:\n",
        "        layer.set_weights(model_top.get_layer(layer.name).get_weights())\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "5MwxW_hfb-zU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define early stopping callback\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(train_images, train_boxes,\n",
        "                    validation_data=(val_images, val_boxes),\n",
        "                    epochs=300, batch_size=8)"
      ],
      "metadata": {
        "id": "1uJT4CUzc820"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "model.save('/content/drive/MyDrive/trained_bbox_model_2.h5')"
      ],
      "metadata": {
        "id": "GCTkwLxFdrIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get the training and validation loss values from the history object\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Get the epoch with the best and worst training loss\n",
        "best_train_epoch = train_loss.index(min(train_loss)) + 1\n",
        "worst_train_epoch = train_loss.index(max(train_loss)) + 1\n",
        "\n",
        "# Get the epoch with the best and worst validation loss\n",
        "best_val_epoch = val_loss.index(min(val_loss)) + 1\n",
        "worst_val_epoch = val_loss.index(max(val_loss)) + 1\n",
        "\n",
        "# Plot the training and validation losses\n",
        "epochs = range(1, len(train_loss) + 1)\n",
        "plt.plot(epochs, train_loss, 'b', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot the best and worst values\n",
        "plt.plot(best_train_epoch, min(train_loss), 'go', label='Best Training Loss')\n",
        "plt.plot(worst_train_epoch, max(train_loss), 'ro', label='Worst Training Loss')\n",
        "plt.plot(best_val_epoch, min(val_loss), 'g^', label='Best Validation Loss')\n",
        "plt.plot(worst_val_epoch, max(val_loss), 'r^', label='Worst Validation Loss')\n",
        "\n",
        "plt.annotate(f'({best_train_epoch}, {min(train_loss):.4f})',\n",
        "             xy=(best_train_epoch, min(train_loss)),\n",
        "             xytext=(best_train_epoch, min(train_loss) + 0.5),\n",
        "             arrowprops=dict(facecolor='green', arrowstyle='->'))\n",
        "\n",
        "plt.annotate(f'({worst_train_epoch}, {max(train_loss):.4f})',\n",
        "             xy=(worst_train_epoch, max(train_loss)),\n",
        "             xytext=(worst_train_epoch, max(train_loss) + 0.5),\n",
        "             arrowprops=dict(facecolor='red', arrowstyle='->'))\n",
        "\n",
        "plt.annotate(f'({best_val_epoch}, {min(val_loss):.4f})',\n",
        "             xy=(best_val_epoch, min(val_loss)),\n",
        "             xytext=(best_val_epoch, min(val_loss) + 0.5),\n",
        "             arrowprops=dict(facecolor='green', arrowstyle='->'))\n",
        "\n",
        "plt.annotate(f'({worst_val_epoch}, {max(val_loss):.4f})',\n",
        "             xy=(worst_val_epoch, max(val_loss)),\n",
        "             xytext=(worst_val_epoch, max(val_loss) + 0.5),\n",
        "             arrowprops=dict(facecolor='red', arrowstyle='->'))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aRrODri1d4Vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_boxes"
      ],
      "metadata": {
        "id": "sq3o3KT9eJaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images"
      ],
      "metadata": {
        "id": "qAYwzLoIeV7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform predictions\n",
        "predicted_boxes = model.predict(test_images)\n",
        "\n",
        "# Calculate IoU scores for each image\n",
        "iou_scores = []\n",
        "for pred_box, true_box in zip(predicted_boxes, test_boxes):\n",
        "    iou_score = calculate_iou(pred_box, true_box)\n",
        "    iou_scores.append(iou_score)\n",
        "\n",
        "# Multiply bounding boxes\n",
        "multiplied_boxes = np.multiply(predicted_boxes, test_boxes)\n",
        "\n",
        "# Denormalize bounding boxes for plotting\n",
        "def denormalize_boxes(boxes, image_shape):\n",
        "    height, width = image_shape[:2]\n",
        "    boxes = np.array(boxes)\n",
        "    boxes[:, [0, 2]] *= width\n",
        "    boxes[:, [1, 3]] *= height\n",
        "    return boxes\n",
        "\n",
        "# Plot images with predicted and original bounding boxes\n",
        "def plot_image_with_boxes(image, boxes, title):\n",
        "    # Create figure and axes\n",
        "    fig, ax = plt.subplots(1)\n",
        "    ax.imshow(image)\n",
        "\n",
        "    # Plot bounding boxes\n",
        "    for box in boxes:\n",
        "        xmin, ymin, xmax, ymax = box\n",
        "        rect = plt.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, fill=False, edgecolor='r', linewidth=2)\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "    # Set title\n",
        "    ax.set_title(title)\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "# Iterate over each image and plot with bounding boxes\n",
        "for i in range(len(test_images)):\n",
        "    # Denormalize bounding boxes\n",
        "    denorm_test_boxes = denormalize_boxes([test_boxes[i]], test_images[i].shape)\n",
        "    denorm_predicted_boxes = denormalize_boxes([predicted_boxes[i]], test_images[i].shape)\n",
        "\n",
        "    # Plot the image with original bounding boxes\n",
        "    plot_image_with_boxes(test_images[i], denorm_test_boxes, \"Original Bounding Boxes\")\n",
        "\n",
        "    # Plot the image with predicted bounding boxes\n",
        "    plot_image_with_boxes(test_images[i], denorm_predicted_boxes, \"Predicted Bounding Boxes\")\n",
        "\n",
        "    # Print the IoU score\n",
        "    print(\"IoU score for image\", i+1, \":\", iou_scores[i])\n",
        "\n",
        "    # Print the multiplied bounding boxes\n",
        "    print(\"Multiplied bounding box for image\", i+1, \":\", multiplied_boxes[i])\n",
        "    print()\n",
        "\n",
        "# Calculate the mean IoU score\n",
        "mean_iou = np.mean(iou_scores)\n",
        "print(\"Mean IoU Score:\", mean_iou)"
      ],
      "metadata": {
        "id": "aWs9D96XeYC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Perform predictions\n",
        "predicted_boxes = model.predict(test_images)\n",
        "\n",
        "# Calculate IoU scores for each image\n",
        "iou_scores = []\n",
        "for pred_box, true_box in zip(predicted_boxes, test_boxes):\n",
        "    iou_score = calculate_iou(pred_box, true_box)\n",
        "    iou_scores.append(iou_score)\n",
        "\n",
        "# Print the bounding boxes and IoU scores for each image\n",
        "for i in range(len(test_images)):\n",
        "    print(\"Bounding Box for Image\", i+1)\n",
        "    print(\"Predicted Box:\", predicted_boxes[i])\n",
        "    print(\"True Box:\", test_boxes[i])\n",
        "    print(\"IoU Score:\", iou_scores[i])\n",
        "    print()\n",
        "\n",
        "# Calculate the mean IoU score\n",
        "mean_iou = np.mean(iou_scores)\n",
        "print(\"Mean IoU Score:\", mean_iou)"
      ],
      "metadata": {
        "id": "qSge46_zhwmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Perform predictions\n",
        "predicted_boxes = model.predict(test_images)\n",
        "\n",
        "# Calculate IoU scores for each image\n",
        "iou_scores = []\n",
        "for pred_box, true_box in zip(predicted_boxes, test_boxes):\n",
        "    iou_score = calculate_iou(pred_box, true_box)\n",
        "    iou_scores.append(iou_score)\n",
        "\n",
        "# Multiply bounding boxes\n",
        "multiplied_boxes = np.multiply(predicted_boxes, test_boxes)\n",
        "\n",
        "# Denormalize bounding boxes for plotting\n",
        "def denormalize_boxes(boxes, image_shape):\n",
        "    height, width = image_shape[:2]\n",
        "    boxes = np.array(boxes)\n",
        "    boxes[:, [0, 2]] *= width\n",
        "    boxes[:, [1, 3]] *= height\n",
        "    return boxes\n",
        "\n",
        "# Plot images with predicted and original bounding boxes\n",
        "def plot_image_with_boxes(image, boxes, iou_score, title):\n",
        "    # Create figure and axes\n",
        "    fig, ax = plt.subplots(1)\n",
        "    ax.imshow(image)\n",
        "\n",
        "    # Plot bounding boxes\n",
        "    for box in boxes:\n",
        "        xmin, ymin, xmax, ymax = box\n",
        "        rect = cv2.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, fill=False, edgecolor='r', linewidth=2)\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "    # Set title and IoU text\n",
        "    ax.set_title(f\"{title}\\nIoU: {iou_score:.2f}\")\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "# Iterate over each image and plot with bounding boxes and IoU\n",
        "mean_iou = 0.0\n",
        "for i in range(len(test_images)):\n",
        "    # Denormalize bounding boxes\n",
        "    denorm_test_boxes = denormalize_boxes([test_boxes[i]], test_images[i].shape)\n",
        "    denorm_predicted_boxes = denormalize_boxes([predicted_boxes[i]], test_images[i].shape)\n",
        "\n",
        "    # Calculate IoU score\n",
        "    iou_score = iou_scores[i]\n",
        "    mean_iou += iou_score\n",
        "\n",
        "    # Plot the image with original and predicted bounding boxes\n",
        "    plot_image_with_boxes(test_images[i], denorm_test_boxes, iou_score, \"Original and Predicted Bounding Boxes\")\n",
        "\n",
        "# Calculate the mean IoU score\n",
        "mean_iou /= len(test_images)\n",
        "print(\"Mean IoU Score:\", mean_iou)"
      ],
      "metadata": {
        "id": "qjU9-4lDltm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "# Perform predictions\n",
        "predicted_boxes = model.predict(test_images)\n",
        "\n",
        "# Calculate IoU scores for each image\n",
        "iou_scores = []\n",
        "for pred_box, true_box in zip(predicted_boxes, test_boxes):\n",
        "    iou_score = calculate_iou(pred_box, true_box)\n",
        "    iou_scores.append(iou_score)\n",
        "\n",
        "# Multiply bounding boxes\n",
        "multiplied_boxes = np.multiply(predicted_boxes, test_boxes)\n",
        "\n",
        "# Denormalize bounding boxes for plotting\n",
        "def denormalize_boxes(boxes, image_shape):\n",
        "    height, width = image_shape[:2]\n",
        "    boxes = np.array(boxes)\n",
        "    boxes[:, [0, 2]] *= width\n",
        "    boxes[:, [1, 3]] *= height\n",
        "    return boxes\n",
        "\n",
        "# Plot images with original and predicted bounding boxes\n",
        "def plot_image_with_boxes(image, true_boxes, pred_boxes, iou_score, title):\n",
        "    # Create figure and axes\n",
        "    fig, ax = plt.subplots(1)\n",
        "    ax.imshow(image)\n",
        "\n",
        "    # Plot original bounding boxes\n",
        "    for box in true_boxes:\n",
        "        xmin, ymin, xmax, ymax = box\n",
        "        rect = Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, fill=False, edgecolor='r', linewidth=2)\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "    # Plot predicted bounding boxes\n",
        "    for box in pred_boxes:\n",
        "        xmin, ymin, xmax, ymax = box\n",
        "        rect = Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, fill=False, edgecolor='b', linewidth=2)\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "    # Set title and IoU text\n",
        "    ax.set_title(f\"{title}\\nIoU: {iou_score:.2f}\")\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "# Iterate over each image and plot with bounding boxes and IoU\n",
        "mean_iou = 0.0\n",
        "for i in range(len(test_images)):\n",
        "    # Denormalize bounding boxes\n",
        "    denorm_test_boxes = denormalize_boxes([test_boxes[i]], test_images[i].shape)\n",
        "    denorm_predicted_boxes = denormalize_boxes([predicted_boxes[i]], test_images[i].shape)\n",
        "\n",
        "    # Calculate IoU score\n",
        "    iou_score = iou_scores[i]\n",
        "    mean_iou += iou_score\n",
        "\n",
        "    # Plot the image with original and predicted bounding boxes\n",
        "    plot_image_with_boxes(test_images[i], denorm_test_boxes, denorm_predicted_boxes, iou_score, \"Original and Predicted Bounding Boxes\")\n",
        "\n",
        "# Calculate the mean IoU score\n",
        "mean_iou /= len(test_images)\n",
        "print(\"Mean IoU Score:\", mean_iou)"
      ],
      "metadata": {
        "id": "ybnGqb-8l4nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "ITA_yn5omXqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model architecture\n",
        "input_layer = Input(shape=(224, 224, 3))\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=input_layer)"
      ],
      "metadata": {
        "id": "7bbzDPoxpjli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flatten = Flatten()(base_model.output)\n",
        "\n",
        "bboxHead = Dense(1024, activation=\"relu\")(flatten)\n",
        "bboxHead = Dense(512, activation=\"relu\")(bboxHead)\n",
        "\n",
        "\n",
        "\n",
        "bbox_output = Dense(4, activation='linear', name='bounding_box')(bboxHead)\n",
        "\n",
        "model_2 = Model(inputs=input_layer, outputs=bbox_output)\n"
      ],
      "metadata": {
        "id": "GoydcAdGplc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_2.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model_2.summary()"
      ],
      "metadata": {
        "id": "c8XnGl2OpoLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define early stopping callback\n",
        "\n",
        "# Train the model with early stopping\n",
        "history_2 = model_2.fit(train_images, train_boxes,\n",
        "                    validation_data=(val_images, val_boxes),\n",
        "                    epochs=300, batch_size=8)"
      ],
      "metadata": {
        "id": "I_XAGVVFpplZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "model_2.save('/content/drive/MyDrive/trained_bbox_model_3.h5')"
      ],
      "metadata": {
        "id": "7BQsDdIBp1BX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get the training and validation loss values from the history object\n",
        "train_loss = history_2.history['loss']\n",
        "val_loss = history_2.history['val_loss']\n",
        "\n",
        "# Get the epoch with the best and worst training loss\n",
        "best_train_epoch = train_loss.index(min(train_loss)) + 1\n",
        "worst_train_epoch = train_loss.index(max(train_loss)) + 1\n",
        "\n",
        "# Get the epoch with the best and worst validation loss\n",
        "best_val_epoch = val_loss.index(min(val_loss)) + 1\n",
        "worst_val_epoch = val_loss.index(max(val_loss)) + 1\n",
        "\n",
        "# Plot the training and validation losses\n",
        "epochs = range(1, len(train_loss) + 1)\n",
        "plt.plot(epochs, train_loss, 'b', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot the best and worst values\n",
        "plt.plot(best_train_epoch, min(train_loss), 'go', label='Best Training Loss')\n",
        "plt.plot(worst_train_epoch, max(train_loss), 'ro', label='Worst Training Loss')\n",
        "plt.plot(best_val_epoch, min(val_loss), 'g^', label='Best Validation Loss')\n",
        "plt.plot(worst_val_epoch, max(val_loss), 'r^', label='Worst Validation Loss')\n",
        "\n",
        "plt.annotate(f'({best_train_epoch}, {min(train_loss):.4f})',\n",
        "             xy=(best_train_epoch, min(train_loss)),\n",
        "             xytext=(best_train_epoch, min(train_loss) + 0.5),\n",
        "             arrowprops=dict(facecolor='green', arrowstyle='->'))\n",
        "\n",
        "plt.annotate(f'({worst_train_epoch}, {max(train_loss):.4f})',\n",
        "             xy=(worst_train_epoch, max(train_loss)),\n",
        "             xytext=(worst_train_epoch, max(train_loss) + 0.5),\n",
        "             arrowprops=dict(facecolor='red', arrowstyle='->'))\n",
        "\n",
        "plt.annotate(f'({best_val_epoch}, {min(val_loss):.4f})',\n",
        "             xy=(best_val_epoch, min(val_loss)),\n",
        "             xytext=(best_val_epoch, min(val_loss) + 0.5),\n",
        "             arrowprops=dict(facecolor='green', arrowstyle='->'))\n",
        "\n",
        "plt.annotate(f'({worst_val_epoch}, {max(val_loss):.4f})',\n",
        "             xy=(worst_val_epoch, max(val_loss)),\n",
        "             xytext=(worst_val_epoch, max(val_loss) + 0.5),\n",
        "             arrowprops=dict(facecolor='red', arrowstyle='->'))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bTLwePnqqP8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "# Perform predictions\n",
        "predicted_boxes = model_2.predict(test_images)\n",
        "\n",
        "# Calculate IoU scores for each image\n",
        "iou_scores = []\n",
        "for pred_box, true_box in zip(predicted_boxes, test_boxes):\n",
        "    iou_score = calculate_iou(pred_box, true_box)\n",
        "    iou_scores.append(iou_score)\n",
        "\n",
        "# Multiply bounding boxes\n",
        "multiplied_boxes = np.multiply(predicted_boxes, test_boxes)\n",
        "\n",
        "# Denormalize bounding boxes for plotting\n",
        "def denormalize_boxes(boxes, image_shape):\n",
        "    height, width = image_shape[:2]\n",
        "    boxes = np.array(boxes)\n",
        "    boxes[:, [0, 2]] *= width\n",
        "    boxes[:, [1, 3]] *= height\n",
        "    return boxes\n",
        "\n",
        "# Plot images with original and predicted bounding boxes\n",
        "def plot_image_with_boxes(image, true_boxes, pred_boxes, iou_score, title):\n",
        "    # Create figure and axes\n",
        "    fig, ax = plt.subplots(1)\n",
        "    ax.imshow(image)\n",
        "\n",
        "    # Plot original bounding boxes\n",
        "    for box in true_boxes:\n",
        "        xmin, ymin, xmax, ymax = box\n",
        "        rect = Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, fill=False, edgecolor='r', linewidth=2)\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "    # Plot predicted bounding boxes\n",
        "    for box in pred_boxes:\n",
        "        xmin, ymin, xmax, ymax = box\n",
        "        rect = Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, fill=False, edgecolor='b', linewidth=2)\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "    # Set title and IoU text\n",
        "    ax.set_title(f\"{title}\\nIoU: {iou_score:.2f}\")\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "# Iterate over each image and plot with bounding boxes and IoU\n",
        "mean_iou = 0.0\n",
        "for i in range(len(test_images)):\n",
        "    # Denormalize bounding boxes\n",
        "    denorm_test_boxes = denormalize_boxes([test_boxes[i]], test_images[i].shape)\n",
        "    denorm_predicted_boxes = denormalize_boxes([predicted_boxes[i]], test_images[i].shape)\n",
        "\n",
        "    # Calculate IoU score\n",
        "    iou_score = iou_scores[i]\n",
        "    mean_iou += iou_score\n",
        "\n",
        "    # Plot the image with original and predicted bounding boxes\n",
        "    plot_image_with_boxes(test_images[i], denorm_test_boxes, denorm_predicted_boxes, iou_score, \"Original and Predicted Bounding Boxes\")\n",
        "\n",
        "# Calculate the mean IoU score\n",
        "mean_iou /= len(test_images)\n",
        "print(\"Mean IoU Score:\", mean_iou)"
      ],
      "metadata": {
        "id": "yzTC6NnCqaiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Perform label encoding on the target labels\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
        "val_labels_encoded = label_encoder.transform(val_labels)\n",
        "\n",
        "# Convert the encoded labels to one-hot encoding\n",
        "train_labels_onehot = to_categorical(train_labels_encoded, num_classes=101)\n",
        "val_labels_onehot = to_categorical(val_labels_encoded, num_classes=101)\n",
        "\n",
        "\n",
        "# Model architecture\n",
        "input_layer = Input(shape=(224, 224, 3))\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=input_layer)\n",
        "\n",
        "flatten = Flatten()(base_model.output)\n",
        "\n",
        "bboxHead = Dense(1024, activation=\"relu\")(flatten)\n",
        "\n",
        "bboxHead = Dense(512, activation=\"relu\")(bboxHead)\n",
        "\n",
        "\n",
        "bbox_output = Dense(4, activation='linear', name='bounding_box')(bboxHead)\n",
        "\n",
        "\n",
        "softmaxHead = Dense(1024, activation=\"relu\")(flatten)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "\n",
        "\n",
        "softmaxHead = Dense(512, activation=\"relu\")(softmaxHead)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "\n",
        "softmaxHead = Dense(256, activation=\"relu\")(softmaxHead)\n",
        "softmaxHead = Dropout(0.5)(softmaxHead)\n",
        "\n",
        "class_output = Dense(101, activation='softmax', name='class_output')(softmaxHead)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=[class_output, bbox_output])\n",
        "\n",
        "# Loss function\n",
        "losses = {\n",
        "    'class_output': 'categorical_crossentropy',\n",
        "    'bounding_box': 'mean_squared_error'\n",
        "}\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss=losses)\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "RLVrH_oyWDOF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}